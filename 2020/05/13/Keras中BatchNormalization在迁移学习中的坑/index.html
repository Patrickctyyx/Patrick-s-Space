<!DOCTYPE html>
<html>
    <head><meta name="generator" content="Hexo 3.9.0">
    <!-- Title -->
    
    <title>
        keras中BatchNormalization在迁移学习中的坑 | Patrick&#39;s Space
    </title>
    
    <!-- Favicons -->
    <link rel="icon shortcut" type="image/ico" href="https://static.jnugeek.cn/img/favion.ico">
    <link rel="icon" sizes="192x192" href="https://static.jnugeek.cn/img/favicon.ico">
    <link rel="apple-touch-icon" href="https://static.jnugeek.cn/img/favicon.ico">
    
    <!-- Meta & INfo -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#0097A7">
    <meta name="author" content="Patrick">
    <meta name="description" content="PatrickCty">
    <meta name="keywords" content="Patrick&#39;s Space">
    
    <!--iOS -->
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-title" content="Title">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="480">
    
    <!-- Add to homescreen for Chrome on Android -->
    <meta name="mobile-web-app-capable" content="yes">
    
    <!-- Add to homescreen for Safari on iOS -->
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="apple-mobile-web-app-title" content="Patrick&#39;s Space">
    
    <!-- The Open Graph protocol -->
    <meta property="og:url" content="https://blog.patrickcty.cc">
    <meta property="og:type" content="blog">
    <meta property="og:title" content="keras中BatchNormalization在迁移学习中的坑 | Patrick&#39;s Space">
    <meta property="og:description" content="PatrickCty">
    
     <!--[if lte IE 9]>
        <link rel="stylesheet" href="/css/ie-blocker.css">
        
        
            <script src="/js/ie-blocker.zhCN.js"></script>
        
    <![endif]-->
    
    <!-- Import CSS -->
    <link rel="stylesheet" href="/css/material.min.css">
    <link rel="stylesheet" href="/css/style.min.css">
    <!-- Config CSS -->


<!-- Other Styles -->
<style>
	body, html{
		font-family: Roboto, "Helvetica Neue", Helvetica, "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei", "微软雅黑", Arial, sans-serif;
	}
	
    a{
        color: #00838F
    }
    
    .mdl-card__media,
    #search-label,
    #search-form-label:after,
    #scheme-Paradox .hot_tags-count,
    #scheme-Paradox .sidebar_archives-count,
    #scheme-Paradox .sidebar-colored .sidebar-header,
    #scheme-Paradox .sidebar-colored .sidebar-badge{
        background-color: #0097A7 !important
    }
    
	/* Sidebar User Drop Down Menu Text Color */
	#scheme-Paradox .sidebar-colored .sidebar-nav>.dropdown>.dropdown-menu>li>a:hover,
    #scheme-Paradox .sidebar-colored .sidebar-nav>.dropdown>.dropdown-menu>li>a:focus{
        color: #0097A7 !important
    }
    
    #post_entry-right-info,
    .sidebar-colored .sidebar-nav li:hover > a,
    .sidebar-colored .sidebar-nav li:hover > a i,
    .sidebar-colored .sidebar-nav li > a:hover,
    .sidebar-colored .sidebar-nav li > a:hover i,
    .sidebar-colored .sidebar-nav li > a:focus i,
    .sidebar-colored .sidebar-nav > .open > a,
    .sidebar-colored .sidebar-nav > .open > a:hover,
    .sidebar-colored .sidebar-nav > .open > a:focus,
    #ds-reset #ds-ctx .ds-ctx-entry .ds-ctx-head a{
        color: #0097A7 !important
    }
    
    .toTop{
        background: #757575 !important
    }
		
	.material-layout .material-post>.material-nav,
	.material-layout .material-index>.material-nav,
	.material-nav a{
		color: #757575;
	}
		
	#scheme-Paradox .MD-burger-layer {
		background-color: #757575;
	}

	#scheme-Paradox #post-toc-trigger-btn{
		color: #757575;
	}
	
	.post-toc a:hover{
		color: #00838F;
		text-decoration: underline;
	}
</style>


<!-- Theme Background Related-->

    <style>
        body{
            background-color: #F5F5F5
        }
		
		/* blog_info bottom background */
        #scheme-Paradox .material-layout .something-else .mdl-card__supporting-text{
            background-color: #fff;
        }
    </style>




<!-- Fade Effect -->

    <style>
        .fade {
            transition: all 800ms linear;
            -webkit-transform: translate3d(0,0,0);
            -moz-transform: translate3d(0,0,0);
            -ms-transform: translate3d(0,0,0);
            -o-transform: translate3d(0,0,0);
            transform: translate3d(0,0,0);
            opacity: 1;
        }

        .fade.out{
            opacity: 0;
        }
    </style>

	<script src="/js/jquery.min.js"></script>
	
	<link rel="stylesheet" href="/css/highlight/solarized-white.css">
	
	<!-- UC Browser Compatible-->
	<script>
		var agent = navigator.userAgent.toLowerCase();
		if(agent.indexOf('ucbrowser')>0) {
			document.write('<link rel="stylesheet" href="/css/uc.css">');
		   alert('由于 UC 浏览器使用极旧的内核，而本网站使用了一些新的特性。\n为了您能更好的浏览，推荐使用 Chrome 或 Firefox 浏览器。');
		}
	</script>
    
    <!-- Custom Head -->
    
        
			<!-- Name -->
			<script type="text/javascript" src="/js/love.js"></script>
        
    
</head>
	
	

    <body id="scheme-Paradox">

		
        <div class="material-layout  mdl-js-layout has-drawer is-upgraded">
				
			
			
            <!-- Main Container -->
            <main class="material-layout__content" id="main">
				
                <!-- Top Anchor -->
                <div id="top"></div>
				
				
                <!-- Hamburger Button -->
                <button class="MD-burger-icon sidebar-toggle">
                    <span class="MD-burger-layer"></span>
                </button>
				
				
                <!-- Post TOC -->

    
	<!-- Back Button -->
<!--
	<div class="material-back" id="backhome-div" tabindex="0">
		<a class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon" href="#" onclick="window.history.back();return false;" target="_self" role="button" data-upgraded=",MaterialButton,MaterialRipple">
			<i class="material-icons" role="presentation">arrow_back</i>
			<span class="mdl-button__ripple-container">
				<span class="mdl-ripple"></span>
			</span>
		</a>
	</div>			
-->
	<!-- Left aligned menu below button -->
	<button id="post-toc-trigger-btn"
			class="mdl-button mdl-js-button mdl-button--icon">
	  <i class="material-icons">format_list_numbered</i>
	</button>

	<ul class="post-toc-wrap mdl-menu mdl-menu--bottom-left mdl-js-menu mdl-js-ripple-effect"
		for="post-toc-trigger-btn">
			
			<ol class="post-toc"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#注"><span class="post-toc-number">1.</span> <span class="post-toc-text">注</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#背景"><span class="post-toc-number">2.</span> <span class="post-toc-text">背景</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#问题"><span class="post-toc-number">3.</span> <span class="post-toc-text">问题</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#结果"><span class="post-toc-number">4.</span> <span class="post-toc-text">结果</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#最后"><span class="post-toc-number">5.</span> <span class="post-toc-text">最后</span></a></li></ol>
		
<!--			<li class="mdl-menu__item">Some Action</li>-->
	</ul>



<!-- Layouts -->

    <!-- Post Module -->
    <div class="material-post_container">
		
        <div class="material-post mdl-grid">
            <div class="mdl-card mdl-shadow--4dp mdl-cell mdl-cell--12-col">

                <!-- Post Header(Thumbnail & Title) -->
                
	<!-- Paradox Post Header -->
	
		
			<!-- Random Thumbnail -->
			<div class="post_thumbnail-random mdl-card__media mdl-color-text--grey-50">
				<script>
    
    var randomNum;
    randomNum = Math.floor(Math.random() * 12 + 1);
    
    $(".post_thumbnail-random").css('background-image', 'url(' + 'https://static.jnugeek.cn/img/my_pic/' + randomNum + '.png' + ')');
    
</script>

		
	
        <p class="article-headline-p">
            keras中BatchNormalization在迁移学习中的坑
        </p>
    </div>

	

				
				
					<!-- Paradox Post Info -->
					<div class="mdl-color-text--grey-700 mdl-card__supporting-text meta">
    
    <!-- Author Avatar -->
    <div id="author-avatar">
        <img src="https://static.jnugeek.cn/img/avatar.jpg" width="44px" height="44px" alt="Author Avatar"/>
    </div>
    <!-- Author Name & Date -->
    <div>
        <strong>Patrick</strong>
        <span>5月 13, 2020</span>
    </div>
    
    <div class="section-spacer"></div>
	
    <!-- Favorite -->
<!--
    <button id="article-functions-like-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon btn-like">
        <i class="material-icons" role="presentation">favorite</i>
        <span class="visuallyhidden">favorites</span>
    </button>
-->
    
    <!-- Tags (bookmark) -->
    <button id="article-functions-viewtags-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon">
        <i class="material-icons" role="presentation">bookmark</i>
        <span class="visuallyhidden">bookmark</span>
    </button>
    <ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-functions-viewtags-button">
        <li class="mdl-menu__item">
        
    </ul>
    
    <!-- Share -->
    <button id="article-fuctions-share-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon">
    <i class="material-icons" role="presentation">share</i>
    <span class="visuallyhidden">share</span>
</button>
<ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-fuctions-share-button">
    
    
    
    
    <!-- Busuanzi Views -->
    <a class="post_share-link" href="#">
        <li class="mdl-menu__item">
            <span id="busuanzi_container_page_pv">
                <span id="busuanzi_value_page_pv"></span>&nbsp;浏览量
            </span>
        </li>
    </a>
    
    
    <!-- Share Twitter -->
    <a class="post_share-link" href="https://twitter.com/intent/tweet?text=keras中BatchNormalization在迁移学习中的坑&url=https://blog.patrickcty.cc//2020/05/13/Keras中BatchNormalization在迁移学习中的坑/index.html&via=Patrick" target="_blank">
        <li class="mdl-menu__item">
            分享到 Twitter
        </li>
    </a>
    
    <!-- Share Google+ -->
    <a class="post_share-link" href="https://plus.google.com/share?url=https://blog.patrickcty.cc//2020/05/13/Keras中BatchNormalization在迁移学习中的坑/index.html" target="_blank">
        <li class="mdl-menu__item">
            分享到 Google+
        </li>
    </a>
    
    <!-- Share Weibo -->
    <a class="post_share-link" href="http://service.weibo.com/share/share.php?appkey=&title=keras中BatchNormalization在迁移学习中的坑&url=https://blog.patrickcty.cc//2020/05/13/Keras中BatchNormalization在迁移学习中的坑/index.html&pic=&searchPic=false&style=simple" target="_blank">
        <li class="mdl-menu__item">
            分享到微博
        </li>
    </a>
</ul>
</div>
				

                <!-- Post Content -->
                <div id="post-content" class="markdown-Github mdl-color-text--grey-700 mdl-card__supporting-text fade out">
	
		<h2 id="注"><a href="#注" class="headerlink" title="注"></a>注</h2><p>这个问题已经在 TF 2.0 中修复了，见<a href="https://tensorflow.google.cn/api_docs/python/tf/keras/layers/BatchNormalization?hl=zh-cn" target="_blank" rel="noopener">文档</a>。</p>
<blockquote>
<p>However, in the case of the BatchNormalization layer, setting trainable = False on the layer means that the layer will be subsequently run in inference mode (meaning that it will use the moving mean and the moving variance to normalize the current batch, rather than using the mean and variance of the current batch).</p>
<p>This behavior has been introduced in TensorFlow 2.0, in order to enable layer.trainable = False to produce the most commonly expected behavior in the convnet fine-tuning use case.</p>
</blockquote>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>最近 Keras 的文档更新了，我发现了一个迁移学习的文档，结果进去之后发现一个奇怪的地方：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">base_model = keras.applications.Xception(</span><br><span class="line">    weights=&quot;imagenet&quot;,  # Load weights pre-trained on ImageNet.</span><br><span class="line">    input_shape=(150, 150, 3),</span><br><span class="line">    include_top=False,</span><br><span class="line">)  # Do not include the ImageNet classifier at the top.</span><br><span class="line"></span><br><span class="line"># Freeze the base_model</span><br><span class="line">base_model.trainable = False</span><br><span class="line"></span><br><span class="line"># Create new model on top</span><br><span class="line">inputs = keras.Input(shape=(150, 150, 3))</span><br><span class="line">x = data_augmentation(inputs)  # Apply random data augmentation</span><br><span class="line">x = keras.layers.experimental.preprocessing.Rescaling(1.0 / 255.0)(</span><br><span class="line">    x</span><br><span class="line">)  # Scale inputs to [0. 1]</span><br><span class="line"># The base model contains batchnorm layers. We want to keep them in inference mode</span><br><span class="line"># when we unfreeze the base model for fine-tuning, so we make sure that the</span><br><span class="line"># base_model is running in inference mode here.</span><br><span class="line">x = base_model(x, training=False)</span><br><span class="line">x = keras.layers.GlobalAveragePooling2D()(x)</span><br><span class="line">x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout</span><br><span class="line">outputs = keras.layers.Dense(1)(x)</span><br><span class="line">model = keras.Model(inputs, outputs)</span><br><span class="line"></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<p>这里是说迁移学习的时候，使用其他的模型，然后冻结之，再增加新的层进行训练。其中 <code>x = base_model(x, training=False)</code> 以及上面的注释引起了我的注意。在这里设置 <code>training=False</code> 是为了让 backbone 处于 inference 状态，这个状态主要是对 BN 起作用，那就是不更新 BN 的参数，即使 unfreeze 之后也不更新。</p>
<p>这个 inference 状态和 training 状态有什么用呢？我们知道，有一些层在训练和测试的时候表现是不同的，比如 BN 和 Dropout。其中 BN 在训练的时候使用 mini-batch 的数据来进行归一化，同时更新 moving mean 和 moving variance，在测试的时候就使用上面的 moving mean 和 moving variance 来进行归一化。这里的 training 是用来控制这些层的表现。</p>
<p>这个 training 出现在 keras Layer 和 Model 的 call 方法中:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def call(self, inputs, training=False):</span><br><span class="line">    pass</span><br></pre></td></tr></table></figure>
<p>当调用层的时候可以指定，比如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = BatchNormalization()(x, training=False)</span><br><span class="line">model = Xception(input_shape=(150, 150, 3))(x, training=True)</span><br></pre></td></tr></table></figure>
<p>本着想更深入地理解这个参数，就查了一下，结果发现了一个 <a href="https://github.com/keras-team/keras/issues/7177" target="_blank" rel="noopener">issue</a> 和一个 <a href="https://github.com/keras-team/keras/pull/9965" target="_blank" rel="noopener">PR</a>，这里面就描述了 keras BatchNormalization 在迁移学习中的坑。</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>大佬的<a href="http://blog.datumbox.com/the-batch-normalization-layer-of-keras-is-broken/" target="_blank" rel="noopener">博客</a>清楚地解释了问题，我这里再重新复述一下。</p>
<p>上面提到过了，BN 层在训练状态和测试状态下的表现是不同的，一个是使用 mini-batch 的数据，另一个是使用积累下来的 moving mean 和 moving variance。而在迁移学习中，我们通常会把 backbone 直接 freeze，训练新加的层，再 unfreeze backbone，然后一起训练。</p>
<p>不过如果不按照上面那样设置 <code>x = base_model(x, training=False)</code>，而是直接像下面这样使用已有的模型然后进行训练（实际上大多数数据增强都不会整合到 model 中，因为只有训练的时候才需要，也就是说，基本不会出现上面这种调用形式），那么就会出现问题。（以下代码来自提到的博客）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">from tensorflow.keras.datasets import cifar10</span><br><span class="line"> </span><br><span class="line">from tensorflow.keras.preprocessing.image import ImageDataGenerator</span><br><span class="line">from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input</span><br><span class="line">from tensorflow.keras.models import Model, load_model</span><br><span class="line">from tensorflow.keras.layers import Dense, Flatten</span><br><span class="line">from tensorflow.keras import backend as K</span><br><span class="line"></span><br><span class="line">seed = 42</span><br><span class="line">epochs = 10</span><br><span class="line">records_per_class = 100</span><br><span class="line"></span><br><span class="line"># We take only 2 classes from CIFAR10 and a very small sample to intentionally overfit the model.</span><br><span class="line"># We will also use the same data for train/test and expect that Keras will give the same accuracy.</span><br><span class="line">(x, y), _ = cifar10.load_data()</span><br><span class="line"> </span><br><span class="line">def filter_resize(category):</span><br><span class="line">   # We do the preprocessing here instead in the Generator to get around a bug on Keras 2.1.5.</span><br><span class="line">   return [preprocess_input(img) for img in x[y.flatten()==category][:records_per_class]]</span><br><span class="line"> </span><br><span class="line">x = np.stack(filter_resize(3)+filter_resize(5))</span><br><span class="line">records_per_class = x.shape[0] // 2</span><br><span class="line">y = np.array([[1,0]]*records_per_class + [[0,1]]*records_per_class)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"># We will use a pre-trained model and finetune the top layers.</span><br><span class="line">np.random.seed(seed)</span><br><span class="line">base_model = ResNet50(weights=&apos;imagenet&apos;, include_top=False, input_shape=(32, 32, 3))</span><br><span class="line">l = Flatten()(base_model.output)</span><br><span class="line">predictions = Dense(2, activation=&apos;softmax&apos;)(l)</span><br><span class="line">model = Model(inputs=base_model.input, outputs=predictions)</span><br><span class="line"> </span><br><span class="line"># for layer in model.layers[:140]:</span><br><span class="line">#    layer.trainable = False</span><br><span class="line"> </span><br><span class="line"># for layer in model.layers[140:]:</span><br><span class="line">#    layer.trainable = True</span><br><span class="line">base_model.trainable = False</span><br><span class="line"> </span><br><span class="line">model.compile(optimizer=&apos;sgd&apos;, loss=&apos;categorical_crossentropy&apos;, metrics=[&apos;accuracy&apos;])</span><br><span class="line">model.fit_generator(ImageDataGenerator().flow(x, y, seed=42), </span><br><span class="line">                    steps_per_epoch=7,</span><br><span class="line">                    epochs=epochs, </span><br><span class="line">                    validation_data=ImageDataGenerator().flow(x, y, seed=42),</span><br><span class="line">                    validation_steps=7</span><br><span class="line">                    )</span><br><span class="line"> </span><br><span class="line"># Store the model on disk</span><br><span class="line">model.save(&apos;tmp.h5&apos;)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"># In every test we will clear the session and reload the model to force Learning_Phase values to change.</span><br><span class="line">print(&apos;DYNAMIC LEARNING_PHASE&apos;)</span><br><span class="line">K.clear_session()</span><br><span class="line">model = load_model(&apos;tmp.h5&apos;)</span><br><span class="line"># This accuracy should match exactly the one of the validation set on the last iteration.</span><br><span class="line">print(model.evaluate(ImageDataGenerator().flow(x, y, seed=42), steps=7))</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">print(&apos;STATIC LEARNING_PHASE = 0&apos;)</span><br><span class="line">K.clear_session()</span><br><span class="line">K.set_learning_phase(0)</span><br><span class="line">model = load_model(&apos;tmp.h5&apos;)</span><br><span class="line"># Again the accuracy should match the above.</span><br><span class="line">print(model.evaluate(ImageDataGenerator().flow(x, y, seed=42), steps=7))</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">print(&apos;STATIC LEARNING_PHASE = 1&apos;)</span><br><span class="line">K.clear_session()</span><br><span class="line">K.set_learning_phase(1)</span><br><span class="line">model = load_model(&apos;tmp.h5&apos;)</span><br><span class="line"># The accuracy will be close to the one of the training set on the last iteration.</span><br><span class="line">print(model.evaluate(ImageDataGenerator().flow(x, y, seed=42), steps=7))</span><br></pre></td></tr></table></figure>
<p>运行上面的代码，其中训练集和验证集是同一个数据集。我们可以看到这两者的结果截然不同，训练的结果远好于验证的结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">Epoch 1/10</span><br><span class="line">6/7 [========================&gt;.....] - ETA: 0s - loss: 1.1314 - acc: 0.5298Epoch 1/10</span><br><span class="line">7/7 [==============================] - 3s 394ms/step - loss: 2.0678 - acc: 0.5700</span><br><span class="line">7/7 [==============================] - 5s 760ms/step - loss: 1.2129 - acc: 0.5300 - val_loss: 2.0678 - val_acc: 0.5700</span><br><span class="line">Epoch 2/10</span><br><span class="line">6/7 [========================&gt;.....] - ETA: 0s - loss: 0.9528 - acc: 0.6012Epoch 1/10</span><br><span class="line">7/7 [==============================] - 2s 265ms/step - loss: 1.4357 - acc: 0.5600</span><br><span class="line">7/7 [==============================] - 4s 558ms/step - loss: 0.8973 - acc: 0.6150 - val_loss: 1.4357 - val_acc: 0.5600</span><br><span class="line">Epoch 3/10</span><br><span class="line">6/7 [========================&gt;.....] - ETA: 0s - loss: 0.7655 - acc: 0.6667Epoch 1/10</span><br><span class="line">7/7 [==============================] - 2s 215ms/step - loss: 1.4113 - acc: 0.5950</span><br><span class="line">7/7 [==============================] - 4s 535ms/step - loss: 0.8119 - acc: 0.6550 - val_loss: 1.4113 - val_acc: 0.5950</span><br><span class="line">Epoch 4/10</span><br><span class="line">6/7 [========================&gt;.....] - ETA: 0s - loss: 0.7548 - acc: 0.7440Epoch 1/10</span><br><span class="line">7/7 [==============================] - 1s 151ms/step - loss: 1.9380 - acc: 0.5800</span><br><span class="line">7/7 [==============================] - 2s 331ms/step - loss: 0.7230 - acc: 0.7350 - val_loss: 1.9380 - val_acc: 0.5800</span><br><span class="line">Epoch 5/10</span><br><span class="line">6/7 [========================&gt;.....] - ETA: 0s - loss: 0.5866 - acc: 0.7202Epoch 1/10</span><br><span class="line">7/7 [==============================] - 1s 150ms/step - loss: 1.8147 - acc: 0.6000</span><br><span class="line">7/7 [==============================] - 2s 322ms/step - loss: 0.5802 - acc: 0.7150 - val_loss: 1.8147 - val_acc: 0.6000</span><br><span class="line">Epoch 6/10</span><br><span class="line">6/7 [========================&gt;.....] - ETA: 0s - loss: 0.3704 - acc: 0.8095Epoch 1/10</span><br><span class="line">7/7 [==============================] - 1s 151ms/step - loss: 1.5603 - acc: 0.6450</span><br><span class="line">7/7 [==============================] - 2s 321ms/step - loss: 0.3881 - acc: 0.7950 - val_loss: 1.5603 - val_acc: 0.6450</span><br><span class="line">Epoch 7/10</span><br><span class="line">6/7 [========================&gt;.....] - ETA: 0s - loss: 0.5056 - acc: 0.7738Epoch 1/10</span><br><span class="line">7/7 [==============================] - 1s 151ms/step - loss: 1.9539 - acc: 0.6250</span><br><span class="line">7/7 [==============================] - 2s 322ms/step - loss: 0.5618 - acc: 0.7400 - val_loss: 1.9539 - val_acc: 0.6250</span><br><span class="line">Epoch 8/10</span><br><span class="line">6/7 [========================&gt;.....] - ETA: 0s - loss: 0.5849 - acc: 0.7976Epoch 1/10</span><br><span class="line">7/7 [==============================] - 1s 153ms/step - loss: 1.4035 - acc: 0.6600</span><br><span class="line">7/7 [==============================] - 2s 323ms/step - loss: 0.5465 - acc: 0.8050 - val_loss: 1.4035 - val_acc: 0.6600</span><br><span class="line">Epoch 9/10</span><br><span class="line">6/7 [========================&gt;.....] - ETA: 0s - loss: 0.4055 - acc: 0.8512Epoch 1/10</span><br><span class="line">7/7 [==============================] - 1s 147ms/step - loss: 1.0538 - acc: 0.6650</span><br><span class="line">7/7 [==============================] - 2s 322ms/step - loss: 0.3984 - acc: 0.8450 - val_loss: 1.0538 - val_acc: 0.6650</span><br><span class="line">Epoch 10/10</span><br><span class="line">6/7 [========================&gt;.....] - ETA: 0s - loss: 0.4082 - acc: 0.8452Epoch 1/10</span><br><span class="line">7/7 [==============================] - 1s 152ms/step - loss: 1.8019 - acc: 0.6000</span><br><span class="line">7/7 [==============================] - 2s 322ms/step - loss: 0.4177 - acc: 0.8400 - val_loss: 1.8019 - val_acc: 0.6000</span><br></pre></td></tr></table></figure>
<p>再看看最后输出的结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">DYNAMIC LEARNING_PHASE</span><br><span class="line">7/7 [==============================] - 2s 256ms/step - loss: 2.0028 - acc: 0.6000</span><br><span class="line">[2.002779943602426, 0.6]</span><br><span class="line">STATIC LEARNING_PHASE = 0</span><br><span class="line">7/7 [==============================] - 1s 204ms/step - loss: 2.0028 - acc: 0.6000</span><br><span class="line">[2.002779943602426, 0.6]</span><br><span class="line">STATIC LEARNING_PHASE = 1</span><br><span class="line">7/7 [==============================] - 1s 212ms/step - loss: 0.3017 - acc: 0.8650</span><br><span class="line">[0.30170093051024843, 0.865]</span><br></pre></td></tr></table></figure>
<p>第一个结果是 keras 直接自动设置运行状态，第二个结果是手动设定运行状态为测试状态，第三个结果是手动设定运行结果为训练状态。可以看出来，keras 在测试的时候自动设置为测试状态，但这个时候结果出现了明显的下滑，而设置为训练状态的时候结果很正常。</p>
<p>其原因在于，在训练的时候，虽然 freeze 了 BN 的参数，但是 keras 仍然认为 BN 是在训练状态，因此会使用 mini-batch 的数据来标准化。也就是说，这时候后层网络学习到的是 mini-batch（训练数据集） 的分布。但是当测试的时候，BN 使用 moving mean 和 moving variance 来标准化，这两个参数由于没更新，是来自于原来数据集的。因为二者分布偏差很大，因此在测试模式下得到的结果非常差。</p>
<p>这个 PR 的改进就是当 freeze BN 的时候，就让 BN 层按照测试状态来进行，而不使用 mini-batch 的数据。</p>
<h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p>看了半天，keras 官方好像没有改这个 bug，但是 TF 2.0 版本已经修改了这个 bug 了，以下是在 TF 2.0 下运行同样代码的结果，可以看到训练和验证的结果是相差不大的。另外值得一提的是，改进过后收敛速度明显快了很多，loss 从 0.3 直接降到了 0.01。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">Epoch 1/10</span><br><span class="line">7/7 [==============================] - 2s 332ms/step - loss: 7.3916 - accuracy: 0.4700 - val_loss: 3.1501 - val_accuracy: 0.6500</span><br><span class="line">Epoch 2/10</span><br><span class="line">7/7 [==============================] - 1s 207ms/step - loss: 2.8816 - accuracy: 0.6700 - val_loss: 8.4492 - val_accuracy: 0.5100</span><br><span class="line">Epoch 3/10</span><br><span class="line">7/7 [==============================] - 1s 206ms/step - loss: 4.1846 - accuracy: 0.6750 - val_loss: 11.3409 - val_accuracy: 0.5600</span><br><span class="line">Epoch 4/10</span><br><span class="line">7/7 [==============================] - 1s 204ms/step - loss: 3.4036 - accuracy: 0.7800 - val_loss: 0.4167 - val_accuracy: 0.8650</span><br><span class="line">Epoch 5/10</span><br><span class="line">7/7 [==============================] - 1s 210ms/step - loss: 0.8244 - accuracy: 0.8150 - val_loss: 9.1833 - val_accuracy: 0.5400</span><br><span class="line">Epoch 6/10</span><br><span class="line">7/7 [==============================] - 1s 210ms/step - loss: 2.3888 - accuracy: 0.7600 - val_loss: 0.7993 - val_accuracy: 0.8100</span><br><span class="line">Epoch 7/10</span><br><span class="line">7/7 [==============================] - 1s 207ms/step - loss: 0.5801 - accuracy: 0.8600 - val_loss: 2.9707 - val_accuracy: 0.6700</span><br><span class="line">Epoch 8/10</span><br><span class="line">7/7 [==============================] - 1s 205ms/step - loss: 4.2250 - accuracy: 0.6050 - val_loss: 1.0646 - val_accuracy: 0.8500</span><br><span class="line">Epoch 9/10</span><br><span class="line">7/7 [==============================] - 1s 206ms/step - loss: 0.4886 - accuracy: 0.8900 - val_loss: 0.0866 - val_accuracy: 0.9800</span><br><span class="line">Epoch 10/10</span><br><span class="line">7/7 [==============================] - 1s 206ms/step - loss: 0.0969 - accuracy: 0.9700 - val_loss: 0.0109 - val_accuracy: 1.0000</span><br><span class="line">DYNAMIC LEARNING_PHASE</span><br><span class="line">7/7 [==============================] - 1s 95ms/step - loss: 0.0118 - accuracy: 1.0000</span><br><span class="line">[0.011801988817751408, 1.0]</span><br><span class="line">STATIC LEARNING_PHASE = 0</span><br><span class="line">7/7 [==============================] - 1s 94ms/step - loss: 0.0118 - accuracy: 1.0000</span><br><span class="line">[0.011801988817751408, 1.0]</span><br><span class="line">STATIC LEARNING_PHASE = 1</span><br><span class="line">7/7 [==============================] - 1s 92ms/step - loss: 0.0118 - accuracy: 1.0000</span><br><span class="line">[0.011801988817751408, 1.0]</span><br></pre></td></tr></table></figure>
<h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>这种问题真的是防不胜防，毕竟很少人会去训练集和验证集使用同一个数据集，训练集和验证集相差大大家也只会怪罪到过拟合头上去。所以平常对于一些关键的东西还是得把他摸透，并且要多看官方文档，遇到问题多思考（所以深度学习就是这一点不好，出了问题有太多可能的原因，很难定位到问题所在）。</p>
<p>P.S. 今天在训练 SOD 的时候并没有出现这个问题，其原因可能在于：</p>
<ul>
<li>我的模型在 backbone 之外增加了很多的参数，减弱了 BN 的影响，因此结果是差不多的。（回头再多做一点实验）</li>
<li>DUTS 的数据本来就来自 ImageNet Detection，因此分布非常接近。</li>
</ul>

	
	
	
	
</div>
				
				

                <!-- Post Comments -->
                
                    


    <!-- 使用 DISQUS -->
	<div id="disqus-comment">
		<div id="disqus_thread"></div>
<script>
	var disqus_config = function () {
		this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
		this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
	};

	(function() { // DON'T EDIT BELOW THIS LINE
		var d = document, s = d.createElement('script');
		s.src = '//patrickcty.disqus.com/embed.js';
		s.setAttribute('data-timestamp', +new Date());
		(d.head || d.body).appendChild(s);
	})();
</script>
	</div>
	<style>
		#disqus-comment{
			background-color:#eee;
			padding:2pc;
		}
	</style>

                
            </div>

            <!-- Post Prev & Next Nav -->
            <nav class="material-nav mdl-color-text--grey-50 mdl-cell mdl-cell--12-col">
    
    <!-- Prev Nav -->
    
        <a href="/2020/10/07/keras自定义训练流程/" id="post_nav-newer" class="prev-content">
            <button class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon mdl-color--white mdl-color-text--grey-900" role="presentation">
                <i class="material-icons">arrow_back</i>
            </button>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            新篇
        </a>
    

    <!-- Section Spacer -->
    <div class="section-spacer"></div>

    <!-- Next Nav -->
    
        <a href="/2020/04/11/keras处理任意大小输入/" id="post_nav-older" class="next-content">
            旧篇
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <button class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon mdl-color--white mdl-color-text--grey-900" role="presentation">
                <i class="material-icons">arrow_forward</i>
            </button>
        </a>
    
</nav>
        </div>
    </div>

				
				
					<!-- Overlay For Active Sidebar -->
<div class="sidebar-overlay "></div>

<!-- Material sidebar -->
<aside id="sidebar" class="sidebar sidebar-colored  sidebar-fixed-left" role="navigation">
	<div id="sidebar-main">
	    <!-- Sidebar Header -->
		<div class="sidebar-header header-cover" style="background-image: url(https://static.jnugeek.cn/img/sidebar.jpg);">
    <!-- Top bar -->
    <div class="top-bar"></div>

    <!-- Sidebar toggle button -->
    <button type="button" class="sidebar-toggle mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon" style="display: initial;" data-upgraded=",MaterialButton,MaterialRipple">
    <i class="material-icons">clear_all</i>
    <span class="mdl-button__ripple-container"><span class="mdl-ripple"></span></span></button>

    <!-- Sidebar Avatar -->
    <div class="sidebar-image">
        <img src="https://static.jnugeek.cn/img/avatar.jpg" alt="Patrick's avatar">
    </div>

    <!-- Sidebar Email -->
    <a data-toggle="dropdown" class="sidebar-brand" href="#settings-dropdown">
        chengtiyanyang@gmail.com
        <b class="caret"></b>
    </a>
</div>

		<!-- Sidebar Navigation  -->
		<ul class="nav sidebar-nav">
    <!-- User dropdown  -->
    <li class="dropdown">
        <ul id="settings-dropdown" class="dropdown-menu">
			
                <li>
                    <a href="https://www.jnugeek.cn" target="_blank" title="网研官网">
						<i class="material-icons sidebar-material-icons sidebar-indent-left1pc-element">undefined</i>
                        网研官网
                    </a>
                </li>
            
        </ul>
    </li>

    <!-- Homepage -->
    <li id="sidebar-first-li">
        <a href="/" target="_self">
            <i class="material-icons sidebar-material-icons">home</i>
             主页
        </a>
    </li>

    <!-- I'm Feeling Lucky -->
<!--
    <li class="dropdown">
        <a href="" target="_self">
            <i class="material-icons sidebar-material-icons">explore</i>
             sidebar.imlucky
        </a>
    </li>
-->

	
    <!-- Archives  -->
    <li class="dropdown">
        <a href="#" class="ripple-effect dropdown-toggle" data-toggle="dropdown">
            <i class="material-icons sidebar-material-icons">inbox</i>
             归档
            <b class="caret"></b>
        </a>
        <ul class="dropdown-menu">
            <li>
            <a class="sidebar_archives-link" href="/archives/2021/05/">五月 2021<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2021/02/">二月 2021<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2021/01/">一月 2021<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2020/11/">十一月 2020<span class="sidebar_archives-count">3</span></a></li><li><a class="sidebar_archives-link" href="/archives/2020/10/">十月 2020<span class="sidebar_archives-count">4</span></a></li><li><a class="sidebar_archives-link" href="/archives/2020/05/">五月 2020<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2020/04/">四月 2020<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2020/03/">三月 2020<span class="sidebar_archives-count">3</span></a></li><li><a class="sidebar_archives-link" href="/archives/2020/02/">二月 2020<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2020/01/">一月 2020<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2019/12/">十二月 2019<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2019/11/">十一月 2019<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2019/08/">八月 2019<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2019/05/">五月 2019<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2019/04/">四月 2019<span class="sidebar_archives-count">3</span></a></li><li><a class="sidebar_archives-link" href="/archives/2019/03/">三月 2019<span class="sidebar_archives-count">20</span></a></li><li><a class="sidebar_archives-link" href="/archives/2019/02/">二月 2019<span class="sidebar_archives-count">5</span></a></li><li><a class="sidebar_archives-link" href="/archives/2019/01/">一月 2019<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/06/">六月 2018<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/05/">五月 2018<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/04/">四月 2018<span class="sidebar_archives-count">3</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/03/">三月 2018<span class="sidebar_archives-count">3</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/01/">一月 2018<span class="sidebar_archives-count">7</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/12/">十二月 2017<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/11/">十一月 2017<span class="sidebar_archives-count">4</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/09/">九月 2017<span class="sidebar_archives-count">6</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/08/">八月 2017<span class="sidebar_archives-count">8</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/07/">七月 2017<span class="sidebar_archives-count">4</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/06/">六月 2017<span class="sidebar_archives-count">8</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/05/">五月 2017<span class="sidebar_archives-count">5</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/04/">四月 2017<span class="sidebar_archives-count">4</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/03/">三月 2017<span class="sidebar_archives-count">10</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/02/">二月 2017<span class="sidebar_archives-count">59</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/01/">一月 2017<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2016/11/">十一月 2016<span class="sidebar_archives-count">2</span></a>
        </ul>
    </li>

    <!-- Divider -->
    <li class="divider"></li>


    <!-- Pages  -->
	
		<li>
			<a href="/categories/ACM/" title="ACM">
				ACM
			</a>
		</li>
	
		<li>
			<a href="/categories/Fronted/" title="Fronted">
				Fronted
			</a>
		</li>
	
		<li>
			<a href="/categories/Python/" title="Python">
				Python
			</a>
		</li>
	
		<li>
			<a href="/categories/Web/" title="Web">
				Web
			</a>
		</li>
	
		<li>
			<a href="/categories/爬虫/" title="爬虫">
				爬虫
			</a>
		</li>
	
		<li>
			<a href="/categories/日记/" title="日记">
				日记
			</a>
		</li>
	
		<li>
			<a href="/categories/电影/" title="电影">
				电影
			</a>
		</li>
	
		<li>
			<a href="/categories/其他/" title="其他">
				其他
			</a>
		</li>
	
		<li>
			<a href="/about/" title="关于我">
				关于我
			</a>
		</li>
	
		<li>
			<a href="/links/" title="友情链接">
				友情链接
			</a>
		</li>
	

    <!-- Article Numebr  -->
    <li>
        <a href="/archives">
             文章总数
             <span class="sidebar-badge">184</span>
        </a>
    </li>
</ul>

		<!-- Sidebar Divider -->
		<div class="sidebar-divider"></div>

		<!-- Sidebar Footer -->
		<!-- 
I'm glad you use this theme, the development is no so easy, I hope you can keep the copyright, I will thank you so much.
If you still want to delete the copyrights, could you still retain the first one? Which namely "Theme Material"
It will not impact the appearance and can give developers a lot of support :)

很高兴您使用并喜欢该主题，开发不易 十分谢谢与希望您可以保留一下版权声明。
如果您仍然想删除的话 能否只保留第一项呢？即 "Theme Material"
它不会影响美观并可以给开发者很大的支持。 :) 
-->

<!-- Theme Material -->
<a href="https://github.com/viosey/hexo-theme-material"  class="sidebar-footer-text-a" target="_blank">
	<div class="sidebar-text mdl-button mdl-js-button mdl-js-ripple-effect sidebar-footer-text-div" data-upgraded=",MaterialButton,MaterialRipple">
		主题 - Material
		<span class="sidebar-badge badge-circle">i</span>
	</div>
</a>

<!-- Help & Support -->
<!--
<a href="mailto:hiviosey@gmail.com" class="sidebar-footer-text-a">
    <div class="sidebar-text mdl-button mdl-js-button mdl-js-ripple-effect sidebar-footer-text-div" data-upgraded=",MaterialButton,MaterialRipple">
		sidebar.help
		<span class="mdl-button__ripple-container">
			<span class="mdl-ripple"></span>
		</span>
	</div>
</a>
-->

<!-- Feedback -->
<!--
<a href="https://github.com/viosey/hexo-theme-material/issues" target="_blank" class="sidebar-footer-text-a">
    <div class="sidebar-text mdl-button mdl-js-button mdl-js-ripple-effect sidebar-footer-text-div" data-upgraded=",MaterialButton,MaterialRipple">
         sidebar.feedback
                    <span class="mdl-button__ripple-container"><span class="mdl-ripple"></span></span></div>
</a>
-->

<!-- Abount Theme -->
<!--
<a href="https://blog.viosey.com/index.php/Material.html" target="_blank" class="sidebar-footer-text-a">
    <div class="sidebar-text mdl-button mdl-js-button mdl-js-ripple-effect sidebar-footer-text-div" data-upgraded=",MaterialButton,MaterialRipple">
         sidebar.about_theme
        <span class="mdl-button__ripple-container"><span class="mdl-ripple"></span></span></div>
</a>-->

	</div>
    
    <!-- Sidebar Sponsor -->
    


</aside>

				
				
				
					<!-- Footer Top Button -->
					<div class="toTop-wrap">
    <a href="#top" class="toTop">
        <i class="material-icons footer_top-i">expand_less</i>
    </a>
</div>
				
				
				<!--Footer-->
<footer class="mdl-mini-footer" id="bottom">
	
	
		<!-- Paradox Footer Left Section -->
		<div class="mdl-mini-footer--left-section sns-list">
    <!-- Twitter -->
    
    <a href="https://twitter.com/" target="view_window"><button class="mdl-mini-footer--social-btn social-btn" style="background-image: url(https://static.jnugeek.cn/img/footer/footer_ico-twitter.png);">
        <span class="visuallyhidden">Twitter</span>
    </button></a>
    
    
    <!-- Facebook -->
    
    
    
    <!-- Google + -->
    
    
    
    <!-- Weibo -->
    
    <a href="http://weibo.com/2867516010/profile?rightmod=1&amp;wvr=6&amp;mod=personinfo&amp;is_all=1" target="view_window"><button class="mdl-mini-footer--social-btn social-btn" style="background-image: url(https://static.jnugeek.cn/img/footer/footer_ico-weibo.png);">
        <span class="visuallyhidden">Weibo</span>
    </button></a>
    
    
    <!-- Instagram -->
    
    <a href="https://www.instagram.com/patrickcty/" target="view_window"><button class="mdl-mini-footer--social-btn social-btn" style="background-image: url(https://static.jnugeek.cn/img/footer/footer_ico-instagram.png);">
        <span class="visuallyhidden">Instagram</span>
    </button></a>
    
    
    <!-- Tumblr -->
    
    
    
    <!-- Github -->
    
    <a href="https://github.com/Patrickctyyx" target="view_window"><button class="mdl-mini-footer--social-btn social-btn" style="background-image: url(https://static.jnugeek.cn/img/footer/footer_ico-github.png);">
        <span class="visuallyhidden">Github</span>
    </button></a>
    
</div>


		<!--Copyright-->
		<div id="copyright">Copyright&nbsp;©&nbsp;<script type="text/javascript">var fd = new Date();document.write(fd.getFullYear());</script>&nbsp;Patrick's Space</div>

		<!-- Paradox Footer Right Section -->

		<!-- 
		I'm glad you use this theme, the development is no so easy, I hope you can keep the copyright.
		It will not impact the appearance and can give developers a lot of support :)

		很高兴您使用该主题，开发不易，希望您可以保留一下版权声明。
		它不会影响美观并可以给开发者很大的支持。 :) 
		-->

		<div class="mdl-mini-footer--right-section">
			<div>
				<div class="footer-develop-div">Powered by <a href="https://hexo.io" target="_blank" class="footer-develop-a">Hexo</a></div>
				<div class="footer-develop-div">Theme - <a href="https://github.com/viosey/hexo-theme-material" target="_blank" class="footer-develop-a">Material</a></div>
			</div>
		</div>
	
    
</footer>
                
				<!-- Import File -->
<script src="/js/highlight.min.js"></script>
<script src="/js/js.min.js"></script>
<script src="/js/nprogress.js"></script>

<script type="text/javascript">
    NProgress.configure({
        showSpinner: true
    });
    NProgress.start();
    
    $('#nprogress .bar').css({
        'background': '#FF4081'
    });
    $('#nprogress .peg').css({
        'box-shadow': '0 0 10px #FF4081, 0 0 15px #FF4081'
    });
    $('#nprogress .spinner-icon').css({
        'border-top-color': '#FF4081',
        'border-left-color': '#FF4081'
    });
    
    setTimeout(function() {
        NProgress.done();
        $('.fade').removeClass('out');
    }, 800);
</script>






    <!-- Busuanzi -->
    <script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>





    <!-- 使用 DISQUS js 代码 -->
	<script id="dsq-count-scr" src="//patrickcty.disqus.com/count.js" async></script>


<!-- Swiftye -->


<!-- Local Search-->

	<script>
	var searchFunc = function(path, search_id, content_id) {
    'use strict';
    $.ajax({
        url: path,
        dataType: "xml",
        success: function( xmlResponse ) {
            // get the contents from search data
            var datas = $( "entry", xmlResponse ).map(function() {
                return {
                    title: $( "title", this ).text(),
                    content: $("content",this).text(),
                    url: $( "url" , this).text()
                };
            }).get();
            var $input = document.getElementById(search_id);
            var $resultContent = document.getElementById(content_id);
            $input.addEventListener('input', function(){
                var str='<ul class=\"search-result-list\">';                
                var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                $resultContent.innerHTML = "";
                if (this.value.trim().length <= 0) {
                    return;
                }
                // perform local searching
                datas.forEach(function(data) {
                    var isMatch = true;
                    var content_index = [];
                    var data_title = data.title.trim().toLowerCase();
                    var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                    var data_url = data.url;
                    var index_title = -1;
                    var index_content = -1;
                    var first_occur = -1;
                    // only match artiles with not empty titles and contents
                    if(data_title != '' && data_content != '') {
                        keywords.forEach(function(keyword, i) {
                            index_title = data_title.indexOf(keyword);
                            index_content = data_content.indexOf(keyword);
                            if( index_title < 0 && index_content < 0 ){
                                isMatch = false;
                            } else {
                                if (index_content < 0) {
                                    index_content = 0;
                                }
                                if (i == 0) {
                                    first_occur = index_content;
                                }
                            }
                        });
                    }
                    // show search results
                    if (isMatch) {
                        str += "<li><a href='"+ data_url +"' class='search-result-title' target='_blank'>"+ data_title;
                        var content = data.content.trim().replace(/<[^>]+>/g,"");
                        if (first_occur >= 0) {
                            // cut out characters
                            var start = first_occur - 6;
                            var end = first_occur + 6;
                            if(start < 0){
                                start = 0;
                            }
                            if(start == 0){
                                end = 10;
                            }
                            if(end > content.length){
                                end = content.length;
                            }
                            var match_content = content.substr(start, end); 
                            // highlight all keywords
                            keywords.forEach(function(keyword){
                                var regS = new RegExp(keyword, "gi");
                                match_content = match_content.replace(regS, "<em class=\"search-keyword\">"+keyword+"</em>");
                            })
                            str += "<p class=\"search-result\">" + match_content +"...</p>" +"</a>";
                        }
                    }
                })
                $resultContent.innerHTML = str;
            })
        }
    })
}
</script>

	<script>
        var inputArea = document.querySelector("#search");
        var getSearchFile = function(){
            var path = "search.xml";
            searchFunc(path, 'search', 'local-search-result');
        }

        inputArea.onfocus = function(){ getSearchFile() }
	</script>


<!-- Window Load-->
<script>
    $(window).load(function() {
        // Post_Toc parent position fixed
        $(".post-toc-wrap").parent(".mdl-menu__container").css("position", "fixed");
    });
</script>

<!-- MathJax Load-->

            </main>
        </div>
		
    </body>
		
	
</html>
