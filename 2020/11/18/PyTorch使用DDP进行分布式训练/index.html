<!DOCTYPE html>
<html>
    <head><meta name="generator" content="Hexo 3.9.0">
    <!-- Title -->
    
    <title>
        PyTorch使用DDP进行分布式训练 | Patrick&#39;s Space
    </title>
    
    <!-- Favicons -->
    <link rel="icon shortcut" type="image/ico" href="https://static.jnugeek.cn/img/favion.ico">
    <link rel="icon" sizes="192x192" href="https://static.jnugeek.cn/img/favicon.ico">
    <link rel="apple-touch-icon" href="https://static.jnugeek.cn/img/favicon.ico">
    
    <!-- Meta & INfo -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#0097A7">
    <meta name="author" content="Patrick">
    <meta name="description" content="PatrickCty">
    <meta name="keywords" content="Patrick&#39;s Space">
    
    <!--iOS -->
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-title" content="Title">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="480">
    
    <!-- Add to homescreen for Chrome on Android -->
    <meta name="mobile-web-app-capable" content="yes">
    
    <!-- Add to homescreen for Safari on iOS -->
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="apple-mobile-web-app-title" content="Patrick&#39;s Space">
    
    <!-- The Open Graph protocol -->
    <meta property="og:url" content="https://blog.patrickcty.cc">
    <meta property="og:type" content="blog">
    <meta property="og:title" content="PyTorch使用DDP进行分布式训练 | Patrick&#39;s Space">
    <meta property="og:description" content="PatrickCty">
    
     <!--[if lte IE 9]>
        <link rel="stylesheet" href="/css/ie-blocker.css">
        
        
            <script src="/js/ie-blocker.zhCN.js"></script>
        
    <![endif]-->
    
    <!-- Import CSS -->
    <link rel="stylesheet" href="/css/material.min.css">
    <link rel="stylesheet" href="/css/style.min.css">
    <!-- Config CSS -->


<!-- Other Styles -->
<style>
	body, html{
		font-family: Roboto, "Helvetica Neue", Helvetica, "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei", "微软雅黑", Arial, sans-serif;
	}
	
    a{
        color: #00838F
    }
    
    .mdl-card__media,
    #search-label,
    #search-form-label:after,
    #scheme-Paradox .hot_tags-count,
    #scheme-Paradox .sidebar_archives-count,
    #scheme-Paradox .sidebar-colored .sidebar-header,
    #scheme-Paradox .sidebar-colored .sidebar-badge{
        background-color: #0097A7 !important
    }
    
	/* Sidebar User Drop Down Menu Text Color */
	#scheme-Paradox .sidebar-colored .sidebar-nav>.dropdown>.dropdown-menu>li>a:hover,
    #scheme-Paradox .sidebar-colored .sidebar-nav>.dropdown>.dropdown-menu>li>a:focus{
        color: #0097A7 !important
    }
    
    #post_entry-right-info,
    .sidebar-colored .sidebar-nav li:hover > a,
    .sidebar-colored .sidebar-nav li:hover > a i,
    .sidebar-colored .sidebar-nav li > a:hover,
    .sidebar-colored .sidebar-nav li > a:hover i,
    .sidebar-colored .sidebar-nav li > a:focus i,
    .sidebar-colored .sidebar-nav > .open > a,
    .sidebar-colored .sidebar-nav > .open > a:hover,
    .sidebar-colored .sidebar-nav > .open > a:focus,
    #ds-reset #ds-ctx .ds-ctx-entry .ds-ctx-head a{
        color: #0097A7 !important
    }
    
    .toTop{
        background: #757575 !important
    }
		
	.material-layout .material-post>.material-nav,
	.material-layout .material-index>.material-nav,
	.material-nav a{
		color: #757575;
	}
		
	#scheme-Paradox .MD-burger-layer {
		background-color: #757575;
	}

	#scheme-Paradox #post-toc-trigger-btn{
		color: #757575;
	}
	
	.post-toc a:hover{
		color: #00838F;
		text-decoration: underline;
	}
</style>


<!-- Theme Background Related-->

    <style>
        body{
            background-color: #F5F5F5
        }
		
		/* blog_info bottom background */
        #scheme-Paradox .material-layout .something-else .mdl-card__supporting-text{
            background-color: #fff;
        }
    </style>




<!-- Fade Effect -->

    <style>
        .fade {
            transition: all 800ms linear;
            -webkit-transform: translate3d(0,0,0);
            -moz-transform: translate3d(0,0,0);
            -ms-transform: translate3d(0,0,0);
            -o-transform: translate3d(0,0,0);
            transform: translate3d(0,0,0);
            opacity: 1;
        }

        .fade.out{
            opacity: 0;
        }
    </style>

	<script src="/js/jquery.min.js"></script>
	
	<link rel="stylesheet" href="/css/highlight/solarized-white.css">
	
	<!-- UC Browser Compatible-->
	<script>
		var agent = navigator.userAgent.toLowerCase();
		if(agent.indexOf('ucbrowser')>0) {
			document.write('<link rel="stylesheet" href="/css/uc.css">');
		   alert('由于 UC 浏览器使用极旧的内核，而本网站使用了一些新的特性。\n为了您能更好的浏览，推荐使用 Chrome 或 Firefox 浏览器。');
		}
	</script>
    
    <!-- Custom Head -->
    
        
			<!-- Name -->
			<script type="text/javascript" src="/js/love.js"></script>
        
    
</head>
	
	

    <body id="scheme-Paradox">

		
        <div class="material-layout  mdl-js-layout has-drawer is-upgraded">
				
			
			
            <!-- Main Container -->
            <main class="material-layout__content" id="main">
				
                <!-- Top Anchor -->
                <div id="top"></div>
				
				
                <!-- Hamburger Button -->
                <button class="MD-burger-icon sidebar-toggle">
                    <span class="MD-burger-layer"></span>
                </button>
				
				
                <!-- Post TOC -->

    
	<!-- Back Button -->
<!--
	<div class="material-back" id="backhome-div" tabindex="0">
		<a class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon" href="#" onclick="window.history.back();return false;" target="_self" role="button" data-upgraded=",MaterialButton,MaterialRipple">
			<i class="material-icons" role="presentation">arrow_back</i>
			<span class="mdl-button__ripple-container">
				<span class="mdl-ripple"></span>
			</span>
		</a>
	</div>			
-->
	<!-- Left aligned menu below button -->
	<button id="post-toc-trigger-btn"
			class="mdl-button mdl-js-button mdl-button--icon">
	  <i class="material-icons">format_list_numbered</i>
	</button>

	<ul class="post-toc-wrap mdl-menu mdl-menu--bottom-left mdl-js-menu mdl-js-ripple-effect"
		for="post-toc-trigger-btn">
			
			<ol class="post-toc"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#原理"><span class="post-toc-number">1.</span> <span class="post-toc-text">原理</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#启动"><span class="post-toc-number">2.</span> <span class="post-toc-text">启动</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#准备阶段"><span class="post-toc-number">3.</span> <span class="post-toc-text">准备阶段</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#初始化分布式环境"><span class="post-toc-number">4.</span> <span class="post-toc-text">初始化分布式环境</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#构建分布式模型"><span class="post-toc-number">5.</span> <span class="post-toc-text">构建分布式模型</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#获得分布式-data-loader"><span class="post-toc-number">6.</span> <span class="post-toc-text">获得分布式 data loader</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#获得总的-loss"><span class="post-toc-number">7.</span> <span class="post-toc-text">获得总的 loss</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#保存检查点"><span class="post-toc-number">8.</span> <span class="post-toc-text">保存检查点</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#测试阶段"><span class="post-toc-number">9.</span> <span class="post-toc-text">测试阶段</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#打印-log"><span class="post-toc-number">10.</span> <span class="post-toc-text">打印 log</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#遇到的坑"><span class="post-toc-number">11.</span> <span class="post-toc-text">遇到的坑</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#原因"><span class="post-toc-number">11.1.</span> <span class="post-toc-text">原因</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#解决方法"><span class="post-toc-number">11.2.</span> <span class="post-toc-text">解决方法</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#参考资料"><span class="post-toc-number">12.</span> <span class="post-toc-text">参考资料</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#总的代码"><span class="post-toc-number">13.</span> <span class="post-toc-text">总的代码</span></a></li></ol>
		
<!--			<li class="mdl-menu__item">Some Action</li>-->
	</ul>



<!-- Layouts -->

    <!-- Post Module -->
    <div class="material-post_container">
		
        <div class="material-post mdl-grid">
            <div class="mdl-card mdl-shadow--4dp mdl-cell mdl-cell--12-col">

                <!-- Post Header(Thumbnail & Title) -->
                
	<!-- Paradox Post Header -->
	
		
			<!-- Random Thumbnail -->
			<div class="post_thumbnail-random mdl-card__media mdl-color-text--grey-50">
				<script>
    
    var randomNum;
    randomNum = Math.floor(Math.random() * 12 + 1);
    
    $(".post_thumbnail-random").css('background-image', 'url(' + 'https://static.jnugeek.cn/img/my_pic/' + randomNum + '.png' + ')');
    
</script>

		
	
        <p class="article-headline-p">
            PyTorch使用DDP进行分布式训练
        </p>
    </div>

	

				
				
					<!-- Paradox Post Info -->
					<div class="mdl-color-text--grey-700 mdl-card__supporting-text meta">
    
    <!-- Author Avatar -->
    <div id="author-avatar">
        <img src="https://static.jnugeek.cn/img/avatar.jpg" width="44px" height="44px" alt="Author Avatar"/>
    </div>
    <!-- Author Name & Date -->
    <div>
        <strong>Patrick</strong>
        <span>11月 18, 2020</span>
    </div>
    
    <div class="section-spacer"></div>
	
    <!-- Favorite -->
<!--
    <button id="article-functions-like-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon btn-like">
        <i class="material-icons" role="presentation">favorite</i>
        <span class="visuallyhidden">favorites</span>
    </button>
-->
    
    <!-- Tags (bookmark) -->
    <button id="article-functions-viewtags-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon">
        <i class="material-icons" role="presentation">bookmark</i>
        <span class="visuallyhidden">bookmark</span>
    </button>
    <ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-functions-viewtags-button">
        <li class="mdl-menu__item">
        <a class="post_tag-link" href="/tags/DDP/">DDP</a></li><li class="mdl-menu__item"><a class="post_tag-link" href="/tags/PyTorch/">PyTorch</a></li><li class="mdl-menu__item"><a class="post_tag-link" href="/tags/分布式训练/">分布式训练</a>
    </ul>
    
    <!-- Share -->
    <button id="article-fuctions-share-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon">
    <i class="material-icons" role="presentation">share</i>
    <span class="visuallyhidden">share</span>
</button>
<ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-fuctions-share-button">
    
    
    
    
    <!-- Busuanzi Views -->
    <a class="post_share-link" href="#">
        <li class="mdl-menu__item">
            <span id="busuanzi_container_page_pv">
                <span id="busuanzi_value_page_pv"></span>&nbsp;浏览量
            </span>
        </li>
    </a>
    
    
    <!-- Share Twitter -->
    <a class="post_share-link" href="https://twitter.com/intent/tweet?text=PyTorch使用DDP进行分布式训练&url=https://blog.patrickcty.cc//2020/11/18/PyTorch使用DDP进行分布式训练/index.html&via=Patrick" target="_blank">
        <li class="mdl-menu__item">
            分享到 Twitter
        </li>
    </a>
    
    <!-- Share Google+ -->
    <a class="post_share-link" href="https://plus.google.com/share?url=https://blog.patrickcty.cc//2020/11/18/PyTorch使用DDP进行分布式训练/index.html" target="_blank">
        <li class="mdl-menu__item">
            分享到 Google+
        </li>
    </a>
    
    <!-- Share Weibo -->
    <a class="post_share-link" href="http://service.weibo.com/share/share.php?appkey=&title=PyTorch使用DDP进行分布式训练&url=https://blog.patrickcty.cc//2020/11/18/PyTorch使用DDP进行分布式训练/index.html&pic=&searchPic=false&style=simple" target="_blank">
        <li class="mdl-menu__item">
            分享到微博
        </li>
    </a>
</ul>
</div>
				

                <!-- Post Content -->
                <div id="post-content" class="markdown-Github mdl-color-text--grey-700 mdl-card__supporting-text fade out">
	
		<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>DDP 是 DistributedDataParallel 的简写，用来进行分布式训练，可以是单主机多 GPU 也可以是多主机多 GPU，以下均从单主机多 GPU 来介绍。其原理是把模型复制到其他的 GPU 上，然后在训练的过程中汇总梯度，进行迭代，从感知上就像是增大了 N 倍的显存。</p>
<h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><p>具体的操作是产生多个进程，每个进程在一个 GPU 上训练，然后结果自动地在主进程中进行汇总。因此启动方式需要通过 <code>torch.distributed.launch</code> 来启动，如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m torch.distributed.launch --nproc_per_node=2 main.py</span><br></pre></td></tr></table></figure>
<p>其中 <code>nproc_per_node</code> 是要使用的总的 GPU 数，如果一台主机上有多个 GPU，但是只想用其中的部分来进行训练，则可以用以下命令来启动：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=1,3,5 python -m torch.distributed.launch --nproc_per_node=3 main.py</span><br></pre></td></tr></table></figure>
<p>如果想调试分布式的代码，那么用以下方式来启动：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">NCCL_DEBUG=INFO python -m torch.distributed.launch --nproc_per_node=2 main.py</span><br></pre></td></tr></table></figure>
<h2 id="准备阶段"><a href="#准备阶段" class="headerlink" title="准备阶段"></a>准备阶段</h2><p>为了让程序能很好地与 GPU 交互，<code>torch.distributed.launch</code> 在启动进程的时候会传入 <code>local_rank</code> 参数，用来标识 GPU，因此我们要在训练脚本中加入相应的参数。值得注意的是，<code>local_rank</code> 永远是从零开始。具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parser.add_argument(<span class="string">'--local_rank'</span>, type=int, default=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h2 id="初始化分布式环境"><a href="#初始化分布式环境" class="headerlink" title="初始化分布式环境"></a>初始化分布式环境</h2><p>首先要初始化进程组，对于单主机来说就用下面简单的语句即可</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.distributed <span class="keyword">as</span> dist</span><br><span class="line"></span><br><span class="line">opt = parser.parse_args()  <span class="comment"># 解析命令行参数</span></span><br><span class="line">torch.cuda.set_device(opt.local_rank)</span><br><span class="line">dist.init_process_group(<span class="string">'nccl'</span>)</span><br><span class="line">device = torch.device(<span class="string">f'cuda:<span class="subst">&#123;opt.local_rank&#125;</span>'</span>)</span><br></pre></td></tr></table></figure>
<h2 id="构建分布式模型"><a href="#构建分布式模型" class="headerlink" title="构建分布式模型"></a>构建分布式模型</h2><p>分布式环境下默认 BN 是在主 GPU 上进行计算，然后同步到其他 GPU，因此使用普通 BN 的时候不能充分发挥分布式训练中大 batch size 的优势。如果使用 Sync BN 则会解决这个问题，这个转换也可以使用一个函数来完成。</p>
<p>之后把模型转换为 DDP 模型即可，注意的是每一个进程都会初始化一个 DDP 模型，<code>device_id</code> 指的是当前进程要用到的 GPU 标号列表。因为我们通常一个进程一个 GPU，因此这里使用 <code>[opt.local_rank]</code> 即可，输出的话是会输出到单个设备上，因此就不用转换为 list。需要注意的是，Sync BN 不支持单进程多 GPU。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.nn.parallel <span class="keyword">import</span> DistributedDataParallel <span class="keyword">as</span> DDP</span><br><span class="line"></span><br><span class="line">model = ResNet()</span><br><span class="line">model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model).to(device)</span><br><span class="line">model = DDP(model, device_ids=[opt.local_rank], output_device=opt.local_rank)</span><br></pre></td></tr></table></figure>
<h2 id="获得分布式-data-loader"><a href="#获得分布式-data-loader" class="headerlink" title="获得分布式 data loader"></a>获得分布式 data loader</h2><p>分布式训练的过程中我们要保证每个 GPU 取到的是不同的数据，因此不能直接使用普通的 Dataloader，要传入一个 sampler 参数，具体也很简单，如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> data</span><br><span class="line"></span><br><span class="line">dataset = SomeDataset(image_root, gt_root, trainsize)</span><br><span class="line"><span class="comment"># 要从原来 dataset 得到一个分布式 sampler</span></span><br><span class="line">sampler = data.distributed.DistributedSampler(dataset)</span><br><span class="line">shuffle = <span class="literal">False</span>  <span class="comment"># sampler 与 shuffle 不兼容</span></span><br><span class="line"></span><br><span class="line">data_loader = data.DataLoader(dataset=dataset,</span><br><span class="line">                              batch_size=batchsize,</span><br><span class="line">                              shuffle=shuffle,</span><br><span class="line">                              num_workers=num_workers,</span><br><span class="line">                              pin_memory=pin_memory,</span><br><span class="line">                              sampler=sampler)</span><br><span class="line"><span class="keyword">return</span> data_loader</span><br></pre></td></tr></table></figure>
<p>dataloader 中要传入 sampler 作为参数，其他的注意事项在注释中</p>
<h2 id="获得总的-loss"><a href="#获得总的-loss" class="headerlink" title="获得总的 loss"></a>获得总的 loss</h2><p>总的准备工作都完成了，接下来就是像平常一样训练了。但是每个进程中的 loss 都是通过自己的输入得到的，如果要得到总的 loss 则需要手动同步一下，具体操作如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduce_tensor</span><span class="params">(tensor: torch.Tensor)</span> -&gt; torch.Tensor:</span></span><br><span class="line">    rt = tensor.clone()</span><br><span class="line">    dist.all_reduce(rt, op=dist.ReduceOp.SUM)</span><br><span class="line">    rt /= dist.get_world_size()  <span class="comment"># 这是进程的数量</span></span><br><span class="line">    <span class="keyword">return</span> rt</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">reduced_loss1 = reduce_tensor(loss1.data).item()</span><br></pre></td></tr></table></figure>
<p><code>all_reduce</code> 会自动获取各个进程中同名 tensor，然后通过指定的 op 来进行计算，最后再同步到各个进程当中，也就是说这是一个原地的操作。为了避免可能产生的影响，这里不是直接对原来的 tensor 进行 reduce，而是先取了副本。</p>
<h2 id="保存检查点"><a href="#保存检查点" class="headerlink" title="保存检查点"></a>保存检查点</h2><p>这里有一个大坑！虽然参数会在各个进程中汇总，但是实际保存的模型的 state_dict 和非分布式的还是有区别的，如果直接载入很可能会出错，解决方法下面会提到。</p>
<h2 id="测试阶段"><a href="#测试阶段" class="headerlink" title="测试阶段"></a>测试阶段</h2><p>如果你没有掉进上一节的坑里面，那么测试阶段的代码可以和非分布式测试的完全相同。</p>
<h2 id="打印-log"><a href="#打印-log" class="headerlink" title="打印 log"></a>打印 log</h2><p>因为各个进程代码完全一样，因此打印结果也是打印 N 份，一个简单的解决方法就是判断当前的 <code>local_rank</code>，只有当其为特定值的时候才打印。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> opt.local_rank == <span class="number">0</span>:</span><br><span class="line">    print(<span class="string">'some log'</span>)</span><br></pre></td></tr></table></figure>
<h2 id="遇到的坑"><a href="#遇到的坑" class="headerlink" title="遇到的坑"></a>遇到的坑</h2><p>DDP 训练的模型通过非 DDP 进行加载之后结果非常差。</p>
<h3 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h3><p>保存的模型 state_dict 前缀多了一个 <code>module.</code>，这样在 <code>strict=False</code> 下载入参数的时候就相当于载入了个寂寞，因此结果很差</p>
<h3 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h3><ol>
<li>加载 DDP 模型的时候重新构造 state_dict，将二者名称统一<a href="https://discuss.pytorch.org/t/failed-to-load-model-trained-by-ddp-for-inference/84841" target="_blank" rel="noopener">[1]</a>:</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dist_load</span><span class="params">(state_dict)</span>:</span></span><br><span class="line"></span><br><span class="line">    new_state_dict = OrderedDict()</span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> state_dict.items():</span><br><span class="line">        name = k[<span class="number">7</span>:]  <span class="comment"># remove 'module.' of DataParallel/DistributedDataParallel</span></span><br><span class="line">        new_state_dict[name] = v</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> new_state_dict</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>（==推荐==）保存 DDP 模型的时候直接保存不包含 <code>module.</code> 前缀<a href="https://discuss.pytorch.org/t/solved-keyerror-unexpected-key-module-encoder-embedding-weight-in-state-dict/1686/17" target="_blank" rel="noopener">[2]</a>：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.save(model.module.state_dict(), path_to_file)</span><br></pre></td></tr></table></figure>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>如果你觉得还是讲的不清楚，那就看<a href="https://zhuanlan.zhihu.com/p/145427849" target="_blank" rel="noopener">这篇文章</a>吧，我就是跟着这篇文章来写的。更深入的理解分析就看<a href="https://zhuanlan.zhihu.com/p/250471767" target="_blank" rel="noopener">这个系列</a>。</p>
<h2 id="总的代码"><a href="#总的代码" class="headerlink" title="总的代码"></a>总的代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> torch.distributed <span class="keyword">as</span> dist</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> torchsummary <span class="keyword">import</span> summary</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> SyncBatchNorm</span><br><span class="line"><span class="keyword">from</span> torch.distributed <span class="keyword">import</span> ReduceOp</span><br><span class="line"><span class="keyword">from</span> torch.nn.parallel <span class="keyword">import</span> DistributedDataParallel</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> data <span class="keyword">import</span> get_loader</span><br><span class="line"><span class="keyword">from</span> model.CPD_ResNet_models <span class="keyword">import</span> CPD_ResNet</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> clip_gradient, adjust_lr, save_single_plot, get_train_parser, init_workspace</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">parser = get_train_parser(loader_type=<span class="string">'rgb'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--local_rank'</span>, type=int, default=<span class="number">0</span>)</span><br><span class="line">opt = parser.parse_args()</span><br><span class="line">main_proc = <span class="literal">True</span> <span class="keyword">if</span> opt.local_rank == <span class="number">0</span> <span class="keyword">else</span> <span class="literal">False</span></span><br><span class="line">basedir = init_workspace(opt, main_proc)</span><br><span class="line"></span><br><span class="line"><span class="comment"># init distribute environment</span></span><br><span class="line">torch.cuda.set_device(opt.local_rank)</span><br><span class="line">dist.init_process_group(<span class="string">'nccl'</span>)</span><br><span class="line">device = torch.device(<span class="string">f'cuda:<span class="subst">&#123;opt.local_rank&#125;</span>'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> main_proc:</span><br><span class="line">    print(<span class="string">'Learning Rate: &#123;&#125; Model type: &#123;&#125;'</span>.format(opt.lr, opt.model))</span><br><span class="line"></span><br><span class="line"><span class="comment"># build models</span></span><br><span class="line">model = CPD_ResNet()</span><br><span class="line">model = SyncBatchNorm.convert_sync_batchnorm(model).to(device)</span><br><span class="line">model = DistributedDataParallel(model, device_ids=[opt.local_rank], output_device=opt.local_rank)</span><br><span class="line"><span class="keyword">if</span> opt.print_model <span class="keyword">and</span> main_proc:</span><br><span class="line">    print(model)</span><br><span class="line">    summary(model, (<span class="number">4</span>, opt.trainsize, opt.trainsize))</span><br><span class="line"></span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), opt.lr)</span><br><span class="line"></span><br><span class="line"><span class="comment"># build distribute data loader</span></span><br><span class="line">train_loader = get_loader(opt.train_img_dir, opt.train_gt_dir, loader_type=<span class="string">'rgb'</span>,</span><br><span class="line">                          batchsize=opt.batchsize, trainsize=opt.trainsize, dist=<span class="literal">True</span>)</span><br><span class="line">total_step = len(train_loader)</span><br><span class="line"></span><br><span class="line"><span class="comment"># build loss</span></span><br><span class="line">CE = torch.nn.BCEWithLogitsLoss().to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># save train results in df</span></span><br><span class="line">df_step = pd.DataFrame(columns=(<span class="string">'loss1'</span>, <span class="string">'loss2'</span>))</span><br><span class="line">df_epoch = pd.DataFrame(columns=(<span class="string">'loss1'</span>, <span class="string">'loss2'</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduce_tensor</span><span class="params">(tensor: torch.Tensor)</span> -&gt; torch.Tensor:</span></span><br><span class="line">    rt = tensor.clone()</span><br><span class="line">    dist.all_reduce(rt, op=dist.ReduceOp.SUM)</span><br><span class="line">    rt /= dist.get_world_size()</span><br><span class="line">    <span class="keyword">return</span> rt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(train_loader, model, optimizer, epoch)</span>:</span></span><br><span class="line">    model.train()</span><br><span class="line">    epoch_loss1 = []</span><br><span class="line">    epoch_loss2 = []</span><br><span class="line">    <span class="keyword">for</span> i, pack <span class="keyword">in</span> enumerate(train_loader, start=<span class="number">1</span>):</span><br><span class="line">        <span class="comment"># if main_proc:</span></span><br><span class="line">        <span class="comment">#     print('running')</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        images, gts = pack</span><br><span class="line"></span><br><span class="line">        images = images.to(device)</span><br><span class="line">        gts = gts.to(device)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># if main_proc:</span></span><br><span class="line">        <span class="comment">#     print('data done')</span></span><br><span class="line"></span><br><span class="line">        atts, dets = model(images)</span><br><span class="line"></span><br><span class="line">        loss1 = CE(atts, gts)</span><br><span class="line">        loss2 = CE(dets, gts)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># if main_proc:</span></span><br><span class="line">        <span class="comment">#     print('CE done')</span></span><br><span class="line"></span><br><span class="line">        loss = loss1 + loss2</span><br><span class="line">        loss.backward()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># if main_proc:</span></span><br><span class="line">        <span class="comment">#     print('loss done')</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># save loss results</span></span><br><span class="line">        reduced_loss1 = reduce_tensor(loss1.data).item()</span><br><span class="line">        <span class="comment"># if main_proc:</span></span><br><span class="line">        <span class="comment">#     print('reduce loss1 done')</span></span><br><span class="line">        reduced_loss2 = reduce_tensor(loss2.data).item()</span><br><span class="line">        <span class="comment"># if main_proc:</span></span><br><span class="line">        <span class="comment">#     print('reduce loss2 done')</span></span><br><span class="line">        <span class="keyword">if</span> main_proc:</span><br><span class="line">            epoch_loss1.append(reduced_loss1)</span><br><span class="line">            epoch_loss2.append(reduced_loss2)</span><br><span class="line">            df_step.loc[df_step.shape[<span class="number">0</span>]] = (reduced_loss1, reduced_loss2)</span><br><span class="line"></span><br><span class="line">        clip_gradient(optimizer, opt.clip)</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (i % <span class="number">400</span> == <span class="number">0</span> <span class="keyword">or</span> i == total_step) <span class="keyword">and</span> main_proc:</span><br><span class="line">            print(<span class="string">'&#123;&#125; Epoch [&#123;:03d&#125;/&#123;:03d&#125;], Step [&#123;:04d&#125;/&#123;:04d&#125;], Loss1: &#123;:.4f&#125; Loss2: &#123;:0.4f&#125;'</span>.</span><br><span class="line">                  format(datetime.now(), epoch, opt.epoch, i, total_step,</span><br><span class="line">                         np.mean(epoch_loss1), np.mean(epoch_loss2)))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> main_proc:</span><br><span class="line">        df_epoch.loc[df_epoch.shape[<span class="number">0</span>]] = (np.mean(epoch_loss1), np.mean(epoch_loss2))</span><br><span class="line">        save_path = os.path.join(basedir, <span class="string">'checkpoints'</span>)</span><br><span class="line">        os.makedirs(save_path, exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (epoch + <span class="number">1</span>) % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="comment"># 注意，这里保存的是 model.module.state_dict()，这样测试的时候就不用做额外的处理</span></span><br><span class="line">            torch.save(model.module.state_dict(), os.path.join(save_path, <span class="string">'CPD_&#123;&#125;.pth'</span>.format(epoch + <span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(<span class="string">"GPU &#123;&#125;: Let's go!"</span>.format(opt.local_rank))</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>, opt.epoch + <span class="number">1</span>):</span><br><span class="line">    adjust_lr(optimizer, opt.lr, epoch, opt.decay_rate, opt.decay_epoch)</span><br><span class="line">    train(train_loader, model, optimizer, epoch)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> main_proc:</span><br><span class="line">    df_epoch.to_csv(os.path.join(basedir, <span class="string">'epoch_loss.csv'</span>), index=<span class="literal">False</span>)</span><br><span class="line">    df_step.to_csv(os.path.join(basedir, <span class="string">'step_loss.csv'</span>), index=<span class="literal">False</span>)</span><br><span class="line">    save_single_plot(df_epoch, (<span class="string">'loss1'</span>, <span class="string">'loss2'</span>), <span class="string">'epoch'</span>, <span class="string">'loss'</span>, basedir, <span class="string">'epoch'</span>)</span><br><span class="line">    save_single_plot(df_step, (<span class="string">'loss1'</span>, <span class="string">'loss2'</span>), <span class="string">'step'</span>, <span class="string">'loss'</span>, basedir, <span class="string">'step'</span>)</span><br></pre></td></tr></table></figure>
	
	
	
	
</div>
				
				

                <!-- Post Comments -->
                
                    


    <!-- 使用 DISQUS -->
	<div id="disqus-comment">
		<div id="disqus_thread"></div>
<script>
	var disqus_config = function () {
		this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
		this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
	};

	(function() { // DON'T EDIT BELOW THIS LINE
		var d = document, s = d.createElement('script');
		s.src = '//patrickcty.disqus.com/embed.js';
		s.setAttribute('data-timestamp', +new Date());
		(d.head || d.body).appendChild(s);
	})();
</script>
	</div>
	<style>
		#disqus-comment{
			background-color:#eee;
			padding:2pc;
		}
	</style>

                
            </div>

            <!-- Post Prev & Next Nav -->
            <nav class="material-nav mdl-color-text--grey-50 mdl-cell mdl-cell--12-col">
    
    <!-- Prev Nav -->
    
        <a href="/2021/01/26/Linux安装蓝牙接收器驱动/" id="post_nav-newer" class="prev-content">
            <button class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon mdl-color--white mdl-color-text--grey-900" role="presentation">
                <i class="material-icons">arrow_back</i>
            </button>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            新篇
        </a>
    

    <!-- Section Spacer -->
    <div class="section-spacer"></div>

    <!-- Next Nav -->
    
        <a href="/2020/11/10/simclr代码分析/" id="post_nav-older" class="next-content">
            旧篇
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <button class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon mdl-color--white mdl-color-text--grey-900" role="presentation">
                <i class="material-icons">arrow_forward</i>
            </button>
        </a>
    
</nav>
        </div>
    </div>

				
				
					<!-- Overlay For Active Sidebar -->
<div class="sidebar-overlay "></div>

<!-- Material sidebar -->
<aside id="sidebar" class="sidebar sidebar-colored  sidebar-fixed-left" role="navigation">
	<div id="sidebar-main">
	    <!-- Sidebar Header -->
		<div class="sidebar-header header-cover" style="background-image: url(https://static.jnugeek.cn/img/sidebar.jpg);">
    <!-- Top bar -->
    <div class="top-bar"></div>

    <!-- Sidebar toggle button -->
    <button type="button" class="sidebar-toggle mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon" style="display: initial;" data-upgraded=",MaterialButton,MaterialRipple">
    <i class="material-icons">clear_all</i>
    <span class="mdl-button__ripple-container"><span class="mdl-ripple"></span></span></button>

    <!-- Sidebar Avatar -->
    <div class="sidebar-image">
        <img src="https://static.jnugeek.cn/img/avatar.jpg" alt="Patrick's avatar">
    </div>

    <!-- Sidebar Email -->
    <a data-toggle="dropdown" class="sidebar-brand" href="#settings-dropdown">
        chengtiyanyang@gmail.com
        <b class="caret"></b>
    </a>
</div>

		<!-- Sidebar Navigation  -->
		<ul class="nav sidebar-nav">
    <!-- User dropdown  -->
    <li class="dropdown">
        <ul id="settings-dropdown" class="dropdown-menu">
			
                <li>
                    <a href="https://www.jnugeek.cn" target="_blank" title="网研官网">
						<i class="material-icons sidebar-material-icons sidebar-indent-left1pc-element">undefined</i>
                        网研官网
                    </a>
                </li>
            
        </ul>
    </li>

    <!-- Homepage -->
    <li id="sidebar-first-li">
        <a href="/" target="_self">
            <i class="material-icons sidebar-material-icons">home</i>
             主页
        </a>
    </li>

    <!-- I'm Feeling Lucky -->
<!--
    <li class="dropdown">
        <a href="" target="_self">
            <i class="material-icons sidebar-material-icons">explore</i>
             sidebar.imlucky
        </a>
    </li>
-->

	
    <!-- Archives  -->
    <li class="dropdown">
        <a href="#" class="ripple-effect dropdown-toggle" data-toggle="dropdown">
            <i class="material-icons sidebar-material-icons">inbox</i>
             归档
            <b class="caret"></b>
        </a>
        <ul class="dropdown-menu">
            <li>
            <a class="sidebar_archives-link" href="/archives/2021/06/">六月 2021<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2021/05/">五月 2021<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2021/02/">二月 2021<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2021/01/">一月 2021<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2020/11/">十一月 2020<span class="sidebar_archives-count">3</span></a></li><li><a class="sidebar_archives-link" href="/archives/2020/10/">十月 2020<span class="sidebar_archives-count">4</span></a></li><li><a class="sidebar_archives-link" href="/archives/2020/05/">五月 2020<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2020/04/">四月 2020<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2020/03/">三月 2020<span class="sidebar_archives-count">3</span></a></li><li><a class="sidebar_archives-link" href="/archives/2020/02/">二月 2020<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2020/01/">一月 2020<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2019/12/">十二月 2019<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2019/11/">十一月 2019<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2019/08/">八月 2019<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2019/05/">五月 2019<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2019/04/">四月 2019<span class="sidebar_archives-count">3</span></a></li><li><a class="sidebar_archives-link" href="/archives/2019/03/">三月 2019<span class="sidebar_archives-count">20</span></a></li><li><a class="sidebar_archives-link" href="/archives/2019/02/">二月 2019<span class="sidebar_archives-count">5</span></a></li><li><a class="sidebar_archives-link" href="/archives/2019/01/">一月 2019<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/06/">六月 2018<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/05/">五月 2018<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/04/">四月 2018<span class="sidebar_archives-count">3</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/03/">三月 2018<span class="sidebar_archives-count">3</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/01/">一月 2018<span class="sidebar_archives-count">7</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/12/">十二月 2017<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/11/">十一月 2017<span class="sidebar_archives-count">4</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/09/">九月 2017<span class="sidebar_archives-count">6</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/08/">八月 2017<span class="sidebar_archives-count">8</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/07/">七月 2017<span class="sidebar_archives-count">4</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/06/">六月 2017<span class="sidebar_archives-count">8</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/05/">五月 2017<span class="sidebar_archives-count">5</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/04/">四月 2017<span class="sidebar_archives-count">4</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/03/">三月 2017<span class="sidebar_archives-count">10</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/02/">二月 2017<span class="sidebar_archives-count">59</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/01/">一月 2017<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2016/11/">十一月 2016<span class="sidebar_archives-count">2</span></a>
        </ul>
    </li>

    <!-- Divider -->
    <li class="divider"></li>


    <!-- Pages  -->
	
		<li>
			<a href="/categories/ACM/" title="ACM">
				ACM
			</a>
		</li>
	
		<li>
			<a href="/categories/Fronted/" title="Fronted">
				Fronted
			</a>
		</li>
	
		<li>
			<a href="/categories/Python/" title="Python">
				Python
			</a>
		</li>
	
		<li>
			<a href="/categories/Web/" title="Web">
				Web
			</a>
		</li>
	
		<li>
			<a href="/categories/爬虫/" title="爬虫">
				爬虫
			</a>
		</li>
	
		<li>
			<a href="/categories/日记/" title="日记">
				日记
			</a>
		</li>
	
		<li>
			<a href="/categories/电影/" title="电影">
				电影
			</a>
		</li>
	
		<li>
			<a href="/categories/其他/" title="其他">
				其他
			</a>
		</li>
	
		<li>
			<a href="/about/" title="关于我">
				关于我
			</a>
		</li>
	
		<li>
			<a href="/links/" title="友情链接">
				友情链接
			</a>
		</li>
	

    <!-- Article Numebr  -->
    <li>
        <a href="/archives">
             文章总数
             <span class="sidebar-badge">185</span>
        </a>
    </li>
</ul>

		<!-- Sidebar Divider -->
		<div class="sidebar-divider"></div>

		<!-- Sidebar Footer -->
		<!-- 
I'm glad you use this theme, the development is no so easy, I hope you can keep the copyright, I will thank you so much.
If you still want to delete the copyrights, could you still retain the first one? Which namely "Theme Material"
It will not impact the appearance and can give developers a lot of support :)

很高兴您使用并喜欢该主题，开发不易 十分谢谢与希望您可以保留一下版权声明。
如果您仍然想删除的话 能否只保留第一项呢？即 "Theme Material"
它不会影响美观并可以给开发者很大的支持。 :) 
-->

<!-- Theme Material -->
<a href="https://github.com/viosey/hexo-theme-material"  class="sidebar-footer-text-a" target="_blank">
	<div class="sidebar-text mdl-button mdl-js-button mdl-js-ripple-effect sidebar-footer-text-div" data-upgraded=",MaterialButton,MaterialRipple">
		主题 - Material
		<span class="sidebar-badge badge-circle">i</span>
	</div>
</a>

<!-- Help & Support -->
<!--
<a href="mailto:hiviosey@gmail.com" class="sidebar-footer-text-a">
    <div class="sidebar-text mdl-button mdl-js-button mdl-js-ripple-effect sidebar-footer-text-div" data-upgraded=",MaterialButton,MaterialRipple">
		sidebar.help
		<span class="mdl-button__ripple-container">
			<span class="mdl-ripple"></span>
		</span>
	</div>
</a>
-->

<!-- Feedback -->
<!--
<a href="https://github.com/viosey/hexo-theme-material/issues" target="_blank" class="sidebar-footer-text-a">
    <div class="sidebar-text mdl-button mdl-js-button mdl-js-ripple-effect sidebar-footer-text-div" data-upgraded=",MaterialButton,MaterialRipple">
         sidebar.feedback
                    <span class="mdl-button__ripple-container"><span class="mdl-ripple"></span></span></div>
</a>
-->

<!-- Abount Theme -->
<!--
<a href="https://blog.viosey.com/index.php/Material.html" target="_blank" class="sidebar-footer-text-a">
    <div class="sidebar-text mdl-button mdl-js-button mdl-js-ripple-effect sidebar-footer-text-div" data-upgraded=",MaterialButton,MaterialRipple">
         sidebar.about_theme
        <span class="mdl-button__ripple-container"><span class="mdl-ripple"></span></span></div>
</a>-->

	</div>
    
    <!-- Sidebar Sponsor -->
    


</aside>

				
				
				
					<!-- Footer Top Button -->
					<div class="toTop-wrap">
    <a href="#top" class="toTop">
        <i class="material-icons footer_top-i">expand_less</i>
    </a>
</div>
				
				
				<!--Footer-->
<footer class="mdl-mini-footer" id="bottom">
	
	
		<!-- Paradox Footer Left Section -->
		<div class="mdl-mini-footer--left-section sns-list">
    <!-- Twitter -->
    
    <a href="https://twitter.com/" target="view_window"><button class="mdl-mini-footer--social-btn social-btn" style="background-image: url(https://static.jnugeek.cn/img/footer/footer_ico-twitter.png);">
        <span class="visuallyhidden">Twitter</span>
    </button></a>
    
    
    <!-- Facebook -->
    
    
    
    <!-- Google + -->
    
    
    
    <!-- Weibo -->
    
    <a href="http://weibo.com/2867516010/profile?rightmod=1&amp;wvr=6&amp;mod=personinfo&amp;is_all=1" target="view_window"><button class="mdl-mini-footer--social-btn social-btn" style="background-image: url(https://static.jnugeek.cn/img/footer/footer_ico-weibo.png);">
        <span class="visuallyhidden">Weibo</span>
    </button></a>
    
    
    <!-- Instagram -->
    
    <a href="https://www.instagram.com/patrickcty/" target="view_window"><button class="mdl-mini-footer--social-btn social-btn" style="background-image: url(https://static.jnugeek.cn/img/footer/footer_ico-instagram.png);">
        <span class="visuallyhidden">Instagram</span>
    </button></a>
    
    
    <!-- Tumblr -->
    
    
    
    <!-- Github -->
    
    <a href="https://github.com/Patrickctyyx" target="view_window"><button class="mdl-mini-footer--social-btn social-btn" style="background-image: url(https://static.jnugeek.cn/img/footer/footer_ico-github.png);">
        <span class="visuallyhidden">Github</span>
    </button></a>
    
</div>


		<!--Copyright-->
		<div id="copyright">Copyright&nbsp;©&nbsp;<script type="text/javascript">var fd = new Date();document.write(fd.getFullYear());</script>&nbsp;Patrick's Space</div>

		<!-- Paradox Footer Right Section -->

		<!-- 
		I'm glad you use this theme, the development is no so easy, I hope you can keep the copyright.
		It will not impact the appearance and can give developers a lot of support :)

		很高兴您使用该主题，开发不易，希望您可以保留一下版权声明。
		它不会影响美观并可以给开发者很大的支持。 :) 
		-->

		<div class="mdl-mini-footer--right-section">
			<div>
				<div class="footer-develop-div">Powered by <a href="https://hexo.io" target="_blank" class="footer-develop-a">Hexo</a></div>
				<div class="footer-develop-div">Theme - <a href="https://github.com/viosey/hexo-theme-material" target="_blank" class="footer-develop-a">Material</a></div>
			</div>
		</div>
	
    
</footer>
                
				<!-- Import File -->
<script src="/js/highlight.min.js"></script>
<script src="/js/js.min.js"></script>
<script src="/js/nprogress.js"></script>

<script type="text/javascript">
    NProgress.configure({
        showSpinner: true
    });
    NProgress.start();
    
    $('#nprogress .bar').css({
        'background': '#FF4081'
    });
    $('#nprogress .peg').css({
        'box-shadow': '0 0 10px #FF4081, 0 0 15px #FF4081'
    });
    $('#nprogress .spinner-icon').css({
        'border-top-color': '#FF4081',
        'border-left-color': '#FF4081'
    });
    
    setTimeout(function() {
        NProgress.done();
        $('.fade').removeClass('out');
    }, 800);
</script>






    <!-- Busuanzi -->
    <script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>





    <!-- 使用 DISQUS js 代码 -->
	<script id="dsq-count-scr" src="//patrickcty.disqus.com/count.js" async></script>


<!-- Swiftye -->


<!-- Local Search-->

	<script>
	var searchFunc = function(path, search_id, content_id) {
    'use strict';
    $.ajax({
        url: path,
        dataType: "xml",
        success: function( xmlResponse ) {
            // get the contents from search data
            var datas = $( "entry", xmlResponse ).map(function() {
                return {
                    title: $( "title", this ).text(),
                    content: $("content",this).text(),
                    url: $( "url" , this).text()
                };
            }).get();
            var $input = document.getElementById(search_id);
            var $resultContent = document.getElementById(content_id);
            $input.addEventListener('input', function(){
                var str='<ul class=\"search-result-list\">';                
                var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                $resultContent.innerHTML = "";
                if (this.value.trim().length <= 0) {
                    return;
                }
                // perform local searching
                datas.forEach(function(data) {
                    var isMatch = true;
                    var content_index = [];
                    var data_title = data.title.trim().toLowerCase();
                    var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                    var data_url = data.url;
                    var index_title = -1;
                    var index_content = -1;
                    var first_occur = -1;
                    // only match artiles with not empty titles and contents
                    if(data_title != '' && data_content != '') {
                        keywords.forEach(function(keyword, i) {
                            index_title = data_title.indexOf(keyword);
                            index_content = data_content.indexOf(keyword);
                            if( index_title < 0 && index_content < 0 ){
                                isMatch = false;
                            } else {
                                if (index_content < 0) {
                                    index_content = 0;
                                }
                                if (i == 0) {
                                    first_occur = index_content;
                                }
                            }
                        });
                    }
                    // show search results
                    if (isMatch) {
                        str += "<li><a href='"+ data_url +"' class='search-result-title' target='_blank'>"+ data_title;
                        var content = data.content.trim().replace(/<[^>]+>/g,"");
                        if (first_occur >= 0) {
                            // cut out characters
                            var start = first_occur - 6;
                            var end = first_occur + 6;
                            if(start < 0){
                                start = 0;
                            }
                            if(start == 0){
                                end = 10;
                            }
                            if(end > content.length){
                                end = content.length;
                            }
                            var match_content = content.substr(start, end); 
                            // highlight all keywords
                            keywords.forEach(function(keyword){
                                var regS = new RegExp(keyword, "gi");
                                match_content = match_content.replace(regS, "<em class=\"search-keyword\">"+keyword+"</em>");
                            })
                            str += "<p class=\"search-result\">" + match_content +"...</p>" +"</a>";
                        }
                    }
                })
                $resultContent.innerHTML = str;
            })
        }
    })
}
</script>

	<script>
        var inputArea = document.querySelector("#search");
        var getSearchFile = function(){
            var path = "search.xml";
            searchFunc(path, 'search', 'local-search-result');
        }

        inputArea.onfocus = function(){ getSearchFile() }
	</script>


<!-- Window Load-->
<script>
    $(window).load(function() {
        // Post_Toc parent position fixed
        $(".post-toc-wrap").parent(".mdl-menu__container").css("position", "fixed");
    });
</script>

<!-- MathJax Load-->

            </main>
        </div>
		
    </body>
		
	
</html>
