<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Patrick&#39;s Space</title>
  <subtitle>Stay hungry, stay foolish!</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://blog.patrickcty.cc/"/>
  <updated>2020-10-14T12:02:35.856Z</updated>
  <id>https://blog.patrickcty.cc/</id>
  
  <author>
    <name>Patrick</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>使用mmsegmentation训练自己的数据集</title>
    <link href="https://blog.patrickcty.cc/2020/10/14/%E4%BD%BF%E7%94%A8mmsegmentation%E8%AE%AD%E7%BB%83%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
    <id>https://blog.patrickcty.cc/2020/10/14/使用mmsegmentation训练自己的数据集/</id>
    <published>2020-10-14T12:01:44.000Z</published>
    <updated>2020-10-14T12:02:35.856Z</updated>
    
    <content type="html"><![CDATA[<h2 id="总体流程"><a href="#总体流程" class="headerlink" title="总体流程"></a>总体流程</h2><ul>
<li>安装</li>
<li>注册数据集</li>
<li>编写配置文件</li>
<li>运行</li>
<li>测试</li>
</ul>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">pip install mmcv</div><div class="line"># 注意只是 clone 是不行的，还要 install 一下产生版本文件</div><div class="line">pip install git+https://github.com/open-mmlab/mmsegmentation.git # install the master branch</div></pre></td></tr></table></figure>
<p>更多安装方法参考<a href="https://github.com/open-mmlab/mmsegmentation/blob/master/docs/install.md" target="_blank" rel="external">官方文档</a></p>
<h2 id="注册数据集"><a href="#注册数据集" class="headerlink" title="注册数据集"></a>注册数据集</h2><ul>
<li>在 <code>mmseg/datasets</code> 目录下添加自己的数据集的 .py 文件，这里主要是让框架知道模型的类别，下面 suffix 根据自己实际情况修改</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> os.path <span class="keyword">as</span> osp</div><div class="line"></div><div class="line"><span class="keyword">from</span> .builder <span class="keyword">import</span> DATASETS</div><div class="line"><span class="keyword">from</span> .custom <span class="keyword">import</span> CustomDataset</div><div class="line"></div><div class="line"></div><div class="line"><span class="meta">@DATASETS.register_module()</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">SatelliteDataset</span><span class="params">(CustomDataset)</span>:</span></div><div class="line">    <span class="string">"""Satellite dataset.</span></div><div class="line"></div><div class="line">    The ``img_suffix`` is fixed to '.tif' and ``seg_map_suffix`` is</div><div class="line">    fixed to '.png'.</div><div class="line">    """</div><div class="line"></div><div class="line">    CLASSES = (<span class="string">'ford'</span>, <span class="string">'transportation'</span>, <span class="string">'building'</span>, <span class="string">'farmland'</span>, <span class="string">'grassland'</span>,</div><div class="line">               <span class="string">'woodland'</span>, <span class="string">'bare_soil'</span>,  <span class="string">'others'</span>)</div><div class="line"></div><div class="line">    PALETTE = [[<span class="number">120</span>, <span class="number">120</span>, <span class="number">120</span>], [<span class="number">180</span>, <span class="number">120</span>, <span class="number">120</span>], [<span class="number">6</span>, <span class="number">230</span>, <span class="number">230</span>], [<span class="number">80</span>, <span class="number">50</span>, <span class="number">50</span>],</div><div class="line">               [<span class="number">4</span>, <span class="number">200</span>, <span class="number">3</span>], [<span class="number">120</span>, <span class="number">120</span>, <span class="number">80</span>], [<span class="number">140</span>, <span class="number">140</span>, <span class="number">140</span>], [<span class="number">204</span>, <span class="number">5</span>, <span class="number">255</span>]]</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, **kwargs)</span>:</span></div><div class="line">        super(SatelliteDataset, self).__init__(</div><div class="line">            img_suffix=<span class="string">'.tif'</span>,</div><div class="line">            seg_map_suffix=<span class="string">'.png'</span>,</div><div class="line">            reduce_zero_label=<span class="keyword">False</span>,</div><div class="line">            **kwargs)</div><div class="line">        <span class="keyword">assert</span> osp.exists(self.img_dir)</div></pre></td></tr></table></figure>
<ul>
<li>在 <code>mmseg/datasets/__init__.py</code> 中导入你自定义的类，并在 <code>__all__</code> 变量中添加你的类名</li>
</ul>
<h2 id="编写配置文件"><a href="#编写配置文件" class="headerlink" title="编写配置文件"></a>编写配置文件</h2><p>在 <code>configs/你要用的方法/</code> 下创建一个 .py 文件，配置文件主要由四部分组成：</p>
<ul>
<li>使用模型</li>
<li>数据集及数据处理流程</li>
<li>模型调度方法</li>
<li>runtime 配置</li>
</ul>
<p>可以引入已有的配置，如果要修改配置就新建一个 dict 覆盖掉原来的配置项（不需要全部字段都有），如下所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">model = dict(</div><div class="line">    # 修改类别</div><div class="line">    decode_head=dict(num_classes=8, norm_cfg=norm_cfg),</div><div class="line">    auxiliary_head=dict(num_classes=8, norm_cfg=norm_cfg),</div><div class="line">    # 修改预训练路径</div><div class="line">    pretrained=&apos;open-mmlab://resnet101_v1c&apos;,</div><div class="line">    # 修改训练 backbone</div><div class="line">    backbone=dict(depth=101, norm_cfg=norm_cfg)</div><div class="line">)</div></pre></td></tr></table></figure>
<p>放一个完整的配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div></pre></td><td class="code"><pre><div class="line">_base_ = [</div><div class="line">    &apos;../_base_/models/pspnet_r50-d8.py&apos;,</div><div class="line">    &apos;../_base_/default_runtime.py&apos;,</div><div class="line">    &apos;../_base_/schedules/schedule_40k.py&apos;</div><div class="line">]</div><div class="line"># norm_cfg = dict(type=&apos;BN&apos;, requires_grad=True)</div><div class="line">norm_cfg = dict(type=&apos;SyncBN&apos;, requires_grad=True)</div><div class="line">model = dict(</div><div class="line">    decode_head=dict(num_classes=8, norm_cfg=norm_cfg),</div><div class="line">    auxiliary_head=dict(num_classes=8, norm_cfg=norm_cfg),</div><div class="line">    pretrained=&apos;open-mmlab://resnet101_v1c&apos;,</div><div class="line">    backbone=dict(depth=101, norm_cfg=norm_cfg)</div><div class="line">)</div><div class="line"></div><div class="line">dataset_type = &apos;SatelliteDataset&apos;</div><div class="line">data_root = &apos;/home/sse/data4T/common_datasets/satelite_dataset/&apos;</div><div class="line">img_norm_cfg = dict(</div><div class="line">    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)</div><div class="line">img_scale = (256, 256)</div><div class="line"># crop_size = (224, 224)</div><div class="line"></div><div class="line">train_pipeline = [</div><div class="line">    dict(type=&apos;LoadImageFromFile&apos;),</div><div class="line">    dict(type=&apos;LoadAnnotations&apos;),</div><div class="line">    dict(type=&apos;RandomFlip&apos;, flip_ratio=0.5),</div><div class="line">    dict(type=&apos;PhotoMetricDistortion&apos;),</div><div class="line">    dict(type=&apos;Normalize&apos;, **img_norm_cfg),</div><div class="line">    dict(type=&apos;DefaultFormatBundle&apos;),</div><div class="line">    dict(type=&apos;Collect&apos;, keys=[&apos;img&apos;, &apos;gt_semantic_seg&apos;]),</div><div class="line">]</div><div class="line">test_pipeline = [</div><div class="line">    dict(type=&apos;LoadImageFromFile&apos;),</div><div class="line">    dict(</div><div class="line">        type=&apos;MultiScaleFlipAug&apos;,</div><div class="line">        img_scale=img_scale,</div><div class="line">        # img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],</div><div class="line">        flip=False,</div><div class="line">        transforms=[</div><div class="line">            dict(type=&apos;Normalize&apos;, **img_norm_cfg),</div><div class="line">            dict(type=&apos;ImageToTensor&apos;, keys=[&apos;img&apos;]),</div><div class="line">            dict(type=&apos;Collect&apos;, keys=[&apos;img&apos;]),</div><div class="line">        ])</div><div class="line">]</div><div class="line">data = dict(</div><div class="line">    samples_per_gpu=12,</div><div class="line">    workers_per_gpu=0,</div><div class="line">    train=dict(</div><div class="line">        type=dataset_type,</div><div class="line">        data_root=data_root,</div><div class="line">        img_dir=&apos;img_dir/train&apos;,</div><div class="line">        ann_dir=&apos;ann_dir/train&apos;,</div><div class="line">        # split=&apos;ImageSets/SegmentationContext/train.txt&apos;,</div><div class="line">        pipeline=train_pipeline),</div><div class="line">    val=dict(  # 训练到一定轮次会自动验证</div><div class="line">        type=dataset_type,</div><div class="line">        data_root=data_root,</div><div class="line">        img_dir=&apos;img_dir/test&apos;,</div><div class="line">        ann_dir=&apos;ann_dir/test&apos;,</div><div class="line">        # split=&apos;ImageSets/SegmentationContext/val.txt&apos;,</div><div class="line">        pipeline=test_pipeline),</div><div class="line">    test=dict(  # 测试的时候才用到</div><div class="line">        type=dataset_type,</div><div class="line">        data_root=data_root,</div><div class="line">        img_dir=&apos;image_A/image_A_9&apos;,</div><div class="line">        # ann_dir=&apos;ann_dir/test&apos;,</div><div class="line">        # split=&apos;ImageSets/SegmentationContext/val.txt&apos;,</div><div class="line">        pipeline=test_pipeline))</div><div class="line"></div><div class="line">total_iters = 100000</div><div class="line">checkpoint_config = dict(by_epoch=False, interval=4000)</div><div class="line">evaluation = dict(interval=4000, metric=&apos;mIoU&apos;)</div><div class="line"></div><div class="line"># 训练结果保存路径</div><div class="line">work_dir = &apos;/home/sse/mmsegmentation/run/satellite-10-12&apos;</div></pre></td></tr></table></figure>
<p>详细配置还是参考<a href="https://github.com/open-mmlab/mmsegmentation/blob/master/docs/config.md" target="_blank" rel="external">官方文档</a></p>
<h2 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h2><p>单卡运行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python tools/train.py 配置文件路径名</div></pre></td></tr></table></figure>
<p>分布式运行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./tools/dist_train.sh 配置文件路径名 GPU数 [optional arguments]</div></pre></td></tr></table></figure>
<p>从已有参数从头开始运行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./tools/dist_train.sh 配置文件路径名 GPU数 --load-from 参数路径</div></pre></td></tr></table></figure>
<p>从已有参数从头继续运行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./tools/dist_train.sh 配置文件路径名 GPU数 --resume-from 参数路径</div></pre></td></tr></table></figure>
<p>更详细的依然参考<a href="https://github.com/open-mmlab/mmsegmentation/blob/master/docs/getting_started.md" target="_blank" rel="external">官方文档</a></p>
<h3 id="运行时候的-一个坑"><a href="#运行时候的-一个坑" class="headerlink" title="运行时候的==一个坑=="></a>运行时候的==一个坑==</h3><p>验证数据集在验证时会把所有的预测结果和 GT 保存在内存中，如果验证集太大很可能进程会挂掉，测试同</p>
<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>测试的时候默认使用配置文件中指定的测试集</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"># single-gpu testing</div><div class="line">python tools/test.py $&#123;CONFIG_FILE&#125; $&#123;CHECKPOINT_FILE&#125; [--out $&#123;RESULT_FILE&#125;] [--eval $&#123;EVAL_METRICS&#125;] [--show]</div><div class="line"></div><div class="line"># multi-gpu testing</div><div class="line">./tools/dist_test.sh $&#123;CONFIG_FILE&#125; $&#123;CHECKPOINT_FILE&#125; $&#123;GPU_NUM&#125; [--out $&#123;RESULT_FILE&#125;] [--eval $&#123;EVAL_METRICS&#125;]</div></pre></td></tr></table></figure>
<p>可选参数</p>
<ul>
<li>RESULT_FILE: pickle 文件，结果保存在其中</li>
<li>EVAL_METRICS: 评价指标，制定之后需要标签文件</li>
<li>–show: 结果会在新窗口中打开</li>
<li>–show-dir: 可视化结果保存到指定文件夹中，注意保存的不是神经网络出来的结果，而是经过 RGB 调色之后和原图叠加的结果</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;总体流程&quot;&gt;&lt;a href=&quot;#总体流程&quot; class=&quot;headerlink&quot; title=&quot;总体流程&quot;&gt;&lt;/a&gt;总体流程&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;安装&lt;/li&gt;
&lt;li&gt;注册数据集&lt;/li&gt;
&lt;li&gt;编写配置文件&lt;/li&gt;
&lt;li&gt;运行&lt;/li&gt;
&lt;li&gt;测
    
    </summary>
    
    
      <category term="深度学习" scheme="https://blog.patrickcty.cc/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="语义分割" scheme="https://blog.patrickcty.cc/tags/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    
  </entry>
  
  <entry>
    <title>【一个坑】exFAT 不支持软链接与硬链接</title>
    <link href="https://blog.patrickcty.cc/2020/10/10/exFAT%E4%B8%8D%E6%94%AF%E6%8C%81%E8%BD%AF%E9%93%BE%E6%8E%A5%E4%B8%8E%E7%A1%AC%E9%93%BE%E6%8E%A5/"/>
    <id>https://blog.patrickcty.cc/2020/10/10/exFAT不支持软链接与硬链接/</id>
    <published>2020-10-10T14:47:13.000Z</published>
    <updated>2020-10-10T14:53:48.276Z</updated>
    
    <content type="html"><![CDATA[<p>今天在跑 mmseg 的代码的时候报了一个 OSError，function not implemented。在终端使用 <code>ln</code> 命令也报了同样的问题，后来经过<a href="https://superuser.com/questions/1256530/linux-links-shortcuts-in-exfat-filesystem/1256536" target="_blank" rel="external">查找</a>之后发现 exFAT 文件系统不支持软链接与硬链接。</p>
<p>P.S. 创建软链接方法：<code>ln -s src_path dst_symlink_path</code></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今天在跑 mmseg 的代码的时候报了一个 OSError，function not implemented。在终端使用 &lt;code&gt;ln&lt;/code&gt; 命令也报了同样的问题，后来经过&lt;a href=&quot;https://superuser.com/questions/1256
    
    </summary>
    
    
      <category term="踩坑" scheme="https://blog.patrickcty.cc/tags/%E8%B8%A9%E5%9D%91/"/>
    
  </entry>
  
  <entry>
    <title>keras自定义训练流程</title>
    <link href="https://blog.patrickcty.cc/2020/10/07/keras%E8%87%AA%E5%AE%9A%E4%B9%89%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B/"/>
    <id>https://blog.patrickcty.cc/2020/10/07/keras自定义训练流程/</id>
    <published>2020-10-07T12:48:50.000Z</published>
    <updated>2020-10-07T12:51:09.771Z</updated>
    
    <content type="html"><![CDATA[<h2 id="标准流程"><a href="#标准流程" class="headerlink" title="标准流程"></a>标准流程</h2><p>keras 的 api 集成度都非常高，在你没有额外需求的时候的时候能非常轻松地完成整个训练流程：</p>
<ul>
<li>加载数据<ul>
<li>可以选择 generator </li>
<li>也可以直接传入内存的数据</li>
<li>还可以按照一定格式组织成文件夹然后直接传文件夹名</li>
</ul>
</li>
<li>构造模型</li>
<li>编译模型<ul>
<li>指定优化器</li>
<li>指定损失函数</li>
<li>指定评价标准</li>
</ul>
</li>
<li>训练模型<ul>
<li>指定训练轮次（epoch）</li>
<li>指定回调</li>
</ul>
</li>
</ul>
<h2 id="自定义流程"><a href="#自定义流程" class="headerlink" title="自定义流程"></a>自定义流程</h2><p>标准流程在大多数情况下都能满足需求，但是对于一些需要获取网络中细节的情况下就需要自定义流程了。自定义主要也是对训练步骤进行处理，基本步骤如下：</p>
<ul>
<li>定义一个 step 的操作：<ul>
<li>取出这个 batch 的数据</li>
<li>传入网络得到输出</li>
<li>计算 loss</li>
<li>计算梯度</li>
<li>梯度下降</li>
</ul>
</li>
</ul>
<p>写成代码如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">loss_object = tf.keras.losses.SparseCategoricalCrossentropy()</div><div class="line">train_loss = tf.keras.metrics.Mean(<span class="string">'train_loss'</span>, dtype=tf.float32)</div><div class="line">train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(<span class="string">'train_accuracy'</span>)</div><div class="line"></div><div class="line"><span class="keyword">for</span> idx, (x_train, y_train) <span class="keyword">in</span> enumerate(train_gen):</div><div class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</div><div class="line">        predictions = model(x_train, training=<span class="keyword">True</span>)  <span class="comment"># 传入网络得到输出</span></div><div class="line">        loss = loss_object(y_train, predictions)  <span class="comment"># 计算 loss</span></div><div class="line">    grads = tape.gradient(loss, model.trainable_variables)  <span class="comment"># 计算梯度</span></div><div class="line">    optimizer.apply_gradients(zip(grads, model.trainable_variables))  <span class="comment"># 梯度下降</span></div><div class="line"></div><div class="line">    <span class="comment"># 一些指标</span></div><div class="line">    train_loss(loss)</div><div class="line">    train_accuracy(y_train, predictions)</div></pre></td></tr></table></figure>
<h2 id="和-TensorBoard-一起作用"><a href="#和-TensorBoard-一起作用" class="headerlink" title="和 TensorBoard 一起作用"></a>和 TensorBoard 一起作用</h2><p>尽管 keras 的 callback 里面也有 tensorboard，但是默认情况下它只能每个 ep 来保存评价指标和直方图，不能看一个 step 中的变化情况，也不能将参数或者梯度来画成图表。在这里我们将参数和梯度的 l2 范数变化情况画成图表，并且原本就有的直方图也不落下。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># create a tensorboard file writer</span></div><div class="line">summary_writer = tf.summary.create_file_writer(some_path)</div><div class="line">loss_object = tf.keras.losses.SparseCategoricalCrossentropy()</div><div class="line">train_loss = tf.keras.metrics.Mean(<span class="string">'train_loss'</span>, dtype=tf.float32)</div><div class="line">train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(<span class="string">'train_accuracy'</span>)</div><div class="line"></div><div class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>, num_epochs + <span class="number">1</span>):</div><div class="line">    <span class="keyword">for</span> idx, (x_train, y_train) <span class="keyword">in</span> enumerate(train_gen):</div><div class="line">        n_iter = (epoch - <span class="number">1</span>) * len(train_gen) + idx + <span class="number">1</span></div><div class="line">        </div><div class="line">        <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</div><div class="line">            predictions = model(x_train, training=<span class="keyword">True</span>)  <span class="comment"># 传入网络得到输出</span></div><div class="line">            loss = loss_object(y_train, predictions)  <span class="comment"># 计算 loss</span></div><div class="line">        gradients = tape.gradient(loss, model.trainable_variables)  <span class="comment"># 计算梯度</span></div><div class="line">        optimizer.apply_gradients(zip(grads, model.trainable_variables))  <span class="comment"># 梯度下降</span></div><div class="line">        trainable_vars = model.trainable_variables</div><div class="line">        </div><div class="line">        <span class="comment"># 一些指标，都是标量</span></div><div class="line">        train_loss(loss)</div><div class="line">        train_accuracy(y_train, predictions)</div><div class="line">        </div><div class="line">        <span class="keyword">with</span> summary_writer.as_default():</div><div class="line">            <span class="comment"># 写入评价指标</span></div><div class="line">            tf.summary.scalar(<span class="string">'loss'</span>, train_loss.result(), step=n_iter)</div><div class="line">            tf.summary.scalar(<span class="string">'accuracy'</span>, train_accuracy.result(), step=n_iter)</div><div class="line">            </div><div class="line">            <span class="keyword">for</span> var, grad <span class="keyword">in</span> zip(trainable_vars, gradients)</div><div class="line">                <span class="comment"># 写入各个可训练元素的直方图、梯度和参数</span></div><div class="line">                tf.summary.histograme(var.name, var, n_iter)</div><div class="line">                tf.summary.scalar(<span class="string">'Grads:'</span> + var.name, tf.norm(grad), n_iter)</div><div class="line">                tf.summart.scalar(<span class="string">'Weights'</span> + var.name, ty.norm(var), n_iter)</div><div class="line"></div><div class="line">    print(<span class="string">'Epoch &#123;:03d&#125; finished.'</span>.format(epoch))</div></pre></td></tr></table></figure>
<p>TensorBoard 里面的数据不能导出来，也可以单独将其写入 csv 来方便后续的处理。</p>
<h2 id="参考教程"><a href="#参考教程" class="headerlink" title="参考教程"></a>参考教程</h2><ul>
<li><a href="https://keras.io/guides/customizing_what_happens_in_fit/" target="_blank" rel="external">https://keras.io/guides/customizing_what_happens_in_fit/</a></li>
<li><a href="https://www.tensorflow.org/tensorboard/get_started" target="_blank" rel="external">https://www.tensorflow.org/tensorboard/get_started</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;标准流程&quot;&gt;&lt;a href=&quot;#标准流程&quot; class=&quot;headerlink&quot; title=&quot;标准流程&quot;&gt;&lt;/a&gt;标准流程&lt;/h2&gt;&lt;p&gt;keras 的 api 集成度都非常高，在你没有额外需求的时候的时候能非常轻松地完成整个训练流程：&lt;/p&gt;
&lt;ul&gt;
&lt;li
    
    </summary>
    
    
      <category term="深度学习" scheme="https://blog.patrickcty.cc/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Keras" scheme="https://blog.patrickcty.cc/tags/Keras/"/>
    
      <category term="TensorFlow" scheme="https://blog.patrickcty.cc/tags/TensorFlow/"/>
    
      <category term="TensorBoard" scheme="https://blog.patrickcty.cc/tags/TensorBoard/"/>
    
  </entry>
  
  <entry>
    <title>keras中BatchNormalization在迁移学习中的坑</title>
    <link href="https://blog.patrickcty.cc/2020/05/13/Keras%E4%B8%ADBatchNormalization%E5%9C%A8%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E5%9D%91/"/>
    <id>https://blog.patrickcty.cc/2020/05/13/Keras中BatchNormalization在迁移学习中的坑/</id>
    <published>2020-05-13T02:38:13.000Z</published>
    <updated>2020-10-08T08:03:09.029Z</updated>
    
    <content type="html"><![CDATA[<h2 id="注"><a href="#注" class="headerlink" title="注"></a>注</h2><p>这个问题已经在 TF 2.0 中修复了，见<a href="https://tensorflow.google.cn/api_docs/python/tf/keras/layers/BatchNormalization?hl=zh-cn" target="_blank" rel="external">文档</a>。</p>
<blockquote>
<p>However, in the case of the BatchNormalization layer, setting trainable = False on the layer means that the layer will be subsequently run in inference mode (meaning that it will use the moving mean and the moving variance to normalize the current batch, rather than using the mean and variance of the current batch).</p>
<p>This behavior has been introduced in TensorFlow 2.0, in order to enable layer.trainable = False to produce the most commonly expected behavior in the convnet fine-tuning use case.</p>
</blockquote>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>最近 Keras 的文档更新了，我发现了一个迁移学习的文档，结果进去之后发现一个奇怪的地方：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">base_model = keras.applications.Xception(</div><div class="line">    weights=&quot;imagenet&quot;,  # Load weights pre-trained on ImageNet.</div><div class="line">    input_shape=(150, 150, 3),</div><div class="line">    include_top=False,</div><div class="line">)  # Do not include the ImageNet classifier at the top.</div><div class="line"></div><div class="line"># Freeze the base_model</div><div class="line">base_model.trainable = False</div><div class="line"></div><div class="line"># Create new model on top</div><div class="line">inputs = keras.Input(shape=(150, 150, 3))</div><div class="line">x = data_augmentation(inputs)  # Apply random data augmentation</div><div class="line">x = keras.layers.experimental.preprocessing.Rescaling(1.0 / 255.0)(</div><div class="line">    x</div><div class="line">)  # Scale inputs to [0. 1]</div><div class="line"># The base model contains batchnorm layers. We want to keep them in inference mode</div><div class="line"># when we unfreeze the base model for fine-tuning, so we make sure that the</div><div class="line"># base_model is running in inference mode here.</div><div class="line">x = base_model(x, training=False)</div><div class="line">x = keras.layers.GlobalAveragePooling2D()(x)</div><div class="line">x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout</div><div class="line">outputs = keras.layers.Dense(1)(x)</div><div class="line">model = keras.Model(inputs, outputs)</div><div class="line"></div><div class="line">model.summary()</div></pre></td></tr></table></figure>
<p>这里是说迁移学习的时候，使用其他的模型，然后冻结之，再增加新的层进行训练。其中 <code>x = base_model(x, training=False)</code> 以及上面的注释引起了我的注意。在这里设置 <code>training=False</code> 是为了让 backbone 处于 inference 状态，这个状态主要是对 BN 起作用，那就是不更新 BN 的参数，即使 unfreeze 之后也不更新。</p>
<p>这个 inference 状态和 training 状态有什么用呢？我们知道，有一些层在训练和测试的时候表现是不同的，比如 BN 和 Dropout。其中 BN 在训练的时候使用 mini-batch 的数据来进行归一化，同时更新 moving mean 和 moving variance，在测试的时候就使用上面的 moving mean 和 moving variance 来进行归一化。这里的 training 是用来控制这些层的表现。</p>
<p>这个 training 出现在 keras Layer 和 Model 的 call 方法中:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">def call(self, inputs, training=False):</div><div class="line">    pass</div></pre></td></tr></table></figure>
<p>当调用层的时候可以指定，比如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">x = BatchNormalization()(x, training=False)</div><div class="line">model = Xception(input_shape=(150, 150, 3))(x, training=True)</div></pre></td></tr></table></figure>
<p>本着想更深入地理解这个参数，就查了一下，结果发现了一个 <a href="https://github.com/keras-team/keras/issues/7177" target="_blank" rel="external">issue</a> 和一个 <a href="https://github.com/keras-team/keras/pull/9965" target="_blank" rel="external">PR</a>，这里面就描述了 keras BatchNormalization 在迁移学习中的坑。</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>大佬的<a href="http://blog.datumbox.com/the-batch-normalization-layer-of-keras-is-broken/" target="_blank" rel="external">博客</a>清楚地解释了问题，我这里再重新复述一下。</p>
<p>上面提到过了，BN 层在训练状态和测试状态下的表现是不同的，一个是使用 mini-batch 的数据，另一个是使用积累下来的 moving mean 和 moving variance。而在迁移学习中，我们通常会把 backbone 直接 freeze，训练新加的层，再 unfreeze backbone，然后一起训练。</p>
<p>不过如果不按照上面那样设置 <code>x = base_model(x, training=False)</code>，而是直接像下面这样使用已有的模型然后进行训练（实际上大多数数据增强都不会整合到 model 中，因为只有训练的时候才需要，也就是说，基本不会出现上面这种调用形式），那么就会出现问题。（以下代码来自提到的博客）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div></pre></td><td class="code"><pre><div class="line">import numpy as np</div><div class="line">from tensorflow.keras.datasets import cifar10</div><div class="line"> </div><div class="line">from tensorflow.keras.preprocessing.image import ImageDataGenerator</div><div class="line">from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input</div><div class="line">from tensorflow.keras.models import Model, load_model</div><div class="line">from tensorflow.keras.layers import Dense, Flatten</div><div class="line">from tensorflow.keras import backend as K</div><div class="line"></div><div class="line">seed = 42</div><div class="line">epochs = 10</div><div class="line">records_per_class = 100</div><div class="line"></div><div class="line"># We take only 2 classes from CIFAR10 and a very small sample to intentionally overfit the model.</div><div class="line"># We will also use the same data for train/test and expect that Keras will give the same accuracy.</div><div class="line">(x, y), _ = cifar10.load_data()</div><div class="line"> </div><div class="line">def filter_resize(category):</div><div class="line">   # We do the preprocessing here instead in the Generator to get around a bug on Keras 2.1.5.</div><div class="line">   return [preprocess_input(img) for img in x[y.flatten()==category][:records_per_class]]</div><div class="line"> </div><div class="line">x = np.stack(filter_resize(3)+filter_resize(5))</div><div class="line">records_per_class = x.shape[0] // 2</div><div class="line">y = np.array([[1,0]]*records_per_class + [[0,1]]*records_per_class)</div><div class="line"> </div><div class="line"> </div><div class="line"># We will use a pre-trained model and finetune the top layers.</div><div class="line">np.random.seed(seed)</div><div class="line">base_model = ResNet50(weights=&apos;imagenet&apos;, include_top=False, input_shape=(32, 32, 3))</div><div class="line">l = Flatten()(base_model.output)</div><div class="line">predictions = Dense(2, activation=&apos;softmax&apos;)(l)</div><div class="line">model = Model(inputs=base_model.input, outputs=predictions)</div><div class="line"> </div><div class="line"># for layer in model.layers[:140]:</div><div class="line">#    layer.trainable = False</div><div class="line"> </div><div class="line"># for layer in model.layers[140:]:</div><div class="line">#    layer.trainable = True</div><div class="line">base_model.trainable = False</div><div class="line"> </div><div class="line">model.compile(optimizer=&apos;sgd&apos;, loss=&apos;categorical_crossentropy&apos;, metrics=[&apos;accuracy&apos;])</div><div class="line">model.fit_generator(ImageDataGenerator().flow(x, y, seed=42), </div><div class="line">                    steps_per_epoch=7,</div><div class="line">                    epochs=epochs, </div><div class="line">                    validation_data=ImageDataGenerator().flow(x, y, seed=42),</div><div class="line">                    validation_steps=7</div><div class="line">                    )</div><div class="line"> </div><div class="line"># Store the model on disk</div><div class="line">model.save(&apos;tmp.h5&apos;)</div><div class="line"> </div><div class="line"> </div><div class="line"># In every test we will clear the session and reload the model to force Learning_Phase values to change.</div><div class="line">print(&apos;DYNAMIC LEARNING_PHASE&apos;)</div><div class="line">K.clear_session()</div><div class="line">model = load_model(&apos;tmp.h5&apos;)</div><div class="line"># This accuracy should match exactly the one of the validation set on the last iteration.</div><div class="line">print(model.evaluate(ImageDataGenerator().flow(x, y, seed=42), steps=7))</div><div class="line"> </div><div class="line"> </div><div class="line">print(&apos;STATIC LEARNING_PHASE = 0&apos;)</div><div class="line">K.clear_session()</div><div class="line">K.set_learning_phase(0)</div><div class="line">model = load_model(&apos;tmp.h5&apos;)</div><div class="line"># Again the accuracy should match the above.</div><div class="line">print(model.evaluate(ImageDataGenerator().flow(x, y, seed=42), steps=7))</div><div class="line"> </div><div class="line"> </div><div class="line">print(&apos;STATIC LEARNING_PHASE = 1&apos;)</div><div class="line">K.clear_session()</div><div class="line">K.set_learning_phase(1)</div><div class="line">model = load_model(&apos;tmp.h5&apos;)</div><div class="line"># The accuracy will be close to the one of the training set on the last iteration.</div><div class="line">print(model.evaluate(ImageDataGenerator().flow(x, y, seed=42), steps=7))</div></pre></td></tr></table></figure>
<p>运行上面的代码，其中训练集和验证集是同一个数据集。我们可以看到这两者的结果截然不同，训练的结果远好于验证的结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line">Epoch 1/10</div><div class="line">6/7 [========================&gt;.....] - ETA: 0s - loss: 1.1314 - acc: 0.5298Epoch 1/10</div><div class="line">7/7 [==============================] - 3s 394ms/step - loss: 2.0678 - acc: 0.5700</div><div class="line">7/7 [==============================] - 5s 760ms/step - loss: 1.2129 - acc: 0.5300 - val_loss: 2.0678 - val_acc: 0.5700</div><div class="line">Epoch 2/10</div><div class="line">6/7 [========================&gt;.....] - ETA: 0s - loss: 0.9528 - acc: 0.6012Epoch 1/10</div><div class="line">7/7 [==============================] - 2s 265ms/step - loss: 1.4357 - acc: 0.5600</div><div class="line">7/7 [==============================] - 4s 558ms/step - loss: 0.8973 - acc: 0.6150 - val_loss: 1.4357 - val_acc: 0.5600</div><div class="line">Epoch 3/10</div><div class="line">6/7 [========================&gt;.....] - ETA: 0s - loss: 0.7655 - acc: 0.6667Epoch 1/10</div><div class="line">7/7 [==============================] - 2s 215ms/step - loss: 1.4113 - acc: 0.5950</div><div class="line">7/7 [==============================] - 4s 535ms/step - loss: 0.8119 - acc: 0.6550 - val_loss: 1.4113 - val_acc: 0.5950</div><div class="line">Epoch 4/10</div><div class="line">6/7 [========================&gt;.....] - ETA: 0s - loss: 0.7548 - acc: 0.7440Epoch 1/10</div><div class="line">7/7 [==============================] - 1s 151ms/step - loss: 1.9380 - acc: 0.5800</div><div class="line">7/7 [==============================] - 2s 331ms/step - loss: 0.7230 - acc: 0.7350 - val_loss: 1.9380 - val_acc: 0.5800</div><div class="line">Epoch 5/10</div><div class="line">6/7 [========================&gt;.....] - ETA: 0s - loss: 0.5866 - acc: 0.7202Epoch 1/10</div><div class="line">7/7 [==============================] - 1s 150ms/step - loss: 1.8147 - acc: 0.6000</div><div class="line">7/7 [==============================] - 2s 322ms/step - loss: 0.5802 - acc: 0.7150 - val_loss: 1.8147 - val_acc: 0.6000</div><div class="line">Epoch 6/10</div><div class="line">6/7 [========================&gt;.....] - ETA: 0s - loss: 0.3704 - acc: 0.8095Epoch 1/10</div><div class="line">7/7 [==============================] - 1s 151ms/step - loss: 1.5603 - acc: 0.6450</div><div class="line">7/7 [==============================] - 2s 321ms/step - loss: 0.3881 - acc: 0.7950 - val_loss: 1.5603 - val_acc: 0.6450</div><div class="line">Epoch 7/10</div><div class="line">6/7 [========================&gt;.....] - ETA: 0s - loss: 0.5056 - acc: 0.7738Epoch 1/10</div><div class="line">7/7 [==============================] - 1s 151ms/step - loss: 1.9539 - acc: 0.6250</div><div class="line">7/7 [==============================] - 2s 322ms/step - loss: 0.5618 - acc: 0.7400 - val_loss: 1.9539 - val_acc: 0.6250</div><div class="line">Epoch 8/10</div><div class="line">6/7 [========================&gt;.....] - ETA: 0s - loss: 0.5849 - acc: 0.7976Epoch 1/10</div><div class="line">7/7 [==============================] - 1s 153ms/step - loss: 1.4035 - acc: 0.6600</div><div class="line">7/7 [==============================] - 2s 323ms/step - loss: 0.5465 - acc: 0.8050 - val_loss: 1.4035 - val_acc: 0.6600</div><div class="line">Epoch 9/10</div><div class="line">6/7 [========================&gt;.....] - ETA: 0s - loss: 0.4055 - acc: 0.8512Epoch 1/10</div><div class="line">7/7 [==============================] - 1s 147ms/step - loss: 1.0538 - acc: 0.6650</div><div class="line">7/7 [==============================] - 2s 322ms/step - loss: 0.3984 - acc: 0.8450 - val_loss: 1.0538 - val_acc: 0.6650</div><div class="line">Epoch 10/10</div><div class="line">6/7 [========================&gt;.....] - ETA: 0s - loss: 0.4082 - acc: 0.8452Epoch 1/10</div><div class="line">7/7 [==============================] - 1s 152ms/step - loss: 1.8019 - acc: 0.6000</div><div class="line">7/7 [==============================] - 2s 322ms/step - loss: 0.4177 - acc: 0.8400 - val_loss: 1.8019 - val_acc: 0.6000</div></pre></td></tr></table></figure>
<p>再看看最后输出的结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">DYNAMIC LEARNING_PHASE</div><div class="line">7/7 [==============================] - 2s 256ms/step - loss: 2.0028 - acc: 0.6000</div><div class="line">[2.002779943602426, 0.6]</div><div class="line">STATIC LEARNING_PHASE = 0</div><div class="line">7/7 [==============================] - 1s 204ms/step - loss: 2.0028 - acc: 0.6000</div><div class="line">[2.002779943602426, 0.6]</div><div class="line">STATIC LEARNING_PHASE = 1</div><div class="line">7/7 [==============================] - 1s 212ms/step - loss: 0.3017 - acc: 0.8650</div><div class="line">[0.30170093051024843, 0.865]</div></pre></td></tr></table></figure>
<p>第一个结果是 keras 直接自动设置运行状态，第二个结果是手动设定运行状态为测试状态，第三个结果是手动设定运行结果为训练状态。可以看出来，keras 在测试的时候自动设置为测试状态，但这个时候结果出现了明显的下滑，而设置为训练状态的时候结果很正常。</p>
<p>其原因在于，在训练的时候，虽然 freeze 了 BN 的参数，但是 keras 仍然认为 BN 是在训练状态，因此会使用 mini-batch 的数据来标准化。也就是说，这时候后层网络学习到的是 mini-batch（训练数据集） 的分布。但是当测试的时候，BN 使用 moving mean 和 moving variance 来标准化，这两个参数由于没更新，是来自于原来数据集的。因为二者分布偏差很大，因此在测试模式下得到的结果非常差。</p>
<p>这个 PR 的改进就是当 freeze BN 的时候，就让 BN 层按照测试状态来进行，而不使用 mini-batch 的数据。</p>
<h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p>看了半天，keras 官方好像没有改这个 bug，但是 TF 2.0 版本已经修改了这个 bug 了，以下是在 TF 2.0 下运行同样代码的结果，可以看到训练和验证的结果是相差不大的。另外值得一提的是，改进过后收敛速度明显快了很多，loss 从 0.3 直接降到了 0.01。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">Epoch 1/10</div><div class="line">7/7 [==============================] - 2s 332ms/step - loss: 7.3916 - accuracy: 0.4700 - val_loss: 3.1501 - val_accuracy: 0.6500</div><div class="line">Epoch 2/10</div><div class="line">7/7 [==============================] - 1s 207ms/step - loss: 2.8816 - accuracy: 0.6700 - val_loss: 8.4492 - val_accuracy: 0.5100</div><div class="line">Epoch 3/10</div><div class="line">7/7 [==============================] - 1s 206ms/step - loss: 4.1846 - accuracy: 0.6750 - val_loss: 11.3409 - val_accuracy: 0.5600</div><div class="line">Epoch 4/10</div><div class="line">7/7 [==============================] - 1s 204ms/step - loss: 3.4036 - accuracy: 0.7800 - val_loss: 0.4167 - val_accuracy: 0.8650</div><div class="line">Epoch 5/10</div><div class="line">7/7 [==============================] - 1s 210ms/step - loss: 0.8244 - accuracy: 0.8150 - val_loss: 9.1833 - val_accuracy: 0.5400</div><div class="line">Epoch 6/10</div><div class="line">7/7 [==============================] - 1s 210ms/step - loss: 2.3888 - accuracy: 0.7600 - val_loss: 0.7993 - val_accuracy: 0.8100</div><div class="line">Epoch 7/10</div><div class="line">7/7 [==============================] - 1s 207ms/step - loss: 0.5801 - accuracy: 0.8600 - val_loss: 2.9707 - val_accuracy: 0.6700</div><div class="line">Epoch 8/10</div><div class="line">7/7 [==============================] - 1s 205ms/step - loss: 4.2250 - accuracy: 0.6050 - val_loss: 1.0646 - val_accuracy: 0.8500</div><div class="line">Epoch 9/10</div><div class="line">7/7 [==============================] - 1s 206ms/step - loss: 0.4886 - accuracy: 0.8900 - val_loss: 0.0866 - val_accuracy: 0.9800</div><div class="line">Epoch 10/10</div><div class="line">7/7 [==============================] - 1s 206ms/step - loss: 0.0969 - accuracy: 0.9700 - val_loss: 0.0109 - val_accuracy: 1.0000</div><div class="line">DYNAMIC LEARNING_PHASE</div><div class="line">7/7 [==============================] - 1s 95ms/step - loss: 0.0118 - accuracy: 1.0000</div><div class="line">[0.011801988817751408, 1.0]</div><div class="line">STATIC LEARNING_PHASE = 0</div><div class="line">7/7 [==============================] - 1s 94ms/step - loss: 0.0118 - accuracy: 1.0000</div><div class="line">[0.011801988817751408, 1.0]</div><div class="line">STATIC LEARNING_PHASE = 1</div><div class="line">7/7 [==============================] - 1s 92ms/step - loss: 0.0118 - accuracy: 1.0000</div><div class="line">[0.011801988817751408, 1.0]</div></pre></td></tr></table></figure>
<h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>这种问题真的是防不胜防，毕竟很少人会去训练集和验证集使用同一个数据集，训练集和验证集相差大大家也只会怪罪到过拟合头上去。所以平常对于一些关键的东西还是得把他摸透，并且要多看官方文档，遇到问题多思考（所以深度学习就是这一点不好，出了问题有太多可能的原因，很难定位到问题所在）。</p>
<p>P.S. 今天在训练 SOD 的时候并没有出现这个问题，其原因可能在于：</p>
<ul>
<li>我的模型在 backbone 之外增加了很多的参数，减弱了 BN 的影响，因此结果是差不多的。（回头再多做一点实验）</li>
<li>DUTS 的数据本来就来自 ImageNet Detection，因此分布非常接近。</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;注&quot;&gt;&lt;a href=&quot;#注&quot; class=&quot;headerlink&quot; title=&quot;注&quot;&gt;&lt;/a&gt;注&lt;/h2&gt;&lt;p&gt;这个问题已经在 TF 2.0 中修复了，见&lt;a href=&quot;https://tensorflow.google.cn/api_docs/python
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>keras处理任意大小输入</title>
    <link href="https://blog.patrickcty.cc/2020/04/11/keras%E5%A4%84%E7%90%86%E4%BB%BB%E6%84%8F%E5%A4%A7%E5%B0%8F%E8%BE%93%E5%85%A5/"/>
    <id>https://blog.patrickcty.cc/2020/04/11/keras处理任意大小输入/</id>
    <published>2020-04-11T07:56:32.000Z</published>
    <updated>2020-04-11T09:28:25.319Z</updated>
    
    <content type="html"><![CDATA[<p>让 keras 处理任意大小输入其实很简单，只需：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"># for rgb</div><div class="line">main_input = layers.Input(shape=(None, None, 3))</div><div class="line"># for gray</div><div class="line">main_input = layers.Input(shape=(None, None, 1))</div></pre></td></tr></table></figure>
<p>对于 U-Net 这种又有下采样又有上采样的就要注意一下了，下采样再上采样得到的结果可能与原来的不同，比如 25 下采样是 12，再上采样就是 24，这样往往会出现一些问题，因此最好让输入经过下采样时不会出现除不尽的情况。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;让 keras 处理任意大小输入其实很简单，只需：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;lin
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>tf.keras重命名模型层名</title>
    <link href="https://blog.patrickcty.cc/2020/04/01/tfkeras%E9%87%8D%E5%91%BD%E5%90%8D%E6%A8%A1%E5%9E%8B/"/>
    <id>https://blog.patrickcty.cc/2020/04/01/tfkeras重命名模型/</id>
    <published>2020-04-01T13:08:27.000Z</published>
    <updated>2020-04-03T11:57:57.714Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前因后果"><a href="#前因后果" class="headerlink" title="前因后果"></a>前因后果</h2><p>为什么要重新命名模型的层名呢，目前做的是一个多任务的网络，两个网络用的是分开的 backbone，如果就这样并在一起作为一个模型的话就会有重复的层名，这个是不允许的，因此必须要重命名层名。</p>
<h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><h3 id="方法一：初始化模型的时候设置不同名字"><a href="#方法一：初始化模型的时候设置不同名字" class="headerlink" title="方法一：初始化模型的时候设置不同名字"></a>方法一：初始化模型的时候设置不同名字</h3><p>其实比较好的解决方法就是在模型的层名中加一个 prefix，对于不同的任务可以定义不同的 prefix，不过这样有一个问题，那就是载入参数的时候不能使用 <code>by_name=True</code>。</p>
<h3 id="方法二：改层名"><a href="#方法二：改层名" class="headerlink" title="方法二：改层名"></a>方法二：改层名</h3><p>不过因为我是直接用的官方的库，不想自己改 backbone，所以就只能退而求其次修改层名了，修改方法为:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">model.layers[idx]._name = &apos;aux_&apos; + l.name</div></pre></td></tr></table></figure>
<p>层的 name 属性是一个 property，不能修改，如果要修改的话使用 _name 属性，不过 _name 是一个 protected 属性，这么修改可能不是最好的方法。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前因后果&quot;&gt;&lt;a href=&quot;#前因后果&quot; class=&quot;headerlink&quot; title=&quot;前因后果&quot;&gt;&lt;/a&gt;前因后果&lt;/h2&gt;&lt;p&gt;为什么要重新命名模型的层名呢，目前做的是一个多任务的网络，两个网络用的是分开的 backbone，如果就这样并在一起作为一个
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>C语言指针的一些理解</title>
    <link href="https://blog.patrickcty.cc/2020/03/18/C%E8%AF%AD%E8%A8%80%E6%8C%87%E9%92%88%E7%9A%84%E4%B8%80%E4%BA%9B%E7%90%86%E8%A7%A3/"/>
    <id>https://blog.patrickcty.cc/2020/03/18/C语言指针的一些理解/</id>
    <published>2020-03-18T15:17:54.000Z</published>
    <updated>2020-03-18T15:41:05.558Z</updated>
    
    <content type="html"><![CDATA[<p>今天在 C 语言一个指针的问题上卡了很久……虽然平常不用 C 语言，但是还是记录一下，不能让时间白白的被浪费了。</p>
<h2 id="指针加减偏移量"><a href="#指针加减偏移量" class="headerlink" title="指针加减偏移量"></a>指针加减偏移量</h2><p>首先是指针加一个整数，加了之后偏移的字节数等于数据类型的字节数乘以整数的数值，例如：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">int</span> *a; <span class="comment">// 假设 int 是四个字节，a 地址为 1000</span></div><div class="line">a = a + <span class="number">3</span>  <span class="comment">// 地址为 1000 + 3 * 4 = 1012</span></div><div class="line"></div><div class="line"><span class="comment">// 假设 SOMESTRUCT 结构体是 52 字节</span></div><div class="line"><span class="comment">// b 地址为 10000</span></div><div class="line">SOMESTRUCT *b;</div><div class="line">b += <span class="number">44</span>; <span class="comment">// 地址为 10000 + 44 * 52 = 12288</span></div></pre></td></tr></table></figure>
<h2 id="非整数倍的偏移量"><a href="#非整数倍的偏移量" class="headerlink" title="非整数倍的偏移量"></a>非整数倍的偏移量</h2><p>如果不想偏移数据类型的整数倍怎么办？很简单，用下标取地址，比如：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">char</span> *a;</div><div class="line">&amp;a[<span class="number">7</span>]</div></pre></td></tr></table></figure>
<p>不过要注意的是这种方法只适用于 char 型的指针，其他类型的还是不行。</p>
<h2 id="文件流的偏移量"><a href="#文件流的偏移量" class="headerlink" title="文件流的偏移量"></a>文件流的偏移量</h2><p>如果要取文件流的偏移量，那就使用 stdio.h 中的 <a href="https://www.runoob.com/cprogramming/c-function-fseek.html" target="_blank" rel="external">fseek</a> 和 <a href="https://www.runoob.com/cprogramming/c-function-fread.html" target="_blank" rel="external">fread</a> 方法。</p>
<p>fseek 会将文件流指针偏移指定大小，fread 则可以将文件流的数据读取到特定的指针之中。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">FILE *fp;</div><div class="line"><span class="keyword">unsigned</span> <span class="keyword">char</span> *p;</div><div class="line"></div><div class="line"><span class="comment">// 将 fp 指针置于文件开头的第十个字节</span></div><div class="line">fseek(fp, <span class="number">10</span>, SEEK_SET);</div><div class="line"><span class="comment">// 将以下量的数据写入 p 指针中</span></div><div class="line"><span class="comment">// 每个元素大小为 100 字节，一共有一个元素</span></div><div class="line"><span class="comment">// 写成 fread(p, 1, 100, fp) 也是相同效果</span></div><div class="line">fread(p, <span class="number">100</span>, <span class="number">1</span>, fp);</div></pre></td></tr></table></figure>
<p>另外，<a href="https://www.runoob.com/cprogramming/c-function-ftell.html" target="_blank" rel="external">ftell</a> 可以让你知道给定文件流当前指针的位置，和 fseek 配合使用可以知道文件流的大小。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">fseek(fp, <span class="number">0</span>, SEEK_END);</div><div class="line"><span class="keyword">int</span> len = ftell(fp);</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今天在 C 语言一个指针的问题上卡了很久……虽然平常不用 C 语言，但是还是记录一下，不能让时间白白的被浪费了。&lt;/p&gt;
&lt;h2 id=&quot;指针加减偏移量&quot;&gt;&lt;a href=&quot;#指针加减偏移量&quot; class=&quot;headerlink&quot; title=&quot;指针加减偏移量&quot;&gt;&lt;/a&gt;指
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>理解多分类中的 mAP</title>
    <link href="https://blog.patrickcty.cc/2020/03/11/%E7%90%86%E8%A7%A3%E5%A4%9A%E5%88%86%E7%B1%BB%E4%B8%AD%E7%9A%84-k/"/>
    <id>https://blog.patrickcty.cc/2020/03/11/理解多分类中的-k/</id>
    <published>2020-03-11T02:33:33.000Z</published>
    <updated>2020-03-11T04:18:57.213Z</updated>
    
    <content type="html"><![CDATA[<p>在多分类任务中，有时候会用 mAP（Mean Average Precision）来表示分类的准确程度，如 VOC。其原因在于 mAP 能很好地评价分类的排序，而通常用的 accuracy 则往往会被最多的那个类别支配。</p>
<p>要计算多分类的 mAP，则要先计算各个类别的 AP。</p>
<h2 id="VOC-中-AP-的计算方法"><a href="#VOC-中-AP-的计算方法" class="headerlink" title="VOC 中 AP 的计算方法"></a>VOC 中 AP 的计算方法</h2><p>总的来说，就是对于某个类别，得到 n 个对该类别的预测概率，按照概率从大到小的顺序进行排列，然后对于 k∈1~n，求每个 k 对应的 Precision 和 Recall 值，对于每个 Recall 值，得到一个 Precision 值（==保证 P-R 曲线单调非递增==），将 n 个 Precision 取平均之后即为 AP 的值。要注意的是，这里不涉及到@k，因为总是为计算所有 n 个预测的结果。</p>
<p>对于一个四分类问题，已知标签和预测结果如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">y_true = np.array([[2], [1], [0], [3], [0], [1]]).astype(np.int64)</div><div class="line">y_pred = np.array([[0.1, 0.2, 0.6, 0.1],</div><div class="line">                   [0.8, 0.05, 0.1, 0.05],</div><div class="line">                   [0.3, 0.4, 0.1, 0.2],</div><div class="line">                   [0.6, 0.25, 0.1, 0.05],</div><div class="line">                   [0.1, 0.2, 0.6, 0.1],</div><div class="line">                   [0.9, 0.0, 0.03, 0.07]]).astype(np.float32)</div></pre></td></tr></table></figure>
<p>以类别 3 为例，六次预测给出的概率经过排序后为<code>[0.2  0.1  0.1  0.07 0.05 0.05]</code>，对应位置预测结果为<code>[0. 0. 0. 0. 0. 1.]</code>，0 表示预测错误，1 表示预测正确，那么可以列出来一个表：</p>
<table>
<thead>
<tr>
<th style="text-align:center">top-k</th>
<th style="text-align:center">Precision</th>
<th style="text-align:center">Recall</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">0/1</td>
<td style="text-align:center">0/1</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">0/2</td>
<td style="text-align:center">0/1</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">0/3</td>
<td style="text-align:center">0/1</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">0/4</td>
<td style="text-align:center">0/1</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">0/5</td>
<td style="text-align:center">0/1</td>
</tr>
<tr>
<td style="text-align:center">6</td>
<td style="text-align:center">1/6</td>
<td style="text-align:center">1/1</td>
</tr>
</tbody>
</table>
<p>在确保 P-R 曲线单调递减的情况下，求各个 Recall 对应的 Precision 的均值，在这里是 AP = (1/6) / 1 = 1/6</p>
<p>具体的内容参考<a href="https://link.zhihu.com/?target=http%3A//blog.sina.com.cn/s/blog_9db078090102whzw.html" target="_blank" rel="external">这一篇</a>。</p>
<p>同理可以求出来各个类别的 AP 为：<code>[1/3, 1/3, 1.0, 1/6]</code>，求均值后得到 MAP = 0.458。</p>
<p>一个 numpy 的实现为，来自这个 <a href="https://github.com/broadinstitute/keras-rcnn/issues/6" target="_blank" rel="external">issue</a>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># y_true is one-hot</span></div><div class="line"> _, classes = y_true.shape</div><div class="line">    </div><div class="line">average_precisions = []</div><div class="line"></div><div class="line"><span class="keyword">for</span> index <span class="keyword">in</span> range(classes):</div><div class="line">        <span class="comment"># 得到从大到小排序后的标签索引</span></div><div class="line">        row_indices_sorted = numpy.argsort(-y_pred[:, index])</div><div class="line"></div><div class="line">        <span class="comment"># 重新排列后的标签和预测结果</span></div><div class="line">        y_true_cls = y_true[row_indices_sorted, index]</div><div class="line">        y_pred_cls = y_pred[row_indices_sorted, index]</div><div class="line"></div><div class="line">        tp = (y_true_cls == <span class="number">1</span>)</div><div class="line">        fp = (y_true_cls == <span class="number">0</span>)</div><div class="line"></div><div class="line">        <span class="comment"># 每个位置是 top-i 的 fp 和 tp</span></div><div class="line">        fp = numpy.cumsum(fp)</div><div class="line">        tp = numpy.cumsum(tp)</div><div class="line"></div><div class="line">        <span class="comment"># 一共有多少预测正确的标签</span></div><div class="line">        npos = numpy.sum(y_true_cls)</div><div class="line"></div><div class="line">        <span class="comment"># top-i 的 recall</span></div><div class="line">        rec = tp*<span class="number">1.0</span> / npos</div><div class="line"></div><div class="line">        <span class="comment"># avoid divide by zero in case the first detection matches a difficult</span></div><div class="line">        <span class="comment"># ground truth</span></div><div class="line">        <span class="comment"># top-i 的 precision</span></div><div class="line">        prec = tp*<span class="number">1.0</span> / numpy.maximum((tp + fp), numpy.finfo(numpy.float64).eps)</div><div class="line"></div><div class="line">        <span class="comment"># 加上头和尾</span></div><div class="line">        mrec = numpy.concatenate(([<span class="number">0.</span>], rec, [<span class="number">1.</span>]))</div><div class="line">        mpre = numpy.concatenate(([<span class="number">0.</span>], prec, [<span class="number">0.</span>]))</div><div class="line"></div><div class="line">        <span class="comment"># compute the precision envelope</span></div><div class="line">        <span class="comment"># 保证 P-R 曲线单调递减</span></div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(mpre.size - <span class="number">1</span>, <span class="number">0</span>, <span class="number">-1</span>):</div><div class="line">            mpre[i - <span class="number">1</span>] = numpy.maximum(mpre[i - <span class="number">1</span>], mpre[i])</div><div class="line"></div><div class="line">        <span class="comment"># to calculate area under PR curve, look for points</span></div><div class="line">        <span class="comment"># where X axis (recall) changes value</span></div><div class="line">        i = numpy.where(mrec[<span class="number">1</span>:] != mrec[:<span class="number">-1</span>])[<span class="number">0</span>]</div><div class="line"></div><div class="line">        <span class="comment"># and sum (\Delta recall) * prec</span></div><div class="line">        <span class="comment"># 相当于求每个 recall 值对应的 precision 的均值</span></div><div class="line">        average_precisions.append(numpy.sum((mrec[i + <span class="number">1</span>] - mrec[i]) * mpre[i + <span class="number">1</span>]))</div></pre></td></tr></table></figure>
<h2 id="TnesorFlow-中的-AP"><a href="#TnesorFlow-中的-AP" class="headerlink" title="TnesorFlow 中的 AP"></a>TnesorFlow 中的 AP</h2><p>TensorFlow 中使用以下方法来计算 mAP</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">tf.compat.v1.metrics.average_precision_at_k(</div><div class="line">    labels, predictions, k, weights=None, metrics_collections=None,</div><div class="line">    updates_collections=None, name=None</div><div class="line">)</div></pre></td></tr></table></figure>
<p>但是这里并不是按照分类的标准类计算 mAP，而是对于检索来计算 mAP，而对于检索来说，总是==要考虑@k==，也就是考虑检索出来前 k 个的结果。</p>
<p>还是对于上面的例子，TF 中将 pred 看成了 6 次检索，每次检索有一个待检索对象（真值标签），检索产生四个概率值，这四个概率值的和为一。不过要注意的是，通常检索的时候待检索对象往往大于一，并且检索所产生的多个概率值的和不一定为一。</p>
<p>对于以下这一个预测结果，当 k = 1 的时候，0.8 对应的是标签 0，因此 Precision = 0/1，Recall = 0/1；k = 2，0.1 对应的是标签 2，因此 Precision = 0/2，Recall = 0/1；k = 3，0.05 对应的是标签 1，因此 Precision = 1/3，Recall = 1/1；k = 4，此时已经全部检索到了，因此 Precision = 1/3，Recall = 1。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">pred = [0.8, 0.05, 0.1, 0.05]</div><div class="line">true = [1]</div></pre></td></tr></table></figure>
<p>其他预测结果同理可求，因此 mAP@3 = (1 + 1/3 + 1/2 + 0 + 1/3 + 0) / 6 = 0.3611。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在多分类任务中，有时候会用 mAP（Mean Average Precision）来表示分类的准确程度，如 VOC。其原因在于 mAP 能很好地评价分类的排序，而通常用的 accuracy 则往往会被最多的那个类别支配。&lt;/p&gt;
&lt;p&gt;要计算多分类的 mAP，则要先计算各个
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>tensorflow遇到的坑</title>
    <link href="https://blog.patrickcty.cc/2020/03/09/tensorflow%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91/"/>
    <id>https://blog.patrickcty.cc/2020/03/09/tensorflow遇到的坑/</id>
    <published>2020-03-08T16:09:12.000Z</published>
    <updated>2020-03-08T16:22:16.401Z</updated>
    
    <content type="html"><![CDATA[<h2 id="IO-的坑"><a href="#IO-的坑" class="headerlink" title="IO 的坑"></a>IO 的坑</h2><p>对于<code>tf.io.decode_image()</code>，如果指定 <code>dtype=tf.float32</code>，那么会默认把 tensor 的值除以 255。</p>
<p>我之前就在这里直接指定了，后面还减掉了 ImageNet 的均值（[123.68, 116.779, 103.939]），所以对于任何的图，其 RGB 通道上的值都基本上是 [-123.68, -116.779, -103.939]，也难怪网络的预测结果都是数量最多的那两个标签……</p>
<p>如果要像我这么做的话，就不指定 dtype，然后再用 <code>tf.cast()</code> 将 tensor 转化为浮点型，这时候就只转换数据类型不改变值的大小了。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;IO-的坑&quot;&gt;&lt;a href=&quot;#IO-的坑&quot; class=&quot;headerlink&quot; title=&quot;IO 的坑&quot;&gt;&lt;/a&gt;IO 的坑&lt;/h2&gt;&lt;p&gt;对于&lt;code&gt;tf.io.decode_image()&lt;/code&gt;，如果指定 &lt;code&gt;dtype=tf.fl
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>colab遇到的坑</title>
    <link href="https://blog.patrickcty.cc/2020/02/28/colab%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91/"/>
    <id>https://blog.patrickcty.cc/2020/02/28/colab遇到的坑/</id>
    <published>2020-02-28T10:11:35.000Z</published>
    <updated>2020-02-28T10:19:15.662Z</updated>
    
    <content type="html"><![CDATA[<h2 id="训练特别慢"><a href="#训练特别慢" class="headerlink" title="训练特别慢"></a>训练特别慢</h2><h3 id="坑"><a href="#坑" class="headerlink" title="坑"></a>坑</h3><p>训练的数据集不要放在 google driver 里面，读取里面的文件特别慢，把 google driver 的文件拷贝到 colab 里面也特别慢。（不过把 colab 文件拷贝过去特别快）</p>
<h3 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h3><p>直接再把相关的文件下载一遍，记得提前写好相关操作的脚本，每次直接执行一下。如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">!wget http://www.cs.bu.edu/groups/ivc/data/SOS/ESOS.zip;mkdir data;mkdir data/ESOS;mv ESOS.zip data/ESOS;unzip ESOS.zip &gt; zip.log</div><div class="line">from utils.dataset_utils.SOS import create_csv</div><div class="line">create_csv(&apos;/content/data/ESOS&apos;)</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;训练特别慢&quot;&gt;&lt;a href=&quot;#训练特别慢&quot; class=&quot;headerlink&quot; title=&quot;训练特别慢&quot;&gt;&lt;/a&gt;训练特别慢&lt;/h2&gt;&lt;h3 id=&quot;坑&quot;&gt;&lt;a href=&quot;#坑&quot; class=&quot;headerlink&quot; title=&quot;坑&quot;&gt;&lt;/a&gt;坑&lt;/h
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>七牛云绑定域名的坑</title>
    <link href="https://blog.patrickcty.cc/2020/01/07/%E4%B8%83%E7%89%9B%E4%BA%91%E7%BB%91%E5%AE%9A%E5%9F%9F%E5%90%8D%E7%9A%84%E5%9D%91/"/>
    <id>https://blog.patrickcty.cc/2020/01/07/七牛云绑定域名的坑/</id>
    <published>2020-01-07T13:36:01.000Z</published>
    <updated>2020-01-07T13:38:59.035Z</updated>
    
    <content type="html"><![CDATA[<p>之前七牛云绑定域名的 SSL 证书过期了，在过期之前我已经特意申请了一个新（也是在七牛云申请的）的并绑定了，但是当旧的证书过期的时候新证书却并没有生效。</p>
<p>原因在于绑定域名的证书是通过绑定域名的配置来决定的，要手动修改相应的配置，将证书选择为新的证书，然后才会使用新的证书 orz。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;之前七牛云绑定域名的 SSL 证书过期了，在过期之前我已经特意申请了一个新（也是在七牛云申请的）的并绑定了，但是当旧的证书过期的时候新证书却并没有生效。&lt;/p&gt;
&lt;p&gt;原因在于绑定域名的证书是通过绑定域名的配置来决定的，要手动修改相应的配置，将证书选择为新的证书，然后才会使
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>最近 tf_keras 中遇到的一些坑</title>
    <link href="https://blog.patrickcty.cc/2020/01/07/%E6%9C%80%E8%BF%91keras%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9D%91/"/>
    <id>https://blog.patrickcty.cc/2020/01/07/最近keras中遇到的一些坑/</id>
    <published>2020-01-07T12:25:41.000Z</published>
    <updated>2020-02-16T01:37:54.455Z</updated>
    
    <content type="html"><![CDATA[<h2 id="文件名格式不对产生-OSError"><a href="#文件名格式不对产生-OSError" class="headerlink" title="文件名格式不对产生 OSError"></a>文件名格式不对产生 OSError</h2><h3 id="产生原因"><a href="#产生原因" class="headerlink" title="产生原因"></a>产生原因</h3><p>在使用 model.save(model_path) 的时候，由于 model_path 格式不对，而产生了 OSError，一个不对的格式是：</p>
<blockquote>
<p>Tue-Jan-7-16-59-41-2020.sos_model.035-mae.0.1543.hdf5</p>
</blockquote>
<p>可能是这个 <code>.0.</code> 导致了这个错误。</p>
<h3 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h3><p>把 mae 后面的 <code>.</code> 改成 <code>-</code> 即可，即：</p>
<blockquote>
<p>Tue-Jan-7-16-59-41-2020.sos_model.035-mae-0.1543.hdf5</p>
</blockquote>
<h2 id="在同样的环境中重复载入模型"><a href="#在同样的环境中重复载入模型" class="headerlink" title="在同样的环境中重复载入模型"></a>在同样的环境中重复载入模型</h2><h3 id="产生原因-1"><a href="#产生原因-1" class="headerlink" title="产生原因"></a>产生原因</h3><p>在同样的环境中重复载入模型会导致没有指定名称的层的名字会发生改变，比如某个卷积层的定义如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">x = layers.Conv2D(layer, (3, 3))(x)</div></pre></td></tr></table></figure>
<p>那么，第一次载入这一层的名字可能就是 conv2d，再次在同样的环境中载入，名字可能就变成了 conv2d_1。</p>
<p>这一点要特别注意一下，特别是在 notebook 中运行的时候，很可能会让原本功能正常的方法报错。</p>
<blockquote>
<p>另外，不用担心同一个环境中加载的不同模型有同样的层名会有问题，因为不在一个计算图里面，所以不会产生冲突。</p>
</blockquote>
<h3 id="解决方法-1"><a href="#解决方法-1" class="headerlink" title="解决方法"></a>解决方法</h3><p>报错了就清除当前的上下文，notebook 里面就重启 kernel。</p>
<h2 id="lr-multiplier-无法正确读入自定义的优化器"><a href="#lr-multiplier-无法正确读入自定义的优化器" class="headerlink" title="lr multiplier 无法正确读入自定义的优化器"></a>lr multiplier 无法正确读入自定义的优化器</h2><h3 id="产生原因-2"><a href="#产生原因-2" class="headerlink" title="产生原因"></a>产生原因</h3><p><a href="https://github.com/CyberZHG/keras-lr-multiplier" target="_blank" rel="external">原模块</a>引入 keras 的方法可能和现在的方法不匹配。</p>
<h3 id="解决方法-2"><a href="#解决方法-2" class="headerlink" title="解决方法"></a>解决方法</h3><p>把源文件复制到当前项目下，再改一下引入就正常了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># 修改之后的方法</div><div class="line">import tensorflow.python.keras.optimizers as optimizers</div></pre></td></tr></table></figure>
<h2 id="plot-model-报缺少-graphviz-的错"><a href="#plot-model-报缺少-graphviz-的错" class="headerlink" title="plot_model 报缺少 graphviz 的错"></a>plot_model 报缺少 graphviz 的错</h2><p>直接运行 <code>plot_model</code> 的时候会报缺少依赖的错误，安装了相关依赖之后还有相同的错误，如下所示:</p>
<blockquote>
<p>keras ImportError: Failed to import pydot. You must install pydot and graphviz for <code>pydotprint</code> to work.</p>
</blockquote>
<h3 id="产生原因-3"><a href="#产生原因-3" class="headerlink" title="产生原因"></a>产生原因</h3><p>graphviz 需要系统级的安装。</p>
<h3 id="解决方法-3"><a href="#解决方法-3" class="headerlink" title="解决方法"></a>解决方法</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"># for mac</div><div class="line">brew install graphviz</div><div class="line"></div><div class="line"># for ubuntu</div><div class="line">sudo apt-get install graphviz</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;文件名格式不对产生-OSError&quot;&gt;&lt;a href=&quot;#文件名格式不对产生-OSError&quot; class=&quot;headerlink&quot; title=&quot;文件名格式不对产生 OSError&quot;&gt;&lt;/a&gt;文件名格式不对产生 OSError&lt;/h2&gt;&lt;h3 id=&quot;产生原因&quot;
    
    </summary>
    
    
      <category term="keras" scheme="https://blog.patrickcty.cc/tags/keras/"/>
    
  </entry>
  
  <entry>
    <title>部署tf_keras模型遇到的坑</title>
    <link href="https://blog.patrickcty.cc/2019/12/14/%E9%83%A8%E7%BD%B2tf-keras%E6%A8%A1%E5%9E%8B%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91/"/>
    <id>https://blog.patrickcty.cc/2019/12/14/部署tf-keras模型遇到的坑/</id>
    <published>2019-12-14T03:20:19.000Z</published>
    <updated>2019-12-14T03:22:21.364Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一次-load-多次-predict"><a href="#一次-load-多次-predict" class="headerlink" title="一次 load 多次 predict"></a>一次 load 多次 predict</h2><p>由于 TensorFlow 使用的是静态图，因此默认并不能做到一次 load 然后就任意在其他的地方调用，因此需要以下方法来做到：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># load</span></div><div class="line">model = load_model(<span class="string">'path_to_model'</span>)</div><div class="line">graph = tf.get_default_graph()</div><div class="line"></div><div class="line"><span class="comment"># predict, maybe in another thread</span></div><div class="line"><span class="keyword">global</span> graph</div><div class="line"><span class="keyword">with</span> graph.as_default():</div><div class="line">    model.predict()</div></pre></td></tr></table></figure>
<h2 id="限制不要占满-GPU-显存"><a href="#限制不要占满-GPU-显存" class="headerlink" title="限制不要占满 GPU 显存"></a>限制不要占满 GPU 显存</h2><p>TensorFlow 默认的机制是会占用满 GPU，但是可以通过设置 allow_growth 来只使用必须的显存：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="keyword">from</span> tensorflow.python.keras.backend <span class="keyword">import</span> set_session</div><div class="line"></div><div class="line">config = tf.ConfigProto()</div><div class="line">config.gpu_options.allow_growth = <span class="keyword">True</span></div><div class="line">sess = tf.Session(config=config)</div><div class="line">set_session(sess)  <span class="comment"># 必须要先设置 session 才能 load model</span></div></pre></td></tr></table></figure>
<p>进行这样设置之后如果要在多个不同情况下调用模型则也必须每次都设置 session：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># predict, maybe in another thread</span></div><div class="line"><span class="keyword">global</span> graph</div><div class="line"><span class="keyword">global</span> sess</div><div class="line"><span class="keyword">with</span> graph.as_default():</div><div class="line">    set_session(sess)</div><div class="line">    model.predict()</div></pre></td></tr></table></figure>
<h2 id="忽视掉-TensorFlow-的一大堆初始化-log"><a href="#忽视掉-TensorFlow-的一大堆初始化-log" class="headerlink" title="忽视掉 TensorFlow 的一大堆初始化 log"></a>忽视掉 TensorFlow 的一大堆初始化 log</h2><p>log level 为 3 的话就只会输出错误信息了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">os.environ[<span class="string">'TF_CPP_MIN_LOG_LEVEL'</span>] = <span class="string">'3'</span></div><div class="line">tf.get_logger().setLevel(<span class="string">'ERROR'</span>)</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;一次-load-多次-predict&quot;&gt;&lt;a href=&quot;#一次-load-多次-predict&quot; class=&quot;headerlink&quot; title=&quot;一次 load 多次 predict&quot;&gt;&lt;/a&gt;一次 load 多次 predict&lt;/h2&gt;&lt;p&gt;由于 Ten
    
    </summary>
    
    
      <category term="TensorFlow" scheme="https://blog.patrickcty.cc/tags/TensorFlow/"/>
    
      <category term="keras" scheme="https://blog.patrickcty.cc/tags/keras/"/>
    
  </entry>
  
  <entry>
    <title>配置内网穿透</title>
    <link href="https://blog.patrickcty.cc/2019/11/20/%E9%85%8D%E7%BD%AE%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/"/>
    <id>https://blog.patrickcty.cc/2019/11/20/配置内网穿透/</id>
    <published>2019-11-20T09:03:14.000Z</published>
    <updated>2019-11-20T10:29:44.214Z</updated>
    
    <content type="html"><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>内网穿透，顾名思义就是从外网访问一个在内网的服务器。我们实验室的 GPU 服务器都是在内网里面，远程访问非常不方便，为了以防万一，还是需要配配置一个内网穿透。</p>
<h2 id="frp"><a href="#frp" class="headerlink" title="frp"></a>frp</h2><p>这里介绍使用 <a href="https://github.com/fatedier/frp" target="_blank" rel="external">frp</a> 配置内网穿透的过程。</p>
<blockquote>
<p>frp 是一个可用于内网穿透的高性能的反向代理应用，支持 tcp, udp 协议，为 http 和 https 应用协议提供了额外的能力，且尝试性支持了点对点穿透。</p>
</blockquote>
<h2 id="Requirements"><a href="#Requirements" class="headerlink" title="Requirements"></a>Requirements</h2><ul>
<li>一个有外网 ip 的服务器：作为内网服务器与客户端的中介</li>
<li>frp 运行文件：这个服务器和客户端都要下载，链接在<a href="https://github.com/fatedier/frp/releases" target="_blank" rel="external">这里</a></li>
</ul>
<h2 id="服务器配置"><a href="#服务器配置" class="headerlink" title="服务器配置"></a>服务器配置</h2><ol>
<li>下载 frp 文件，解压</li>
<li><p>进入相应文件夹，编辑 frps.ini</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"># frps.ini</div><div class="line">[common]</div><div class="line">bind_port = 7000 # frp运行端口,需要开放防火墙</div><div class="line">vhost_http_port = 8080 # http服务端口,可以 和 bind_port 相同</div></pre></td></tr></table></figure>
</li>
<li><p>启动 ./frps -c ./frps.ini</p>
</li>
</ol>
<h2 id="客户端配置"><a href="#客户端配置" class="headerlink" title="客户端配置"></a>客户端配置</h2><ol>
<li>下载 frp 文件，解压</li>
<li><p>进入相应文件夹，编辑 frpc.ini（注意是 frpc）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"># frpc.ini</div><div class="line">[common]</div><div class="line">server_addr = 上一步的服务器地址</div><div class="line">server_port = 上一步填写的端口</div><div class="line"></div><div class="line">[ssh]</div><div class="line">type = tcp</div><div class="line">local_ip = 127.0.0.1</div><div class="line">local_port = 22</div><div class="line">remote_port = 6000  # 通过这个端口来访问</div></pre></td></tr></table></figure>
</li>
<li><p>启动 ./frpc -c ./frpc.ini</p>
</li>
<li>使用 ssh 访问 <code>ssh -oPort 6000 ssh_name@ssh_ip</code></li>
</ol>
<h2 id="多个客户端配置"><a href="#多个客户端配置" class="headerlink" title="多个客户端配置"></a>多个客户端配置</h2><p>多个客户端配置只要 ssh 下的 remote_port 不冲突即可<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"># frpc2.ini</div><div class="line">[common]</div><div class="line">server_addr = 上一步的服务器地址</div><div class="line">server_port = 上一步填写的端口</div><div class="line"></div><div class="line">[ssh]</div><div class="line">type = tcp</div><div class="line">local_ip = 127.0.0.1</div><div class="line">local_port = 22</div><div class="line">remote_port = 6001  # 这个地方不冲突即可</div><div class="line"></div><div class="line"># 使用 ssh 访问 ssh -oPort 6001 ssh_name@ssh_ip</div></pre></td></tr></table></figure></p>
<h2 id="配置客户端-http-访问"><a href="#配置客户端-http-访问" class="headerlink" title="配置客户端 http 访问"></a>配置客户端 http 访问</h2><ol>
<li><p>修改客户端上 frpc.ini 文件，加入以下内容</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[web]</div><div class="line">type = http</div><div class="line">local_port = 80  # 或者是其他的端口也都可以</div><div class="line">custom_domains = www.example.com</div></pre></td></tr></table></figure>
</li>
<li><p>访问网页 <code>www.example.com:8080</code>(这个端口是服务器 frps.ini 里面的 vhost_http_port)</p>
</li>
</ol>
<h2 id="将-frp-添加到启动项"><a href="#将-frp-添加到启动项" class="headerlink" title="将 frp 添加到启动项"></a>将 frp 添加到启动项</h2><ol>
<li><p><code>sudo vim /lib/systemd/system/frps.service</code>，添加以下内容</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">[Unit]</div><div class="line">Description=frps</div><div class="line">After=network.target</div><div class="line"></div><div class="line">[Service]</div><div class="line">TimeoutStartSec=30</div><div class="line">ExecStart=$&#123;frps的绝对路径&#125; -c $&#123;frps.ini的绝对路径&#125;</div><div class="line">ExecStop=/bin/kill $MAINPID</div><div class="line"></div><div class="line">[Install]</div><div class="line">WantedBy=multi-user.target</div></pre></td></tr></table></figure>
</li>
<li><p>启用服务</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">systemctl enable frps</div><div class="line">systemctl start frps</div><div class="line">systemctl status frps</div></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li><a href="https://blog.xinshangshangxin.com/2018/06/18/frp/" target="_blank" rel="external">https://blog.xinshangshangxin.com/2018/06/18/frp/</a></li>
<li><a href="https://github.com/fatedier/frp/issues/407" target="_blank" rel="external">https://github.com/fatedier/frp/issues/407</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h2&gt;&lt;p&gt;内网穿透，顾名思义就是从外网访问一个在内网的服务器。我们实验室的 GPU 服务器都是在内网里面，远程访问非常不方便，为了以防万一，还是需要配
    
    </summary>
    
      <category term="utils" scheme="https://blog.patrickcty.cc/categories/utils/"/>
    
    
      <category term="内网穿透" scheme="https://blog.patrickcty.cc/tags/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/"/>
    
  </entry>
  
  <entry>
    <title>使用keras进行语义分割注意事项</title>
    <link href="https://blog.patrickcty.cc/2019/08/22/%E4%BD%BF%E7%94%A8keras%E8%BF%9B%E8%A1%8C%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/"/>
    <id>https://blog.patrickcty.cc/2019/08/22/使用keras进行语义分割注意事项/</id>
    <published>2019-08-22T12:37:28.000Z</published>
    <updated>2019-08-22T12:38:25.198Z</updated>
    
    <content type="html"><![CDATA[<h2 id="总览"><a href="#总览" class="headerlink" title="总览"></a>总览</h2><ul>
<li>载入数据<ul>
<li>图像和标签相对应</li>
<li>数据预处理与增强</li>
<li>标签处理</li>
<li>标签还原与可视化预测结果 </li>
<li>多输入/出处理</li>
</ul>
</li>
<li>网络结构<ul>
<li>反卷积</li>
<li>上采样</li>
<li>todo</li>
</ul>
</li>
<li>训练脚本<ul>
<li>Warm-up</li>
<li>多输入/出（合并到第一部分）</li>
</ul>
</li>
</ul>
<h2 id="载入数据"><a href="#载入数据" class="headerlink" title="载入数据"></a>载入数据</h2><h3 id="图像和标签对应"><a href="#图像和标签对应" class="headerlink" title="图像和标签对应"></a>图像和标签对应</h3><p>语义分割中需要同时载入图像和标签，和分类问题不一样，语义分割的标签也是图像，因此要和载入的图像相对应。</p>
<p>如果使用 keras 自带的 ImageDataGenerator 来获取数据则需要分别为图像和标签初始化两个对象，并传入相同的随机化种子，具体操作如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"># we create two instances with the same arguments</div><div class="line">data_gen_args = dict(featurewise_center=True,</div><div class="line">                     featurewise_std_normalization=True,</div><div class="line">                     rotation_range=90,</div><div class="line">                     width_shift_range=0.1,</div><div class="line">                     height_shift_range=0.1,</div><div class="line">                     zoom_range=0.2)</div><div class="line">image_datagen = ImageDataGenerator(**data_gen_args)</div><div class="line">mask_datagen = ImageDataGenerator(**data_gen_args)</div><div class="line"></div><div class="line"># Provide the same seed and keyword arguments to the fit and flow methods</div><div class="line">seed = 1</div><div class="line">image_datagen.fit(images, augment=True, seed=seed)</div><div class="line">mask_datagen.fit(masks, augment=True, seed=seed)</div><div class="line"></div><div class="line">image_generator = image_datagen.flow_from_directory(</div><div class="line">    directory=&apos;data&apos;,</div><div class="line">    class_mode=None,</div><div class="line">    classes=[&apos;图像文件夹的名字&apos;],</div><div class="line">    seed=seed)</div><div class="line"></div><div class="line">mask_generator = mask_datagen.flow_from_directory(</div><div class="line">    &apos;data&apos;,</div><div class="line">    class_mode=None,</div><div class="line">    classes=[&apos;标签文件夹的名字&apos;],</div><div class="line">    seed=seed)</div><div class="line"></div><div class="line"># combine generators into one which yields image and masks</div><div class="line">train_generator = zip(image_generator, mask_generator)</div><div class="line"></div><div class="line">model.fit_generator(</div><div class="line">    directory=train_generator,</div><div class="line">    # 要指定这个参数，因为 zip 之后无法知道</div><div class="line">    # 每个 epoch 有多少次迭代</div><div class="line">    steps_per_epoch=2000,</div><div class="line">    epochs=50)</div></pre></td></tr></table></figure>
<p>其中要注意的有：</p>
<ul>
<li><code>flow_from_directory</code> 方法是通过 directory + class name 来寻找图片的，也就是说如果在这里让 <code>directory=&#39;data/images&#39;</code> 并且不设置 classes 则无法读取到图片；另外，<code>classes</code> 应该传入一个列表；还有则是 <code>class_mode</code> 要设置为 None，不然就会根据子文件夹名返回标签</li>
<li><code>fit_generator</code> 中要指定 <code>steps_per_epoch</code>，在这里可以通过 <code>ceil(len(image_generator / batch_size)</code> 来计算</li>
<li><code>fit</code> 和 <code>flow</code> 传入相同的随机化种子以保证生成相对应的图片</li>
</ul>
<h3 id="图像预处理与增强"><a href="#图像预处理与增强" class="headerlink" title="图像预处理与增强"></a>图像预处理与增强</h3><ul>
<li>标准化: <ul>
<li><code>img = (img - img_mean) / img_std</code></li>
<li>简化起见也可以 <code>img = img / 255 - 0.5</code></li>
</ul>
</li>
<li>数据增强：<ul>
<li>语义分割中最主要的增强是通过随机裁剪来进行的 ，具体的操作是把一张很大的图片随机裁剪出若干张(256, 256) 大小的图片，这样既增加了数据大小，也避免缩放出现的信息丢失</li>
<li>todo：还需要进一步查看文档</li>
</ul>
</li>
</ul>
<h3 id="标签处理"><a href="#标签处理" class="headerlink" title="标签处理"></a>标签处理</h3><p>由于语义分割的标签是和原图像同样大小的彩色图片，并且为了标注的方便，标签图像用一种颜色，也就是一组 RGB 的值来表示一种类别。</p>
<p>在进行损失函数的计算时，我们需要将 RGB 值转换成一组 one-hot 的标签，并且把图片拉成一个向量（以便于计算交叉熵损失）。比如对于 (256, 256, 3) 的标签，我们要将其转变成 (256 <strong> 2, 3) 的向量，然后转换为 (256 </strong> 2, num_classes) 的 one-hot 形式。具体的操作如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"># VOC 中的列表表示</div><div class="line">VOC_COLORMAP = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0],</div><div class="line">                [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128],</div><div class="line">                [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0],</div><div class="line">                [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128],</div><div class="line">                [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],</div><div class="line">                [0, 64, 128]]</div><div class="line"></div><div class="line">VOC_CLASSES = [&apos;background&apos;, &apos;aeroplane&apos;, &apos;bicycle&apos;, &apos;bird&apos;, &apos;boat&apos;,</div><div class="line">               &apos;bottle&apos;, &apos;bus&apos;, &apos;car&apos;, &apos;cat&apos;, &apos;chair&apos;, &apos;cow&apos;,</div><div class="line">               &apos;diningtable&apos;, &apos;dog&apos;, &apos;horse&apos;, &apos;motorbike&apos;, &apos;person&apos;,</div><div class="line">               &apos;potted plant&apos;, &apos;sheep&apos;, &apos;sofa&apos;, &apos;train&apos;, &apos;tv/monitor&apos;]</div><div class="line"></div><div class="line"># 完成 RGB 与类别数值的映射</div><div class="line">colormap2label = np.zeros(256 ** 3)</div><div class="line">label2colormap = np.zeros_like(VOC_CLASSES)</div><div class="line">for i, colormap in enumerate(VOC_COLORMAP):</div><div class="line">    idx = (colormap[0] * 256 + colormap[1]) * 256 + colormap[2]</div><div class="line">    colormap2label[idx] = i</div><div class="line">    label2colormap[i] = idx</div><div class="line"></div><div class="line">def mask_preprocessing(mask):</div><div class="line">    mask = mask.astype(&apos;int32&apos;)</div><div class="line">    if len(mask.shape) == 3:  # 输入为单个图片</div><div class="line">        w, h, _ = mask.shape</div><div class="line">        # 将 RGB 的类别值转换成单一数字表示的的类别值</div><div class="line">        idx = ((mask[:, :, 0] * 256 + mask[:, :, 1]) * 256 + mask[:, :, 2])</div><div class="line">        # 将图片拉成向量</div><div class="line">        new_mask = colormap2label[idx].reshape((w * h, -1))</div><div class="line">    else:  # len == 4  # 输入为一个 batch 的图片</div><div class="line">        b, w, h, _ = mask.shape</div><div class="line">        idx = ((mask[:, :, :, 0] * 256 + mask[:, :, :, 1]) * 256 + mask[:, :, :, 2])</div><div class="line">        new_mask = colormap2label[idx].reshape((b, w * h, -1))</div><div class="line">    # 将标签转换为 one-hot 的形式</div><div class="line">    r_mask = to_categorical(new_mask, num_classes=self.config.num_classes)</div><div class="line">    return r_mask</div></pre></td></tr></table></figure>
<h3 id="标签还原与可视化预测结果"><a href="#标签还原与可视化预测结果" class="headerlink" title="标签还原与可视化预测结果"></a>标签还原与可视化预测结果</h3><p>预测结果的标签和输入的一样都是一个 (w * h, num_classes) 的 one-hot 矩阵，我们要先将其变成非 one-hot 的类别形式，然后再还原成 RGB 的形式，然后将其变成图片的形状，之后输出的标签就和标注好的标签比较类似了。操作方法如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"># 将图片从单个数字表示的类别映射回 RGB</div><div class="line">def labelVisualize(self, num_class, img):</div><div class="line">    img = img[:, :, 0] if len(img.shape) == 3 else img</div><div class="line">    img_out = np.zeros(img.shape + (3,))</div><div class="line">    for i in range(num_class):</div><div class="line">        img_out[img == i, :] = VOC_COLORMAP[i]</div><div class="line">    return img_out / 255</div><div class="line"></div><div class="line">def mask_propressing(predict_mask_list, save_to=None):</div><div class="line">    # 这里是因为有多个输出因此要用循环来处理</div><div class="line">    for i in range(len(predict_mask_list)):</div><div class="line">        # 将 one-hot 还原</div><div class="line">        num_classes = predict_mask_list[0].shape[-1]</div><div class="line">        predict_mask = predict_mask_list[i]</div><div class="line">        num_classes = predict_mask.shape[-1]</div><div class="line">        mkdir_if_not_exist(os.path.join(save_to, str(i)))</div><div class="line">        if len(predict_mask.shape) == 3:  # (?, 65536, 21)</div><div class="line">            temp_mask = predict_mask.reshape((predict_mask.shape[0], self.config.input_shape,</div><div class="line">                                              self.config.input_shape, num_classes))</div><div class="line">            for item in temp_mask:</div><div class="line">                img = self.labelVisualize(num_classes, item)</div><div class="line">                if save_to:</div><div class="line">                    io.imsave(os.path.join(save_to, str(i), &apos;%s_pred.png&apos; % str(uuid.uuid4())[:4]), img)</div><div class="line"></div><div class="line">        else:  # (65536, 21)</div><div class="line">            temp_mask = predict_mask.reshape((self.config.input_shape, self.config.input_shape, num_classes))</div><div class="line">            img = self.labelVisualize(num_classes, temp_mask)</div><div class="line">            if save_to:</div><div class="line">                io.imsave(os.path.join(save_to, str(i), &apos;%s_pred.png&apos; % str(uuid.uuid4())[:4]), img)</div></pre></td></tr></table></figure>
<h3 id="多输出处理"><a href="#多输出处理" class="headerlink" title="多输出处理"></a>多输出处理</h3><p>如果神经网络有多输入/出，则对于每个输入和输出都要有相应的标签进行对应：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"># 输入到 fit_generator 的形式</div><div class="line"># tuple 的第一个第二个分别是输入和输入</div><div class="line"># 多个不同的通过名字和数据的字典来对应</div><div class="line">(&#123;&apos;input1&apos;: img1, &apos;input2&apos;, img2&#125;, </div><div class="line"> &#123;&apos;pred1&apos;: mask1, &apos;pred2&apos;: mask2, &apos;pred3&apos;: mask3&#125;)</div><div class="line"> </div><div class="line"># 输入 comple 的形式</div><div class="line"># 这里主要是对输入的内容进行指定</div><div class="line">model.compile(optimizer=&apos;rmsprop&apos;,</div><div class="line">              loss=&#123;&apos;pred1&apos;: &apos;binary_crossentropy&apos;, &apos;pred2&apos;: &apos;binary_crossentropy&apos;&#125;,</div><div class="line">              &apos;pred3&apos;: &apos;binary_crossentropy&apos;&#125;,</div><div class="line">              loss_weights=&#123;&apos;pred1&apos;: 1., &apos;pred2&apos;: 0.2, &apos;pred3&apos;: 0.2&#125;)</div></pre></td></tr></table></figure>
<h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p>todo</p>
<h2 id="训练脚本"><a href="#训练脚本" class="headerlink" title="训练脚本"></a>训练脚本</h2><h3 id="Warm-up"><a href="#Warm-up" class="headerlink" title="Warm-up"></a>Warm-up</h3><p>在开始的时候使用比较小的学习率训练，再使用正常的学习率训练，这种方法可以防止神经网络在一开始跑向了错误的方向而取得不理想的效果。</p>
<p>假设初始的学习率为 <code>lr_init</code>，warm-up 的 epoch 数为 <code>num</code>，当前 epoch 数为 <code>i</code>（从 1 开始计数），则当前学习率为：<code>lr = lr_init * i / num (i &lt; num)</code>。</p>
<p>在 keras 里面可以用 LeaningRateScheduler 的回调来实现：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">def lr_scheduler_warm_up(epoch_idx, cur_lr):</div><div class="line">    if epoch_idx == 0:</div><div class="line">        return cur_lr / 5</div><div class="line">    if epoch_idx &lt; 5:  # 前五个 epoch</div><div class="line">        return cur_lr * (epoch_idx + 1) / epoch_idx</div><div class="line">    return cur_lr</div><div class="line"></div><div class="line">lr_warm_up = LearningRateScheduler(lr_scheduler_warm_up)</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;总览&quot;&gt;&lt;a href=&quot;#总览&quot; class=&quot;headerlink&quot; title=&quot;总览&quot;&gt;&lt;/a&gt;总览&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;载入数据&lt;ul&gt;
&lt;li&gt;图像和标签相对应&lt;/li&gt;
&lt;li&gt;数据预处理与增强&lt;/li&gt;
&lt;li&gt;标签处理&lt;/li&gt;
&lt;li&gt;标
    
    </summary>
    
      <category term="keras" scheme="https://blog.patrickcty.cc/categories/keras/"/>
    
      <category term="深度学习" scheme="https://blog.patrickcty.cc/categories/keras/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="语义分割" scheme="https://blog.patrickcty.cc/categories/keras/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    
    
      <category term="语义分割" scheme="https://blog.patrickcty.cc/tags/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    
  </entry>
  
  <entry>
    <title>深度学习一些概念整理</title>
    <link href="https://blog.patrickcty.cc/2019/05/03/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5%E6%95%B4%E7%90%86/"/>
    <id>https://blog.patrickcty.cc/2019/05/03/深度学习一些概念整理/</id>
    <published>2019-05-03T03:26:37.000Z</published>
    <updated>2019-12-30T13:48:30.511Z</updated>
    
    <content type="html"><![CDATA[<h2 id="全连接层转换为卷积层"><a href="#全连接层转换为卷积层" class="headerlink" title="全连接层转换为卷积层"></a>全连接层转换为卷积层</h2><h3 id="如何转换"><a href="#如何转换" class="headerlink" title="如何转换"></a>如何转换</h3><p>卷积层与全连接层可以相互转换，例如，对于输入为 7 <em> 7 </em> 512 的有 4096 个神经元的全连接层，可以表示为如下的卷积层：</p>
<ul>
<li>Kernel size: 7</li>
<li>Padding: 0</li>
<li>Stride: 1</li>
<li>Filters: 4096</li>
</ul>
<p>这样卷积层输出就是 1 <em> 1 </em> 4096，与全连接层的输出相同。</p>
<h3 id="转换的原理"><a href="#转换的原理" class="headerlink" title="转换的原理"></a>转换的原理</h3><p>还是以上面的为例，全连接层的每个输出（1/4096）需要输入的每一个元素都参与，即：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Dense_&#123;out_i&#125; = \Sigma_&#123;j=1&#125;^&#123;25088&#125;&#123;(w_&#123;ij&#125; * in_j)&#125; \\ i = 1, 2, \dots, 4096</div></pre></td></tr></table></figure>
<p>而对应的卷积层的输出也是需要每个元素的参与，即：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Conv_&#123;out_i&#125; = \Sigma_&#123;j=1&#125;^&#123;512&#125;&#123;\Sigma_&#123;k=1&#125;^&#123;49&#125;&#123;(w_&#123;ijk&#125; * in_&#123;jk&#125;)&#125;&#125; \\ i = 1, 2, \dots, 4096</div></pre></td></tr></table></figure>
<p>可以看出来，本质没有变，只是形式变了。</p>
<h3 id="转换的作用"><a href="#转换的作用" class="headerlink" title="转换的作用"></a>转换的作用</h3><ul>
<li>便于计算不同分辨率的输入</li>
</ul>
<p>比如 AlexNet 输入为 227 <em> 227，如果输入为 384 </em> 384 则到了全连接层会报错，而如果进行了如上转换，则会正常输出，不过输出结果为 6 <em> 6 </em> 1000 而非 1 <em> 1 </em> 1000。</p>
<p>实际上，常用于分割任务上的全卷积网络（FCN）就使用了这种方法去掉了全连接层以支持不同分辨率的输入。</p>
<h2 id="1-1-卷积核作用"><a href="#1-1-卷积核作用" class="headerlink" title="1 * 1 卷积核作用"></a>1 * 1 卷积核作用</h2><ul>
<li>实现数据维度改变</li>
</ul>
<p>可以把维度从 m <em> n </em> 10 改变到 m <em> n </em> 5 或者 m <em> n </em> 50，只需要改变 filter 的数量</p>
<ul>
<li>实现跨通道的交互信息的整合</li>
</ul>
<p>由于次个卷积会把多个通道的信息汇总，因此这个 1 * 1 卷积的过程也会把跨通道的交互信息整合起来</p>
<ul>
<li>增加非线性</li>
</ul>
<p>通过卷积之后的非线性激活函数来实现</p>
<p>具体讲解参考<a href="https://zhuanlan.zhihu.com/p/40050371" target="_blank" rel="external">这篇文章</a>。</p>
<h2 id="Global-Average-Pooling-GAP-作用"><a href="#Global-Average-Pooling-GAP-作用" class="headerlink" title="Global Average Pooling (GAP) 作用"></a>Global Average Pooling (GAP) 作用</h2><p>GAP 是用来将每个通道的信息统一到同一个像素上，比如输入为 7 <em> 7 </em> 512 的张量，经过 GAP 之后输出就是 1 <em> 1 </em> 512。</p>
<ul>
<li>代替全连接层</li>
</ul>
<p>CNN 最后一层卷积的输出就是一个高度提取的 feature map（本质上是特征），而全连接层就是将最后一层卷积得到的特征整合起来映射到样本空间（分类，识别等）（由于有非线性激活函数，因此不是线性映射）。</p>
<p>具体理解参照<a href="https://www.zhihu.com/question/41037974/answer/320267531" target="_blank" rel="external">这个回答</a>。</p>
<p>关于 GAP 的效果对比可以参考<a href="https://www.cnblogs.com/hutao722/p/10008581.html" target="_blank" rel="external">这篇博客</a>。</p>
<p>我自己在小型的神经网络上训练的结果（GAP 代替了 128 FC）是使用 GAP 提高了 2% 左右的准确度。</p>
<h2 id="batch"><a href="#batch" class="headerlink" title="batch"></a>batch</h2><p>深度学习更新参数通常不是由一个数据来决定的，不然更新的方向可能会差别较大（一下这边一下那边）。</p>
<p>一批里面有多个数据更容易朝着正确的方向进行，利用各个数据之间的一些共性。</p>
<p>另外，使用批处理也避免了一次使用所有数据进行训练，减小了显存的压力，也更有可能找到极小值。</p>
<h2 id="epoch"><a href="#epoch" class="headerlink" title="epoch"></a>epoch</h2><p>一个完整的数据集经过网络一次并返回一次的结果。一个 epoch 并不一定能让网络达到最佳的方向，因而要训练多个 epoch，但是训练过多会过拟合。</p>
<h2 id="Batch-Normalization-作用"><a href="#Batch-Normalization-作用" class="headerlink" title="Batch Normalization 作用"></a>Batch Normalization 作用</h2><p>将一个 batch 中的各个元素归一化（各个通道分别进行 BN），通常放到激活函数之前。</p>
<p>好处：</p>
<ul>
<li>减小梯度弥散（梯度消失/爆炸）</li>
</ul>
<p>改变激活函数的输入，让数据分布更均匀，从而杀掉的神经元更少。</p>
<ul>
<li>训练更快，可以用更高的学习率</li>
</ul>
<p>数据分布更均匀，神经网络不用去适应各种分布</p>
<ul>
<li>一定程度增加泛化能力，避免过拟合</li>
</ul>
<p>数据通过 BN 处理引入的随机噪声能够起到对模型参数进行正则化的作用，有利于增强模型泛化能力</p>
<p>缺陷：</p>
<ul>
<li>不适用 batch 非常小</li>
<li>不适用 RNN</li>
</ul>
<p>关于 BN 的理解，尤其是背后的原理理解参考<a href="https://www.jiqizhixin.com/articles/2018-08-29-7" target="_blank" rel="external">这篇文章</a></p>
<h2 id="验证-测试集的作用"><a href="#验证-测试集的作用" class="headerlink" title="验证/测试集的作用"></a>验证/测试集的作用</h2><h3 id="验证集"><a href="#验证集" class="headerlink" title="验证集"></a>验证集</h3><ul>
<li>与测试集同分布，用来观察训练的走向（是否过拟合等）</li>
<li>选择超参数</li>
</ul>
<h3 id="测试集"><a href="#测试集" class="headerlink" title="测试集"></a>测试集</h3><p>评估模型的训练状况，检验泛化能力</p>
<h2 id="Softmax-是什么"><a href="#Softmax-是什么" class="headerlink" title="Softmax 是什么"></a>Softmax 是什么</h2><p>Softmax 函数用来产生 k 个概率，而 Softmax 损失函数，准确来说是用 Softmax 的结果来计算交叉熵分类损失函数。</p>
<p>Softmax 函数可以参考<a href="https://blog.csdn.net/ture_dream/article/details/54948518" target="_blank" rel="external">这篇博文</a>，交叉熵可以参考<a href="https://zhuanlan.zhihu.com/p/35709485" target="_blank" rel="external">这篇博文</a>。</p>
<h2 id="logits-是什么"><a href="#logits-是什么" class="headerlink" title="logits 是什么"></a>logits 是什么</h2><p>出现于 <code>tf.nn.softmax_cross_entropy_with_logits</code>，简单来说就是 softmax 的输入。更多内容可以参考<a href="https://www.zhihu.com/question/60751553" target="_blank" rel="external">这个问题</a>。</p>
<h2 id="weight-的冷知识"><a href="#weight-的冷知识" class="headerlink" title="weight 的冷知识"></a>weight 的冷知识</h2><p>weight decay = 对 weight 施加 norm = 对输入数据增加方差小的噪音</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;全连接层转换为卷积层&quot;&gt;&lt;a href=&quot;#全连接层转换为卷积层&quot; class=&quot;headerlink&quot; title=&quot;全连接层转换为卷积层&quot;&gt;&lt;/a&gt;全连接层转换为卷积层&lt;/h2&gt;&lt;h3 id=&quot;如何转换&quot;&gt;&lt;a href=&quot;#如何转换&quot; class=&quot;head
    
    </summary>
    
      <category term="深度学习" scheme="https://blog.patrickcty.cc/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Batch Normalization" scheme="https://blog.patrickcty.cc/tags/Batch-Normalization/"/>
    
      <category term="Global Average Pooling" scheme="https://blog.patrickcty.cc/tags/Global-Average-Pooling/"/>
    
      <category term="Deep Learning" scheme="https://blog.patrickcty.cc/tags/Deep-Learning/"/>
    
      <category term="CNN" scheme="https://blog.patrickcty.cc/tags/CNN/"/>
    
  </entry>
  
  <entry>
    <title>cifar100实验</title>
    <link href="https://blog.patrickcty.cc/2019/05/03/cifar100%E5%AE%9E%E9%AA%8C/"/>
    <id>https://blog.patrickcty.cc/2019/05/03/cifar100实验/</id>
    <published>2019-05-03T02:44:20.000Z</published>
    <updated>2019-05-03T02:45:03.723Z</updated>
    
    <content type="html"><![CDATA[<h2 id="实验一：初步探究-BN-作用"><a href="#实验一：初步探究-BN-作用" class="headerlink" title="实验一：初步探究 BN 作用"></a>实验一：初步探究 BN 作用</h2><h3 id="基本配置"><a href="#基本配置" class="headerlink" title="基本配置"></a>基本配置</h3><ul>
<li>A：使用 VGG16 + BN + GAP</li>
<li>B：使用 VGG16 + GAP</li>
<li>数据集 cifar100</li>
<li>Adam，30 epoch</li>
</ul>
<h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><ul>
<li>A：train acc：90%+，test acc：50%，发生严重的过拟合</li>
<li>B：train acc：1%，发生严重的欠拟合</li>
</ul>
<h3 id="结果分析"><a href="#结果分析" class="headerlink" title="结果分析"></a>结果分析</h3><p>BN 在防止梯度弥散这方面起了重要的作用，让深层的神经网络在面对很小的数据的时候也能够拟合。</p>
<h2 id="实验二：探究-GAP-作用"><a href="#实验二：探究-GAP-作用" class="headerlink" title="实验二：探究 GAP 作用"></a>实验二：探究 GAP 作用</h2><h3 id="基本配置-1"><a href="#基本配置-1" class="headerlink" title="基本配置"></a>基本配置</h3><ul>
<li>A：使用 VGG16 + 256 fc * 2 + BN</li>
<li>B：使用 VGG16 + 256 fc * 2</li>
<li>数据集 cifar100</li>
<li>Adam，30 epoch</li>
</ul>
<h3 id="实验结果-1"><a href="#实验结果-1" class="headerlink" title="实验结果"></a>实验结果</h3><p>A，B train acc 均为 1%，发生严重的欠拟合</p>
<h3 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h3><p>怀疑是因为：</p>
<ul>
<li>数据维度过小，后面的卷积层很难提取特征（1 <em> 1， 2 </em> 2 这样的大小）</li>
<li>全连接层神经元太少（只有 256 * 2）</li>
<li>GAP 把过于分散的特征“结合”了起来，因此实验一在 BN 的帮助下还是可以拟合的</li>
</ul>
<h2 id="实验三：实验二欠拟合探究之一"><a href="#实验三：实验二欠拟合探究之一" class="headerlink" title="实验三：实验二欠拟合探究之一"></a>实验三：实验二欠拟合探究之一</h2><h3 id="基本配置-2"><a href="#基本配置-2" class="headerlink" title="基本配置"></a>基本配置</h3><ul>
<li>A：使用 VGG16 + 4096 fc * 2 + BN</li>
<li>B：使用 VGG16 + 256 fc <em> 2 + 图像缩放到 80 </em> 80 </li>
<li>数据集 cifar100</li>
<li>Adam，30 epoch</li>
</ul>
<h3 id="实验结果-2"><a href="#实验结果-2" class="headerlink" title="实验结果"></a>实验结果</h3><ul>
<li>A：train acc：69%，test acc：43%，略有过拟合</li>
<li>B：train acc：1%，欠拟合严重</li>
</ul>
<h3 id="结果分析-1"><a href="#结果分析-1" class="headerlink" title="结果分析"></a>结果分析</h3><p>增加了 fc 神经元个数之后就开始拟合了，效果好了一些，因此上一个推测二是对的；增加了图像的大大小之后还是不能拟合，因而单纯缩放是无法解决问题的（症结还是在网络骨架的结构上）。</p>
<h2 id="实验四：实验二欠拟合探究之二"><a href="#实验四：实验二欠拟合探究之二" class="headerlink" title="实验四：实验二欠拟合探究之二"></a>实验四：实验二欠拟合探究之二</h2><h3 id="基本配置-3"><a href="#基本配置-3" class="headerlink" title="基本配置"></a>基本配置</h3><ul>
<li>A：使用 VGG16 + BN + 4096 fc * 2（去掉 vgg block 5）</li>
<li>B：使用 VGG16 + 4096 fc <em> 2 + 图像缩放到 80 </em> 80 </li>
<li>数据集 cifar100</li>
<li>Adam，30 epoch</li>
</ul>
<h3 id="实验结果-3"><a href="#实验结果-3" class="headerlink" title="实验结果"></a>实验结果</h3><ul>
<li>A：train acc：75%，test acc：48%，有过拟合</li>
<li>B：train acc：1%，欠拟合严重</li>
</ul>
<h3 id="结果分析-2"><a href="#结果分析-2" class="headerlink" title="结果分析"></a>结果分析</h3><p>进一步表明图像缩不是症结所在果，图像本身太小了，持续的池化让 shape 过小，再使用卷积反而起反作用，因而效果差了。</p>
<h2 id="实验五：深入研究-BN-作用"><a href="#实验五：深入研究-BN-作用" class="headerlink" title="实验五：深入研究 BN 作用"></a>实验五：深入研究 BN 作用</h2><h3 id="基本配置-4"><a href="#基本配置-4" class="headerlink" title="基本配置"></a>基本配置</h3><ul>
<li>A：使用 VGG16 + GAP + BN（去掉 vgg block 5）</li>
<li>B：使用 VGG16 + GAP（去掉 vgg block 5）</li>
<li>C：使用 VGG16 + GAP + BN（去掉 vgg block 4、5）</li>
<li>D：使用 VGG16 + GAP（去掉 vgg block 4、5）</li>
<li>数据集 cifar100</li>
<li>Adam，30 epoch</li>
</ul>
<h3 id="实验结果-4"><a href="#实验结果-4" class="headerlink" title="实验结果"></a>实验结果</h3><ul>
<li>A：train acc：98%，test acc：53%，发生严重过拟合</li>
<li>B：train acc：&lt;1%，欠拟合严重</li>
<li>C：train acc：98%，test acc：59%，发生严重过拟合</li>
<li>D：train acc：87%，test acc：34%，过拟合严重且结果也一般</li>
</ul>
<h3 id="结果分析-3"><a href="#结果分析-3" class="headerlink" title="结果分析"></a>结果分析</h3><p>BN 确实厉害，可以有效防止过拟合，梯度弥散。</p>
<ul>
<li>同样是过拟合没加 BN 过拟合程度比加了要严重不少。</li>
<li>同样是多了一个 block，没有 BN 就直接梯度消失没办法拟合，有了 BN 尽管会过拟合但是可以非常顺利训练下来。</li>
</ul>
<p>而且加了 BN 之后训练的训读会快一些（A：47s-&gt;B：65s，C：24s-&gt;D：39s）</p>
<h2 id="实验六：过拟合探究"><a href="#实验六：过拟合探究" class="headerlink" title="实验六：过拟合探究"></a>实验六：过拟合探究</h2><h3 id="基本配置-5"><a href="#基本配置-5" class="headerlink" title="基本配置"></a>基本配置</h3><ul>
<li>A：使用 VGG16（去掉 vgg block 4、5） + GAP + BN + l2_normalization（所有卷积层都加 l2）+ 60 epoch</li>
<li>B：使用 VGG16（去掉 vgg block 4、5） + GAP + BN + l2_normalization（l2 只加到最后一个卷积上）+ 30 epoch</li>
<li>C：使用 VGG16（去掉 vgg block 4、5） + GAP + BN + l2_normalization（l2 只加到最后三个卷积上）+ 30 epoch</li>
<li>数据集 cifar100</li>
<li>Adam</li>
</ul>
<h3 id="实验结果-5"><a href="#实验结果-5" class="headerlink" title="实验结果"></a>实验结果</h3><ul>
<li>A：train acc：51.8%，test acc：38%，虽然过拟合没那么严重，但是效果比较差</li>
<li>B：train acc：93%，test acc：46%，惩罚作用太弱，过拟合严重</li>
<li>C：<ul>
<li>30 epoch：train acc：71%，test acc：43%，惩罚作用较强，过拟合依旧严重</li>
<li>60 epoch：train acc：84%，test acc：39%，惩罚作用较强，过拟合依旧严重</li>
</ul>
</li>
</ul>
<h3 id="结果分析-4"><a href="#结果分析-4" class="headerlink" title="结果分析"></a>结果分析</h3><p>l2_normalization 如果在全局应用会使惩罚作用太强，性能严重降低；只在最后一层加惩罚效果又太弱；在最后三层加则不仅性能差而且过拟合依旧严重。</p>
<p>这几次实验都是训练到最后，没有加入验证集，从而没有在过拟合之前停止下来查看效果。</p>
<p>不过实验证明了加 l2 正则并不是一个非常有效的方法。或者是 l2 正则不应该这样用。</p>
<h2 id="实验七：图片预处理"><a href="#实验七：图片预处理" class="headerlink" title="实验七：图片预处理"></a>实验七：图片预处理</h2><h3 id="基本配置-6"><a href="#基本配置-6" class="headerlink" title="基本配置"></a>基本配置</h3><ul>
<li>使用 VGG16 + GAP + BN + 预处理（去掉 vgg block 4、5）</li>
<li>数据集 cifar100</li>
<li>Adam，40 epoch</li>
</ul>
<h3 id="实验结果-6"><a href="#实验结果-6" class="headerlink" title="实验结果"></a>实验结果</h3><p>train acc：98%，test acc：65%，过拟合略有缓解</p>
<h3 id="结果分析-5"><a href="#结果分析-5" class="headerlink" title="结果分析"></a>结果分析</h3><p>给图片做预处理果然有用，缓解过拟合效果不错。不过需要注意，训练图片和测试图片格式必须一样！！！（比如如果要除以 255 就都要除），不然就是百分之百测试效果很差了 233。</p>
<h2 id="实验总结"><a href="#实验总结" class="headerlink" title="实验总结"></a>实验总结</h2><ul>
<li>对于小的输入不要使用太复杂的神经网络，不然梯度消失反而会起到反作用</li>
<li>设计网络时将最后一层卷积输出控制在 4 <em> 4 </em> 512 比较好</li>
<li>使用 BN 可以有效加快训练速度，缓解梯度弥散</li>
<li>使用 GAP 代替全连接层，减小训练量，降低过拟合</li>
<li>使用图片预处理减轻过拟合</li>
<li>l2 normalization 慎用</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;实验一：初步探究-BN-作用&quot;&gt;&lt;a href=&quot;#实验一：初步探究-BN-作用&quot; class=&quot;headerlink&quot; title=&quot;实验一：初步探究 BN 作用&quot;&gt;&lt;/a&gt;实验一：初步探究 BN 作用&lt;/h2&gt;&lt;h3 id=&quot;基本配置&quot;&gt;&lt;a href=&quot;#基
    
    </summary>
    
      <category term="深度学习" scheme="https://blog.patrickcty.cc/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="https://blog.patrickcty.cc/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Batch Normalization" scheme="https://blog.patrickcty.cc/tags/Batch-Normalization/"/>
    
      <category term="Global Average Pooling" scheme="https://blog.patrickcty.cc/tags/Global-Average-Pooling/"/>
    
  </entry>
  
  <entry>
    <title>图像检索一些指标</title>
    <link href="https://blog.patrickcty.cc/2019/04/26/%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2%E4%B8%80%E4%BA%9B%E6%8C%87%E6%A0%87/"/>
    <id>https://blog.patrickcty.cc/2019/04/26/图像检索一些指标/</id>
    <published>2019-04-26T02:27:44.000Z</published>
    <updated>2019-05-03T03:30:23.090Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Precision-查准率"><a href="#Precision-查准率" class="headerlink" title="Precision 查准率"></a>Precision 查准率</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Precision = \frac&#123;TP&#125;&#123;TP + TN&#125;</div></pre></td></tr></table></figure>
<p>即检索到的这些结果中正确结果的比例。</p>
<h2 id="Recall-查全率"><a href="#Recall-查全率" class="headerlink" title="Recall 查全率"></a>Recall 查全率</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Recall = \frac&#123;TP&#125;&#123;TP + FN&#125;</div></pre></td></tr></table></figure>
<p>即检索到的正确结果占所有正确结果的比例。</p>
<h2 id="F-measure"><a href="#F-measure" class="headerlink" title="F-measure"></a>F-measure</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Recall = 2 \cdot \frac&#123;Precision \cdot Recall&#125;&#123;Precision + Recall&#125;</div></pre></td></tr></table></figure>
<p>综合描述 Precision 和 Recall。</p>
<h2 id="PR-曲线"><a href="#PR-曲线" class="headerlink" title="PR 曲线"></a>PR 曲线</h2><p>描述 Precision 和 Recall 变化关系的曲线，一般来说 Precision 越高 Recall 就比较低，反之亦然。</p>
<p>用来进行二者之间的取舍，一般检索类的要保证 Recall 提高 Precision，反垃圾等则要保证 Precision 提高 Recall。</p>
<h2 id="AP-和-mAP"><a href="#AP-和-mAP" class="headerlink" title="AP 和 mAP"></a>AP 和 mAP</h2><p>分别为：图像检索精度（average precision，AP）与平均检索精度（mean average precision，mAP）。</p>
<p>这两个指标是为了解决 P，R，F-measure 的单点值局限性，考虑了检索效果的排名情况。</p>
<p>计算方法参考[1]。</p>
<h2 id="top-k"><a href="#top-k" class="headerlink" title="top@k"></a>top@k</h2><p>指检索返回的结果为 k 个，一般作为评价 P，R，mAP 等指标的阈值。</p>
<h2 id="信息检索评价指标"><a href="#信息检索评价指标" class="headerlink" title="信息检索评价指标"></a>信息检索评价指标</h2><p>一般是 Precision，Recall，mAP</p>
<h2 id="ROC-曲线和-AUC"><a href="#ROC-曲线和-AUC" class="headerlink" title="ROC 曲线和 AUC"></a>ROC 曲线和 AUC</h2><p>这个是用来评价二分类器所用指标，ROC 纵轴为 TPR（True Positive Rate），横轴为 FPR（False Positive Rate，公式分别为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">TPR = \frac&#123;TP&#125;&#123;TP + FN&#125;</div><div class="line"></div><div class="line">FPR = \frac&#123;fP&#125;&#123;FP + TN&#125;</div></pre></td></tr></table></figure>
<p>AUC（Area Under Curve）即 ROC 曲线与坐标轴围成的面积，一般不小于 0.5，越大表示分类效果越好。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="http://yongyuan.name/blog/evaluation-of-information-retrieval.html" target="_blank" rel="external">http://yongyuan.name/blog/evaluation-of-information-retrieval.html</a><br>[2] <a href="https://blog.csdn.net/marising/article/details/6543943" target="_blank" rel="external">https://blog.csdn.net/marising/article/details/6543943</a><br>[3] <a href="https://zhuanlan.zhihu.com/p/34079183" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/34079183</a><br>[4] <a href="https://blog.csdn.net/Lu597203933/article/details/41802155" target="_blank" rel="external">https://blog.csdn.net/Lu597203933/article/details/41802155</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Precision-查准率&quot;&gt;&lt;a href=&quot;#Precision-查准率&quot; class=&quot;headerlink&quot; title=&quot;Precision 查准率&quot;&gt;&lt;/a&gt;Precision 查准率&lt;/h2&gt;&lt;figure class=&quot;highlight plai
    
    </summary>
    
      <category term="深度学习" scheme="https://blog.patrickcty.cc/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Deep Learning" scheme="https://blog.patrickcty.cc/tags/Deep-Learning/"/>
    
      <category term="Information Retrieval" scheme="https://blog.patrickcty.cc/tags/Information-Retrieval/"/>
    
  </entry>
  
  <entry>
    <title>关于毕业设计的一些事</title>
    <link href="https://blog.patrickcty.cc/2019/04/16/%E5%85%B3%E4%BA%8E%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BA%8B/"/>
    <id>https://blog.patrickcty.cc/2019/04/16/关于毕业设计的一些事/</id>
    <published>2019-04-16T15:55:49.000Z</published>
    <updated>2019-05-03T03:29:37.042Z</updated>
    
    <content type="html"><![CDATA[<h2 id="漫画人脸二分类"><a href="#漫画人脸二分类" class="headerlink" title="漫画人脸二分类"></a>漫画人脸二分类</h2><p>一开始我一直想用 VGG 来实现漫画人脸的二分类，即判断是不是人脸。但是效果一直很差，acc 和随便猜的一模一样（50%）。</p>
<p>这时候我一直以为是数据有问题，不过在洗过好多次之后我发现并非如此，出问题的不是数据，而是数据和网络不匹配。</p>
<p>换句话来说就是漫画人脸中包含的要素太少，使用 VGG 这种深层网络会让特征到最后“消失殆尽”，所以最后效果就很差了。</p>
<p>为了验证这个猜想，我使用 VGG 训练 MNIST，结果不出意料的也是随便猜的概率（10%）。</p>
<p>++当然上面的也只是猜想，因为我对 CNN 理解还是太浅，这个基础问题还得在之后再恶补一下了。++</p>
<p>心里有这个概念之后我就尝试用浅一点的网络来解决问题了，尝试着用 AlexNet 和另一个浅一点的 CNN 来训练模型，虽然最后在二分类问题上能达到 80% 左右 的准确率，但是还有一个大问题又被我忽视掉了。</p>
<p>在尝试这两个网络中，我又在其中加入了 bn 层，不过加入之后浅层的 CNN acc 又变成了 50%……</p>
<h3 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h3><p>MNIST 这个 acc 这么低，原因不是我想的那样，而是我在处理输入的时候直接无脑 resize，破坏了原来图片的语义……使用正常的处理方法就能得到正确的结果了，并不是 VGG 的锅……</p>
<p>那么问题来了，我的漫画网络究竟是哪里出问题了呢……</p>
<h2 id="提取特征"><a href="#提取特征" class="headerlink" title="提取特征"></a>提取特征</h2><p>Acc 80%，这是一个不算特别好又不算坏的结果。但是试了很多种方法一时间没能找到更高的准确度，于是就准备拿这个模型来提取特征了。</p>
<p>不过在这个过程中，我有又发现了一个大问题：提取出来的特征太稀疏了，256 维的特征中，只有不到十个元素不为零……而 flatten 层也仅有 1/8 左右的不为零。虽然我内心没有逼数，但这的确是一个不正常的现象。</p>
<p>==后面我准备训练 MNIST 来观察一下各层的正常输出应该是怎么样的。==</p>
<h3 id="检索系统中遇到的坑"><a href="#检索系统中遇到的坑" class="headerlink" title="检索系统中遇到的坑"></a>检索系统中遇到的坑</h3><ul>
<li><code>ValueError: Tensor Tensor(&quot;Sigmoid_2:0&quot;, shape=(?, 17), dtype=float32) is not an element of this graph.</code></li>
</ul>
<p>出现这个问题的原因就是多线程、分布式环境下，恢复 Model 时的 Tensor Graph 和生成 Model 时不同。</p>
<p>具体来说就是模型是在全局变量里面恢复的，但是调用是在 Flask 的多线程调用的。</p>
<p>解决方法就是在恢复 Model 的时候保存相应的 Graph，然后再在 predict 的时候恢复这个 Graph 即可。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"># when load model</div><div class="line">graph = tf.get_default_graph()</div><div class="line"></div><div class="line"># when use model in another thread</div><div class="line">global graph</div><div class="line">with graph.as_default():</div><div class="line">    (... do inference here ...)</div></pre></td></tr></table></figure>
<p>参考资料：</p>
<ul>
<li><a href="https://github.com/keras-team/keras/issues/2397" target="_blank" rel="external">https://github.com/keras-team/keras/issues/2397</a></li>
<li><p><a href="https://justttry.github.io/justttry.github.io/not-an-element-of-Tensor-graph/" target="_blank" rel="external">https://justttry.github.io/justttry.github.io/not-an-element-of-Tensor-graph/</a></p>
</li>
<li><p><code>FailedPreconditionError: tensorflow not found container localhost does not exist</code></p>
</li>
</ul>
<p>这个问题比较玄学，好像各种问题都可能报这个错误。我出现这个问题的原因可能是 tf 的版本和 keras 的版本有些冲突，使用系统的 Python 不行，但是换成 Anaconda 的 Python 就没问题了。</p>
<p>不过需要注意的是，tf.keras 和 keras 并不是一个东西，如果两个混用的话是会出现各种错误的，如果用到了某一个就一条路走到黑。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;漫画人脸二分类&quot;&gt;&lt;a href=&quot;#漫画人脸二分类&quot; class=&quot;headerlink&quot; title=&quot;漫画人脸二分类&quot;&gt;&lt;/a&gt;漫画人脸二分类&lt;/h2&gt;&lt;p&gt;一开始我一直想用 VGG 来实现漫画人脸的二分类，即判断是不是人脸。但是效果一直很差，acc 和随便
    
    </summary>
    
      <category term="Python" scheme="https://blog.patrickcty.cc/categories/Python/"/>
    
      <category term="深度学习" scheme="https://blog.patrickcty.cc/categories/Python/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Keras" scheme="https://blog.patrickcty.cc/tags/Keras/"/>
    
      <category term="TensorFlow" scheme="https://blog.patrickcty.cc/tags/TensorFlow/"/>
    
      <category term="Deep Learning" scheme="https://blog.patrickcty.cc/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>安装 OpenCV C++ 库以及运行相应程序</title>
    <link href="https://blog.patrickcty.cc/2019/04/07/%E5%AE%89%E8%A3%85OpenCV/"/>
    <id>https://blog.patrickcty.cc/2019/04/07/安装OpenCV/</id>
    <published>2019-04-07T07:40:53.000Z</published>
    <updated>2019-05-03T03:31:38.203Z</updated>
    
    <content type="html"><![CDATA[<h2 id="扯两句废话"><a href="#扯两句废话" class="headerlink" title="扯两句废话"></a>扯两句废话</h2><p>之前用惯了 Python，以为使用 C++ 的模块也是直接一行命令安装然后再直接编译就可以了，没想到并没有这么简单，还是需要其他的一些步骤。</p>
<p>于是这两天在不会 C++ 上吃了大亏 orz。</p>
<h2 id="Ubuntu-安装-OpenCV"><a href="#Ubuntu-安装-OpenCV" class="headerlink" title="Ubuntu 安装 OpenCV"></a>Ubuntu 安装 OpenCV</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt-get install libopencv-dev</div></pre></td></tr></table></figure>
<p>没错，一行命令完事。</p>
<p>一开始我是老老实实下载、编译的（因为搜安装教程完全没看到用 apt 安装的，于是我以为只能编译来安装了 orz），结果配了半天环境变量还是找不到 OpenCV 的包，最后这行命令下去直接就一切 ok 了。</p>
<p>检查 OpenCV 是否安装成功：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pkg-config --cflags --libs opencv</div></pre></td></tr></table></figure>
<p>如果输出的那一大堆不是报错的那就说明安装成功了。</p>
<h2 id="Mac-安装-OpenCV"><a href="#Mac-安装-OpenCV" class="headerlink" title="Mac 安装 OpenCV"></a>Mac 安装 OpenCV</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">brew install opencv</div></pre></td></tr></table></figure>
<p>这样安装了还是要配置环境变量</p>
<h3 id="配置-pkg-config-环境变量"><a href="#配置-pkg-config-环境变量" class="headerlink" title="配置 pkg-config 环境变量"></a>配置 pkg-config 环境变量</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig/</div></pre></td></tr></table></figure>
<h3 id="把-OpenCV-pc-文件链接到-PKG-CONFIG-PATH"><a href="#把-OpenCV-pc-文件链接到-PKG-CONFIG-PATH" class="headerlink" title="把 OpenCV .pc 文件链接到 PKG_CONFIG_PATH"></a>把 OpenCV .pc 文件链接到 PKG_CONFIG_PATH</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ln -s /usr/local/opt/opencv3/lib/pkgconfig/opencv.pc $PKG_CONFIG_PATH</div></pre></td></tr></table></figure>
<p>这一步具体的路径就要看 opencv.pc 文件在哪里了，我的 Mac 上的是 opencv4.pc 文件</p>
<h3 id="然后"><a href="#然后" class="headerlink" title="然后"></a>然后</h3><p>环境变量配置好了之后应该就可以了，之后还是运行上面的命令来检查是否安装成功。详细的安装过程可以看<a href="https://gist.github.com/nkcr/6f5c6db4dccd3b32e8ba" target="_blank" rel="external">这个教程</a>。</p>
<h2 id="运行相应程序"><a href="#运行相应程序" class="headerlink" title="运行相应程序"></a>运行相应程序</h2><p>如果源程序中引用了相应的模块那么编译的时候就要加入一些其他的内容了，比如如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">g++ -std=c++11 main.cpp mangaLineSeparator.cpp -o main $(pkg-config --cflags --libs opencv4)</div></pre></td></tr></table></figure>
<p>然后就生成了可执行程序 <code>main</code> 了。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>C++ 的模块的使用和 Python 还是有一些不同的，在处理问题的时候不要根据惯性思维来思考，不然就会在一些你意想不到的地方纠结……比如明明是编译的命令写错了，我却一直以为是模块没有正常安装……</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;扯两句废话&quot;&gt;&lt;a href=&quot;#扯两句废话&quot; class=&quot;headerlink&quot; title=&quot;扯两句废话&quot;&gt;&lt;/a&gt;扯两句废话&lt;/h2&gt;&lt;p&gt;之前用惯了 Python，以为使用 C++ 的模块也是直接一行命令安装然后再直接编译就可以了，没想到并没有这么简单，
    
    </summary>
    
      <category term="C++" scheme="https://blog.patrickcty.cc/categories/C/"/>
    
    
      <category term="C++" scheme="https://blog.patrickcty.cc/tags/C/"/>
    
      <category term="OpenCV" scheme="https://blog.patrickcty.cc/tags/OpenCV/"/>
    
  </entry>
  
</feed>
