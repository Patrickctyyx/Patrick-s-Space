<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Patrick&#39;s Space</title>
  <subtitle>Stay hungry, stay foolish!</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://blog.patrickcty.cc/"/>
  <updated>2020-03-11T04:18:57.213Z</updated>
  <id>https://blog.patrickcty.cc/</id>
  
  <author>
    <name>Patrick</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>理解多分类中的 mAP</title>
    <link href="https://blog.patrickcty.cc/2020/03/11/%E7%90%86%E8%A7%A3%E5%A4%9A%E5%88%86%E7%B1%BB%E4%B8%AD%E7%9A%84-k/"/>
    <id>https://blog.patrickcty.cc/2020/03/11/理解多分类中的-k/</id>
    <published>2020-03-11T02:33:33.000Z</published>
    <updated>2020-03-11T04:18:57.213Z</updated>
    
    <content type="html"><![CDATA[<p>在多分类任务中，有时候会用 mAP（Mean Average Precision）来表示分类的准确程度，如 VOC。其原因在于 mAP 能很好地评价分类的排序，而通常用的 accuracy 则往往会被最多的那个类别支配。</p>
<p>要计算多分类的 mAP，则要先计算各个类别的 AP。</p>
<h2 id="VOC-中-AP-的计算方法"><a href="#VOC-中-AP-的计算方法" class="headerlink" title="VOC 中 AP 的计算方法"></a>VOC 中 AP 的计算方法</h2><p>总的来说，就是对于某个类别，得到 n 个对该类别的预测概率，按照概率从大到小的顺序进行排列，然后对于 k∈1~n，求每个 k 对应的 Precision 和 Recall 值，对于每个 Recall 值，得到一个 Precision 值（==保证 P-R 曲线单调非递增==），将 n 个 Precision 取平均之后即为 AP 的值。要注意的是，这里不涉及到@k，因为总是为计算所有 n 个预测的结果。</p>
<p>对于一个四分类问题，已知标签和预测结果如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">y_true = np.array([[2], [1], [0], [3], [0], [1]]).astype(np.int64)</div><div class="line">y_pred = np.array([[0.1, 0.2, 0.6, 0.1],</div><div class="line">                   [0.8, 0.05, 0.1, 0.05],</div><div class="line">                   [0.3, 0.4, 0.1, 0.2],</div><div class="line">                   [0.6, 0.25, 0.1, 0.05],</div><div class="line">                   [0.1, 0.2, 0.6, 0.1],</div><div class="line">                   [0.9, 0.0, 0.03, 0.07]]).astype(np.float32)</div></pre></td></tr></table></figure>
<p>以类别 3 为例，六次预测给出的概率经过排序后为<code>[0.2  0.1  0.1  0.07 0.05 0.05]</code>，对应位置预测结果为<code>[0. 0. 0. 0. 0. 1.]</code>，0 表示预测错误，1 表示预测正确，那么可以列出来一个表：</p>
<table>
<thead>
<tr>
<th style="text-align:center">top-k</th>
<th style="text-align:center">Precision</th>
<th style="text-align:center">Recall</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">0/1</td>
<td style="text-align:center">0/1</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">0/2</td>
<td style="text-align:center">0/1</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">0/3</td>
<td style="text-align:center">0/1</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">0/4</td>
<td style="text-align:center">0/1</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">0/5</td>
<td style="text-align:center">0/1</td>
</tr>
<tr>
<td style="text-align:center">6</td>
<td style="text-align:center">1/6</td>
<td style="text-align:center">1/1</td>
</tr>
</tbody>
</table>
<p>在确保 P-R 曲线单调递减的情况下，求各个 Recall 对应的 Precision 的均值，在这里是 AP = (1/6) / 1 = 1/6</p>
<p>具体的内容参考<a href="https://link.zhihu.com/?target=http%3A//blog.sina.com.cn/s/blog_9db078090102whzw.html" target="_blank" rel="external">这一篇</a>。</p>
<p>同理可以求出来各个类别的 AP 为：<code>[1/3, 1/3, 1.0, 1/6]</code>，求均值后得到 MAP = 0.458。</p>
<p>一个 numpy 的实现为，来自这个 <a href="https://github.com/broadinstitute/keras-rcnn/issues/6" target="_blank" rel="external">issue</a>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># y_true is one-hot</span></div><div class="line"> _, classes = y_true.shape</div><div class="line">    </div><div class="line">average_precisions = []</div><div class="line"></div><div class="line"><span class="keyword">for</span> index <span class="keyword">in</span> range(classes):</div><div class="line">        <span class="comment"># 得到从大到小排序后的标签索引</span></div><div class="line">        row_indices_sorted = numpy.argsort(-y_pred[:, index])</div><div class="line"></div><div class="line">        <span class="comment"># 重新排列后的标签和预测结果</span></div><div class="line">        y_true_cls = y_true[row_indices_sorted, index]</div><div class="line">        y_pred_cls = y_pred[row_indices_sorted, index]</div><div class="line"></div><div class="line">        tp = (y_true_cls == <span class="number">1</span>)</div><div class="line">        fp = (y_true_cls == <span class="number">0</span>)</div><div class="line"></div><div class="line">        <span class="comment"># 每个位置是 top-i 的 fp 和 tp</span></div><div class="line">        fp = numpy.cumsum(fp)</div><div class="line">        tp = numpy.cumsum(tp)</div><div class="line"></div><div class="line">        <span class="comment"># 一共有多少预测正确的标签</span></div><div class="line">        npos = numpy.sum(y_true_cls)</div><div class="line"></div><div class="line">        <span class="comment"># top-i 的 recall</span></div><div class="line">        rec = tp*<span class="number">1.0</span> / npos</div><div class="line"></div><div class="line">        <span class="comment"># avoid divide by zero in case the first detection matches a difficult</span></div><div class="line">        <span class="comment"># ground truth</span></div><div class="line">        <span class="comment"># top-i 的 precision</span></div><div class="line">        prec = tp*<span class="number">1.0</span> / numpy.maximum((tp + fp), numpy.finfo(numpy.float64).eps)</div><div class="line"></div><div class="line">        <span class="comment"># 加上头和尾</span></div><div class="line">        mrec = numpy.concatenate(([<span class="number">0.</span>], rec, [<span class="number">1.</span>]))</div><div class="line">        mpre = numpy.concatenate(([<span class="number">0.</span>], prec, [<span class="number">0.</span>]))</div><div class="line"></div><div class="line">        <span class="comment"># compute the precision envelope</span></div><div class="line">        <span class="comment"># 保证 P-R 曲线单调递减</span></div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(mpre.size - <span class="number">1</span>, <span class="number">0</span>, <span class="number">-1</span>):</div><div class="line">            mpre[i - <span class="number">1</span>] = numpy.maximum(mpre[i - <span class="number">1</span>], mpre[i])</div><div class="line"></div><div class="line">        <span class="comment"># to calculate area under PR curve, look for points</span></div><div class="line">        <span class="comment"># where X axis (recall) changes value</span></div><div class="line">        i = numpy.where(mrec[<span class="number">1</span>:] != mrec[:<span class="number">-1</span>])[<span class="number">0</span>]</div><div class="line"></div><div class="line">        <span class="comment"># and sum (\Delta recall) * prec</span></div><div class="line">        <span class="comment"># 相当于求每个 recall 值对应的 precision 的均值</span></div><div class="line">        average_precisions.append(numpy.sum((mrec[i + <span class="number">1</span>] - mrec[i]) * mpre[i + <span class="number">1</span>]))</div></pre></td></tr></table></figure>
<h2 id="TnesorFlow-中的-AP"><a href="#TnesorFlow-中的-AP" class="headerlink" title="TnesorFlow 中的 AP"></a>TnesorFlow 中的 AP</h2><p>TensorFlow 中使用以下方法来计算 mAP</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">tf.compat.v1.metrics.average_precision_at_k(</div><div class="line">    labels, predictions, k, weights=None, metrics_collections=None,</div><div class="line">    updates_collections=None, name=None</div><div class="line">)</div></pre></td></tr></table></figure>
<p>但是这里并不是按照分类的标准类计算 mAP，而是对于检索来计算 mAP，而对于检索来说，总是==要考虑@k==，也就是考虑检索出来前 k 个的结果。</p>
<p>还是对于上面的例子，TF 中将 pred 看成了 6 次检索，每次检索有一个待检索对象（真值标签），检索产生四个概率值，这四个概率值的和为一。不过要注意的是，通常检索的时候待检索对象往往大于一，并且检索所产生的多个概率值的和不一定为一。</p>
<p>对于以下这一个预测结果，当 k = 1 的时候，0.8 对应的是标签 0，因此 Precision = 0/1，Recall = 0/1；k = 2，0.1 对应的是标签 2，因此 Precision = 0/2，Recall = 0/1；k = 3，0.05 对应的是标签 1，因此 Precision = 1/3，Recall = 1/1；k = 4，此时已经全部检索到了，因此 Precision = 1/3，Recall = 1。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">pred = [0.8, 0.05, 0.1, 0.05]</div><div class="line">true = [1]</div></pre></td></tr></table></figure>
<p>其他预测结果同理可求，因此 mAP@3 = (1 + 1/3 + 1/2 + 0 + 1/3 + 0) / 6 = 0.3611。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在多分类任务中，有时候会用 mAP（Mean Average Precision）来表示分类的准确程度，如 VOC。其原因在于 mAP 能很好地评价分类的排序，而通常用的 accuracy 则往往会被最多的那个类别支配。&lt;/p&gt;
&lt;p&gt;要计算多分类的 mAP，则要先计算各个
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>tensorflow遇到的坑</title>
    <link href="https://blog.patrickcty.cc/2020/03/09/tensorflow%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91/"/>
    <id>https://blog.patrickcty.cc/2020/03/09/tensorflow遇到的坑/</id>
    <published>2020-03-08T16:09:12.000Z</published>
    <updated>2020-03-08T16:22:16.401Z</updated>
    
    <content type="html"><![CDATA[<h2 id="IO-的坑"><a href="#IO-的坑" class="headerlink" title="IO 的坑"></a>IO 的坑</h2><p>对于<code>tf.io.decode_image()</code>，如果指定 <code>dtype=tf.float32</code>，那么会默认把 tensor 的值除以 255。</p>
<p>我之前就在这里直接指定了，后面还减掉了 ImageNet 的均值（[123.68, 116.779, 103.939]），所以对于任何的图，其 RGB 通道上的值都基本上是 [-123.68, -116.779, -103.939]，也难怪网络的预测结果都是数量最多的那两个标签……</p>
<p>如果要像我这么做的话，就不指定 dtype，然后再用 <code>tf.cast()</code> 将 tensor 转化为浮点型，这时候就只转换数据类型不改变值的大小了。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;IO-的坑&quot;&gt;&lt;a href=&quot;#IO-的坑&quot; class=&quot;headerlink&quot; title=&quot;IO 的坑&quot;&gt;&lt;/a&gt;IO 的坑&lt;/h2&gt;&lt;p&gt;对于&lt;code&gt;tf.io.decode_image()&lt;/code&gt;，如果指定 &lt;code&gt;dtype=tf.fl
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>colab遇到的坑</title>
    <link href="https://blog.patrickcty.cc/2020/02/28/colab%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91/"/>
    <id>https://blog.patrickcty.cc/2020/02/28/colab遇到的坑/</id>
    <published>2020-02-28T10:11:35.000Z</published>
    <updated>2020-02-28T10:19:15.662Z</updated>
    
    <content type="html"><![CDATA[<h2 id="训练特别慢"><a href="#训练特别慢" class="headerlink" title="训练特别慢"></a>训练特别慢</h2><h3 id="坑"><a href="#坑" class="headerlink" title="坑"></a>坑</h3><p>训练的数据集不要放在 google driver 里面，读取里面的文件特别慢，把 google driver 的文件拷贝到 colab 里面也特别慢。（不过把 colab 文件拷贝过去特别快）</p>
<h3 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h3><p>直接再把相关的文件下载一遍，记得提前写好相关操作的脚本，每次直接执行一下。如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">!wget http://www.cs.bu.edu/groups/ivc/data/SOS/ESOS.zip;mkdir data;mkdir data/ESOS;mv ESOS.zip data/ESOS;unzip ESOS.zip &gt; zip.log</div><div class="line">from utils.dataset_utils.SOS import create_csv</div><div class="line">create_csv(&apos;/content/data/ESOS&apos;)</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;训练特别慢&quot;&gt;&lt;a href=&quot;#训练特别慢&quot; class=&quot;headerlink&quot; title=&quot;训练特别慢&quot;&gt;&lt;/a&gt;训练特别慢&lt;/h2&gt;&lt;h3 id=&quot;坑&quot;&gt;&lt;a href=&quot;#坑&quot; class=&quot;headerlink&quot; title=&quot;坑&quot;&gt;&lt;/a&gt;坑&lt;/h
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>七牛云绑定域名的坑</title>
    <link href="https://blog.patrickcty.cc/2020/01/07/%E4%B8%83%E7%89%9B%E4%BA%91%E7%BB%91%E5%AE%9A%E5%9F%9F%E5%90%8D%E7%9A%84%E5%9D%91/"/>
    <id>https://blog.patrickcty.cc/2020/01/07/七牛云绑定域名的坑/</id>
    <published>2020-01-07T13:36:01.000Z</published>
    <updated>2020-01-07T13:38:59.035Z</updated>
    
    <content type="html"><![CDATA[<p>之前七牛云绑定域名的 SSL 证书过期了，在过期之前我已经特意申请了一个新（也是在七牛云申请的）的并绑定了，但是当旧的证书过期的时候新证书却并没有生效。</p>
<p>原因在于绑定域名的证书是通过绑定域名的配置来决定的，要手动修改相应的配置，将证书选择为新的证书，然后才会使用新的证书 orz。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;之前七牛云绑定域名的 SSL 证书过期了，在过期之前我已经特意申请了一个新（也是在七牛云申请的）的并绑定了，但是当旧的证书过期的时候新证书却并没有生效。&lt;/p&gt;
&lt;p&gt;原因在于绑定域名的证书是通过绑定域名的配置来决定的，要手动修改相应的配置，将证书选择为新的证书，然后才会使
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>最近 tf_keras 中遇到的一些坑</title>
    <link href="https://blog.patrickcty.cc/2020/01/07/%E6%9C%80%E8%BF%91keras%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9D%91/"/>
    <id>https://blog.patrickcty.cc/2020/01/07/最近keras中遇到的一些坑/</id>
    <published>2020-01-07T12:25:41.000Z</published>
    <updated>2020-02-16T01:37:54.455Z</updated>
    
    <content type="html"><![CDATA[<h2 id="文件名格式不对产生-OSError"><a href="#文件名格式不对产生-OSError" class="headerlink" title="文件名格式不对产生 OSError"></a>文件名格式不对产生 OSError</h2><h3 id="产生原因"><a href="#产生原因" class="headerlink" title="产生原因"></a>产生原因</h3><p>在使用 model.save(model_path) 的时候，由于 model_path 格式不对，而产生了 OSError，一个不对的格式是：</p>
<blockquote>
<p>Tue-Jan-7-16-59-41-2020.sos_model.035-mae.0.1543.hdf5</p>
</blockquote>
<p>可能是这个 <code>.0.</code> 导致了这个错误。</p>
<h3 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h3><p>把 mae 后面的 <code>.</code> 改成 <code>-</code> 即可，即：</p>
<blockquote>
<p>Tue-Jan-7-16-59-41-2020.sos_model.035-mae-0.1543.hdf5</p>
</blockquote>
<h2 id="在同样的环境中重复载入模型"><a href="#在同样的环境中重复载入模型" class="headerlink" title="在同样的环境中重复载入模型"></a>在同样的环境中重复载入模型</h2><h3 id="产生原因-1"><a href="#产生原因-1" class="headerlink" title="产生原因"></a>产生原因</h3><p>在同样的环境中重复载入模型会导致没有指定名称的层的名字会发生改变，比如某个卷积层的定义如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">x = layers.Conv2D(layer, (3, 3))(x)</div></pre></td></tr></table></figure>
<p>那么，第一次载入这一层的名字可能就是 conv2d，再次在同样的环境中载入，名字可能就变成了 conv2d_1。</p>
<p>这一点要特别注意一下，特别是在 notebook 中运行的时候，很可能会让原本功能正常的方法报错。</p>
<blockquote>
<p>另外，不用担心同一个环境中加载的不同模型有同样的层名会有问题，因为不在一个计算图里面，所以不会产生冲突。</p>
</blockquote>
<h3 id="解决方法-1"><a href="#解决方法-1" class="headerlink" title="解决方法"></a>解决方法</h3><p>报错了就清除当前的上下文，notebook 里面就重启 kernel。</p>
<h2 id="lr-multiplier-无法正确读入自定义的优化器"><a href="#lr-multiplier-无法正确读入自定义的优化器" class="headerlink" title="lr multiplier 无法正确读入自定义的优化器"></a>lr multiplier 无法正确读入自定义的优化器</h2><h3 id="产生原因-2"><a href="#产生原因-2" class="headerlink" title="产生原因"></a>产生原因</h3><p><a href="https://github.com/CyberZHG/keras-lr-multiplier" target="_blank" rel="external">原模块</a>引入 keras 的方法可能和现在的方法不匹配。</p>
<h3 id="解决方法-2"><a href="#解决方法-2" class="headerlink" title="解决方法"></a>解决方法</h3><p>把源文件复制到当前项目下，再改一下引入就正常了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># 修改之后的方法</div><div class="line">import tensorflow.python.keras.optimizers as optimizers</div></pre></td></tr></table></figure>
<h2 id="plot-model-报缺少-graphviz-的错"><a href="#plot-model-报缺少-graphviz-的错" class="headerlink" title="plot_model 报缺少 graphviz 的错"></a>plot_model 报缺少 graphviz 的错</h2><p>直接运行 <code>plot_model</code> 的时候会报缺少依赖的错误，安装了相关依赖之后还有相同的错误，如下所示:</p>
<blockquote>
<p>keras ImportError: Failed to import pydot. You must install pydot and graphviz for <code>pydotprint</code> to work.</p>
</blockquote>
<h3 id="产生原因-3"><a href="#产生原因-3" class="headerlink" title="产生原因"></a>产生原因</h3><p>graphviz 需要系统级的安装。</p>
<h3 id="解决方法-3"><a href="#解决方法-3" class="headerlink" title="解决方法"></a>解决方法</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"># for mac</div><div class="line">brew install graphviz</div><div class="line"></div><div class="line"># for ubuntu</div><div class="line">sudo apt-get install graphviz</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;文件名格式不对产生-OSError&quot;&gt;&lt;a href=&quot;#文件名格式不对产生-OSError&quot; class=&quot;headerlink&quot; title=&quot;文件名格式不对产生 OSError&quot;&gt;&lt;/a&gt;文件名格式不对产生 OSError&lt;/h2&gt;&lt;h3 id=&quot;产生原因&quot;
    
    </summary>
    
    
      <category term="keras" scheme="https://blog.patrickcty.cc/tags/keras/"/>
    
  </entry>
  
  <entry>
    <title>部署tf_keras模型遇到的坑</title>
    <link href="https://blog.patrickcty.cc/2019/12/14/%E9%83%A8%E7%BD%B2tf-keras%E6%A8%A1%E5%9E%8B%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91/"/>
    <id>https://blog.patrickcty.cc/2019/12/14/部署tf-keras模型遇到的坑/</id>
    <published>2019-12-14T03:20:19.000Z</published>
    <updated>2019-12-14T03:22:21.364Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一次-load-多次-predict"><a href="#一次-load-多次-predict" class="headerlink" title="一次 load 多次 predict"></a>一次 load 多次 predict</h2><p>由于 TensorFlow 使用的是静态图，因此默认并不能做到一次 load 然后就任意在其他的地方调用，因此需要以下方法来做到：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># load</span></div><div class="line">model = load_model(<span class="string">'path_to_model'</span>)</div><div class="line">graph = tf.get_default_graph()</div><div class="line"></div><div class="line"><span class="comment"># predict, maybe in another thread</span></div><div class="line"><span class="keyword">global</span> graph</div><div class="line"><span class="keyword">with</span> graph.as_default():</div><div class="line">    model.predict()</div></pre></td></tr></table></figure>
<h2 id="限制不要占满-GPU-显存"><a href="#限制不要占满-GPU-显存" class="headerlink" title="限制不要占满 GPU 显存"></a>限制不要占满 GPU 显存</h2><p>TensorFlow 默认的机制是会占用满 GPU，但是可以通过设置 allow_growth 来只使用必须的显存：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="keyword">from</span> tensorflow.python.keras.backend <span class="keyword">import</span> set_session</div><div class="line"></div><div class="line">config = tf.ConfigProto()</div><div class="line">config.gpu_options.allow_growth = <span class="keyword">True</span></div><div class="line">sess = tf.Session(config=config)</div><div class="line">set_session(sess)  <span class="comment"># 必须要先设置 session 才能 load model</span></div></pre></td></tr></table></figure>
<p>进行这样设置之后如果要在多个不同情况下调用模型则也必须每次都设置 session：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># predict, maybe in another thread</span></div><div class="line"><span class="keyword">global</span> graph</div><div class="line"><span class="keyword">global</span> sess</div><div class="line"><span class="keyword">with</span> graph.as_default():</div><div class="line">    set_session(sess)</div><div class="line">    model.predict()</div></pre></td></tr></table></figure>
<h2 id="忽视掉-TensorFlow-的一大堆初始化-log"><a href="#忽视掉-TensorFlow-的一大堆初始化-log" class="headerlink" title="忽视掉 TensorFlow 的一大堆初始化 log"></a>忽视掉 TensorFlow 的一大堆初始化 log</h2><p>log level 为 3 的话就只会输出错误信息了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">os.environ[<span class="string">'TF_CPP_MIN_LOG_LEVEL'</span>] = <span class="string">'3'</span></div><div class="line">tf.get_logger().setLevel(<span class="string">'ERROR'</span>)</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;一次-load-多次-predict&quot;&gt;&lt;a href=&quot;#一次-load-多次-predict&quot; class=&quot;headerlink&quot; title=&quot;一次 load 多次 predict&quot;&gt;&lt;/a&gt;一次 load 多次 predict&lt;/h2&gt;&lt;p&gt;由于 Ten
    
    </summary>
    
    
      <category term="TensorFlow" scheme="https://blog.patrickcty.cc/tags/TensorFlow/"/>
    
      <category term="keras" scheme="https://blog.patrickcty.cc/tags/keras/"/>
    
  </entry>
  
  <entry>
    <title>配置内网穿透</title>
    <link href="https://blog.patrickcty.cc/2019/11/20/%E9%85%8D%E7%BD%AE%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/"/>
    <id>https://blog.patrickcty.cc/2019/11/20/配置内网穿透/</id>
    <published>2019-11-20T09:03:14.000Z</published>
    <updated>2019-11-20T10:29:44.214Z</updated>
    
    <content type="html"><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>内网穿透，顾名思义就是从外网访问一个在内网的服务器。我们实验室的 GPU 服务器都是在内网里面，远程访问非常不方便，为了以防万一，还是需要配配置一个内网穿透。</p>
<h2 id="frp"><a href="#frp" class="headerlink" title="frp"></a>frp</h2><p>这里介绍使用 <a href="https://github.com/fatedier/frp" target="_blank" rel="external">frp</a> 配置内网穿透的过程。</p>
<blockquote>
<p>frp 是一个可用于内网穿透的高性能的反向代理应用，支持 tcp, udp 协议，为 http 和 https 应用协议提供了额外的能力，且尝试性支持了点对点穿透。</p>
</blockquote>
<h2 id="Requirements"><a href="#Requirements" class="headerlink" title="Requirements"></a>Requirements</h2><ul>
<li>一个有外网 ip 的服务器：作为内网服务器与客户端的中介</li>
<li>frp 运行文件：这个服务器和客户端都要下载，链接在<a href="https://github.com/fatedier/frp/releases" target="_blank" rel="external">这里</a></li>
</ul>
<h2 id="服务器配置"><a href="#服务器配置" class="headerlink" title="服务器配置"></a>服务器配置</h2><ol>
<li>下载 frp 文件，解压</li>
<li><p>进入相应文件夹，编辑 frps.ini</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"># frps.ini</div><div class="line">[common]</div><div class="line">bind_port = 7000 # frp运行端口,需要开放防火墙</div><div class="line">vhost_http_port = 8080 # http服务端口,可以 和 bind_port 相同</div></pre></td></tr></table></figure>
</li>
<li><p>启动 ./frps -c ./frps.ini</p>
</li>
</ol>
<h2 id="客户端配置"><a href="#客户端配置" class="headerlink" title="客户端配置"></a>客户端配置</h2><ol>
<li>下载 frp 文件，解压</li>
<li><p>进入相应文件夹，编辑 frpc.ini（注意是 frpc）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"># frpc.ini</div><div class="line">[common]</div><div class="line">server_addr = 上一步的服务器地址</div><div class="line">server_port = 上一步填写的端口</div><div class="line"></div><div class="line">[ssh]</div><div class="line">type = tcp</div><div class="line">local_ip = 127.0.0.1</div><div class="line">local_port = 22</div><div class="line">remote_port = 6000  # 通过这个端口来访问</div></pre></td></tr></table></figure>
</li>
<li><p>启动 ./frpc -c ./frpc.ini</p>
</li>
<li>使用 ssh 访问 <code>ssh -oPort 6000 ssh_name@ssh_ip</code></li>
</ol>
<h2 id="多个客户端配置"><a href="#多个客户端配置" class="headerlink" title="多个客户端配置"></a>多个客户端配置</h2><p>多个客户端配置只要 ssh 下的 remote_port 不冲突即可<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"># frpc2.ini</div><div class="line">[common]</div><div class="line">server_addr = 上一步的服务器地址</div><div class="line">server_port = 上一步填写的端口</div><div class="line"></div><div class="line">[ssh]</div><div class="line">type = tcp</div><div class="line">local_ip = 127.0.0.1</div><div class="line">local_port = 22</div><div class="line">remote_port = 6001  # 这个地方不冲突即可</div><div class="line"></div><div class="line"># 使用 ssh 访问 ssh -oPort 6001 ssh_name@ssh_ip</div></pre></td></tr></table></figure></p>
<h2 id="配置客户端-http-访问"><a href="#配置客户端-http-访问" class="headerlink" title="配置客户端 http 访问"></a>配置客户端 http 访问</h2><ol>
<li><p>修改客户端上 frpc.ini 文件，加入以下内容</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[web]</div><div class="line">type = http</div><div class="line">local_port = 80  # 或者是其他的端口也都可以</div><div class="line">custom_domains = www.example.com</div></pre></td></tr></table></figure>
</li>
<li><p>访问网页 <code>www.example.com:8080</code>(这个端口是服务器 frps.ini 里面的 vhost_http_port)</p>
</li>
</ol>
<h2 id="将-frp-添加到启动项"><a href="#将-frp-添加到启动项" class="headerlink" title="将 frp 添加到启动项"></a>将 frp 添加到启动项</h2><ol>
<li><p><code>sudo vim /lib/systemd/system/frps.service</code>，添加以下内容</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">[Unit]</div><div class="line">Description=frps</div><div class="line">After=network.target</div><div class="line"></div><div class="line">[Service]</div><div class="line">TimeoutStartSec=30</div><div class="line">ExecStart=$&#123;frps的绝对路径&#125; -c $&#123;frps.ini的绝对路径&#125;</div><div class="line">ExecStop=/bin/kill $MAINPID</div><div class="line"></div><div class="line">[Install]</div><div class="line">WantedBy=multi-user.target</div></pre></td></tr></table></figure>
</li>
<li><p>启用服务</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">systemctl enable frps</div><div class="line">systemctl start frps</div><div class="line">systemctl status frps</div></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li><a href="https://blog.xinshangshangxin.com/2018/06/18/frp/" target="_blank" rel="external">https://blog.xinshangshangxin.com/2018/06/18/frp/</a></li>
<li><a href="https://github.com/fatedier/frp/issues/407" target="_blank" rel="external">https://github.com/fatedier/frp/issues/407</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h2&gt;&lt;p&gt;内网穿透，顾名思义就是从外网访问一个在内网的服务器。我们实验室的 GPU 服务器都是在内网里面，远程访问非常不方便，为了以防万一，还是需要配
    
    </summary>
    
      <category term="utils" scheme="https://blog.patrickcty.cc/categories/utils/"/>
    
    
      <category term="内网穿透" scheme="https://blog.patrickcty.cc/tags/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/"/>
    
  </entry>
  
  <entry>
    <title>使用keras进行语义分割注意事项</title>
    <link href="https://blog.patrickcty.cc/2019/08/22/%E4%BD%BF%E7%94%A8keras%E8%BF%9B%E8%A1%8C%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/"/>
    <id>https://blog.patrickcty.cc/2019/08/22/使用keras进行语义分割注意事项/</id>
    <published>2019-08-22T12:37:28.000Z</published>
    <updated>2019-08-22T12:38:25.198Z</updated>
    
    <content type="html"><![CDATA[<h2 id="总览"><a href="#总览" class="headerlink" title="总览"></a>总览</h2><ul>
<li>载入数据<ul>
<li>图像和标签相对应</li>
<li>数据预处理与增强</li>
<li>标签处理</li>
<li>标签还原与可视化预测结果 </li>
<li>多输入/出处理</li>
</ul>
</li>
<li>网络结构<ul>
<li>反卷积</li>
<li>上采样</li>
<li>todo</li>
</ul>
</li>
<li>训练脚本<ul>
<li>Warm-up</li>
<li>多输入/出（合并到第一部分）</li>
</ul>
</li>
</ul>
<h2 id="载入数据"><a href="#载入数据" class="headerlink" title="载入数据"></a>载入数据</h2><h3 id="图像和标签对应"><a href="#图像和标签对应" class="headerlink" title="图像和标签对应"></a>图像和标签对应</h3><p>语义分割中需要同时载入图像和标签，和分类问题不一样，语义分割的标签也是图像，因此要和载入的图像相对应。</p>
<p>如果使用 keras 自带的 ImageDataGenerator 来获取数据则需要分别为图像和标签初始化两个对象，并传入相同的随机化种子，具体操作如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"># we create two instances with the same arguments</div><div class="line">data_gen_args = dict(featurewise_center=True,</div><div class="line">                     featurewise_std_normalization=True,</div><div class="line">                     rotation_range=90,</div><div class="line">                     width_shift_range=0.1,</div><div class="line">                     height_shift_range=0.1,</div><div class="line">                     zoom_range=0.2)</div><div class="line">image_datagen = ImageDataGenerator(**data_gen_args)</div><div class="line">mask_datagen = ImageDataGenerator(**data_gen_args)</div><div class="line"></div><div class="line"># Provide the same seed and keyword arguments to the fit and flow methods</div><div class="line">seed = 1</div><div class="line">image_datagen.fit(images, augment=True, seed=seed)</div><div class="line">mask_datagen.fit(masks, augment=True, seed=seed)</div><div class="line"></div><div class="line">image_generator = image_datagen.flow_from_directory(</div><div class="line">    directory=&apos;data&apos;,</div><div class="line">    class_mode=None,</div><div class="line">    classes=[&apos;图像文件夹的名字&apos;],</div><div class="line">    seed=seed)</div><div class="line"></div><div class="line">mask_generator = mask_datagen.flow_from_directory(</div><div class="line">    &apos;data&apos;,</div><div class="line">    class_mode=None,</div><div class="line">    classes=[&apos;标签文件夹的名字&apos;],</div><div class="line">    seed=seed)</div><div class="line"></div><div class="line"># combine generators into one which yields image and masks</div><div class="line">train_generator = zip(image_generator, mask_generator)</div><div class="line"></div><div class="line">model.fit_generator(</div><div class="line">    directory=train_generator,</div><div class="line">    # 要指定这个参数，因为 zip 之后无法知道</div><div class="line">    # 每个 epoch 有多少次迭代</div><div class="line">    steps_per_epoch=2000,</div><div class="line">    epochs=50)</div></pre></td></tr></table></figure>
<p>其中要注意的有：</p>
<ul>
<li><code>flow_from_directory</code> 方法是通过 directory + class name 来寻找图片的，也就是说如果在这里让 <code>directory=&#39;data/images&#39;</code> 并且不设置 classes 则无法读取到图片；另外，<code>classes</code> 应该传入一个列表；还有则是 <code>class_mode</code> 要设置为 None，不然就会根据子文件夹名返回标签</li>
<li><code>fit_generator</code> 中要指定 <code>steps_per_epoch</code>，在这里可以通过 <code>ceil(len(image_generator / batch_size)</code> 来计算</li>
<li><code>fit</code> 和 <code>flow</code> 传入相同的随机化种子以保证生成相对应的图片</li>
</ul>
<h3 id="图像预处理与增强"><a href="#图像预处理与增强" class="headerlink" title="图像预处理与增强"></a>图像预处理与增强</h3><ul>
<li>标准化: <ul>
<li><code>img = (img - img_mean) / img_std</code></li>
<li>简化起见也可以 <code>img = img / 255 - 0.5</code></li>
</ul>
</li>
<li>数据增强：<ul>
<li>语义分割中最主要的增强是通过随机裁剪来进行的 ，具体的操作是把一张很大的图片随机裁剪出若干张(256, 256) 大小的图片，这样既增加了数据大小，也避免缩放出现的信息丢失</li>
<li>todo：还需要进一步查看文档</li>
</ul>
</li>
</ul>
<h3 id="标签处理"><a href="#标签处理" class="headerlink" title="标签处理"></a>标签处理</h3><p>由于语义分割的标签是和原图像同样大小的彩色图片，并且为了标注的方便，标签图像用一种颜色，也就是一组 RGB 的值来表示一种类别。</p>
<p>在进行损失函数的计算时，我们需要将 RGB 值转换成一组 one-hot 的标签，并且把图片拉成一个向量（以便于计算交叉熵损失）。比如对于 (256, 256, 3) 的标签，我们要将其转变成 (256 <strong> 2, 3) 的向量，然后转换为 (256 </strong> 2, num_classes) 的 one-hot 形式。具体的操作如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"># VOC 中的列表表示</div><div class="line">VOC_COLORMAP = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0],</div><div class="line">                [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128],</div><div class="line">                [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0],</div><div class="line">                [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128],</div><div class="line">                [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],</div><div class="line">                [0, 64, 128]]</div><div class="line"></div><div class="line">VOC_CLASSES = [&apos;background&apos;, &apos;aeroplane&apos;, &apos;bicycle&apos;, &apos;bird&apos;, &apos;boat&apos;,</div><div class="line">               &apos;bottle&apos;, &apos;bus&apos;, &apos;car&apos;, &apos;cat&apos;, &apos;chair&apos;, &apos;cow&apos;,</div><div class="line">               &apos;diningtable&apos;, &apos;dog&apos;, &apos;horse&apos;, &apos;motorbike&apos;, &apos;person&apos;,</div><div class="line">               &apos;potted plant&apos;, &apos;sheep&apos;, &apos;sofa&apos;, &apos;train&apos;, &apos;tv/monitor&apos;]</div><div class="line"></div><div class="line"># 完成 RGB 与类别数值的映射</div><div class="line">colormap2label = np.zeros(256 ** 3)</div><div class="line">label2colormap = np.zeros_like(VOC_CLASSES)</div><div class="line">for i, colormap in enumerate(VOC_COLORMAP):</div><div class="line">    idx = (colormap[0] * 256 + colormap[1]) * 256 + colormap[2]</div><div class="line">    colormap2label[idx] = i</div><div class="line">    label2colormap[i] = idx</div><div class="line"></div><div class="line">def mask_preprocessing(mask):</div><div class="line">    mask = mask.astype(&apos;int32&apos;)</div><div class="line">    if len(mask.shape) == 3:  # 输入为单个图片</div><div class="line">        w, h, _ = mask.shape</div><div class="line">        # 将 RGB 的类别值转换成单一数字表示的的类别值</div><div class="line">        idx = ((mask[:, :, 0] * 256 + mask[:, :, 1]) * 256 + mask[:, :, 2])</div><div class="line">        # 将图片拉成向量</div><div class="line">        new_mask = colormap2label[idx].reshape((w * h, -1))</div><div class="line">    else:  # len == 4  # 输入为一个 batch 的图片</div><div class="line">        b, w, h, _ = mask.shape</div><div class="line">        idx = ((mask[:, :, :, 0] * 256 + mask[:, :, :, 1]) * 256 + mask[:, :, :, 2])</div><div class="line">        new_mask = colormap2label[idx].reshape((b, w * h, -1))</div><div class="line">    # 将标签转换为 one-hot 的形式</div><div class="line">    r_mask = to_categorical(new_mask, num_classes=self.config.num_classes)</div><div class="line">    return r_mask</div></pre></td></tr></table></figure>
<h3 id="标签还原与可视化预测结果"><a href="#标签还原与可视化预测结果" class="headerlink" title="标签还原与可视化预测结果"></a>标签还原与可视化预测结果</h3><p>预测结果的标签和输入的一样都是一个 (w * h, num_classes) 的 one-hot 矩阵，我们要先将其变成非 one-hot 的类别形式，然后再还原成 RGB 的形式，然后将其变成图片的形状，之后输出的标签就和标注好的标签比较类似了。操作方法如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"># 将图片从单个数字表示的类别映射回 RGB</div><div class="line">def labelVisualize(self, num_class, img):</div><div class="line">    img = img[:, :, 0] if len(img.shape) == 3 else img</div><div class="line">    img_out = np.zeros(img.shape + (3,))</div><div class="line">    for i in range(num_class):</div><div class="line">        img_out[img == i, :] = VOC_COLORMAP[i]</div><div class="line">    return img_out / 255</div><div class="line"></div><div class="line">def mask_propressing(predict_mask_list, save_to=None):</div><div class="line">    # 这里是因为有多个输出因此要用循环来处理</div><div class="line">    for i in range(len(predict_mask_list)):</div><div class="line">        # 将 one-hot 还原</div><div class="line">        num_classes = predict_mask_list[0].shape[-1]</div><div class="line">        predict_mask = predict_mask_list[i]</div><div class="line">        num_classes = predict_mask.shape[-1]</div><div class="line">        mkdir_if_not_exist(os.path.join(save_to, str(i)))</div><div class="line">        if len(predict_mask.shape) == 3:  # (?, 65536, 21)</div><div class="line">            temp_mask = predict_mask.reshape((predict_mask.shape[0], self.config.input_shape,</div><div class="line">                                              self.config.input_shape, num_classes))</div><div class="line">            for item in temp_mask:</div><div class="line">                img = self.labelVisualize(num_classes, item)</div><div class="line">                if save_to:</div><div class="line">                    io.imsave(os.path.join(save_to, str(i), &apos;%s_pred.png&apos; % str(uuid.uuid4())[:4]), img)</div><div class="line"></div><div class="line">        else:  # (65536, 21)</div><div class="line">            temp_mask = predict_mask.reshape((self.config.input_shape, self.config.input_shape, num_classes))</div><div class="line">            img = self.labelVisualize(num_classes, temp_mask)</div><div class="line">            if save_to:</div><div class="line">                io.imsave(os.path.join(save_to, str(i), &apos;%s_pred.png&apos; % str(uuid.uuid4())[:4]), img)</div></pre></td></tr></table></figure>
<h3 id="多输出处理"><a href="#多输出处理" class="headerlink" title="多输出处理"></a>多输出处理</h3><p>如果神经网络有多输入/出，则对于每个输入和输出都要有相应的标签进行对应：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"># 输入到 fit_generator 的形式</div><div class="line"># tuple 的第一个第二个分别是输入和输入</div><div class="line"># 多个不同的通过名字和数据的字典来对应</div><div class="line">(&#123;&apos;input1&apos;: img1, &apos;input2&apos;, img2&#125;, </div><div class="line"> &#123;&apos;pred1&apos;: mask1, &apos;pred2&apos;: mask2, &apos;pred3&apos;: mask3&#125;)</div><div class="line"> </div><div class="line"># 输入 comple 的形式</div><div class="line"># 这里主要是对输入的内容进行指定</div><div class="line">model.compile(optimizer=&apos;rmsprop&apos;,</div><div class="line">              loss=&#123;&apos;pred1&apos;: &apos;binary_crossentropy&apos;, &apos;pred2&apos;: &apos;binary_crossentropy&apos;&#125;,</div><div class="line">              &apos;pred3&apos;: &apos;binary_crossentropy&apos;&#125;,</div><div class="line">              loss_weights=&#123;&apos;pred1&apos;: 1., &apos;pred2&apos;: 0.2, &apos;pred3&apos;: 0.2&#125;)</div></pre></td></tr></table></figure>
<h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p>todo</p>
<h2 id="训练脚本"><a href="#训练脚本" class="headerlink" title="训练脚本"></a>训练脚本</h2><h3 id="Warm-up"><a href="#Warm-up" class="headerlink" title="Warm-up"></a>Warm-up</h3><p>在开始的时候使用比较小的学习率训练，再使用正常的学习率训练，这种方法可以防止神经网络在一开始跑向了错误的方向而取得不理想的效果。</p>
<p>假设初始的学习率为 <code>lr_init</code>，warm-up 的 epoch 数为 <code>num</code>，当前 epoch 数为 <code>i</code>（从 1 开始计数），则当前学习率为：<code>lr = lr_init * i / num (i &lt; num)</code>。</p>
<p>在 keras 里面可以用 LeaningRateScheduler 的回调来实现：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">def lr_scheduler_warm_up(epoch_idx, cur_lr):</div><div class="line">    if epoch_idx == 0:</div><div class="line">        return cur_lr / 5</div><div class="line">    if epoch_idx &lt; 5:  # 前五个 epoch</div><div class="line">        return cur_lr * (epoch_idx + 1) / epoch_idx</div><div class="line">    return cur_lr</div><div class="line"></div><div class="line">lr_warm_up = LearningRateScheduler(lr_scheduler_warm_up)</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;总览&quot;&gt;&lt;a href=&quot;#总览&quot; class=&quot;headerlink&quot; title=&quot;总览&quot;&gt;&lt;/a&gt;总览&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;载入数据&lt;ul&gt;
&lt;li&gt;图像和标签相对应&lt;/li&gt;
&lt;li&gt;数据预处理与增强&lt;/li&gt;
&lt;li&gt;标签处理&lt;/li&gt;
&lt;li&gt;标
    
    </summary>
    
      <category term="keras" scheme="https://blog.patrickcty.cc/categories/keras/"/>
    
      <category term="深度学习" scheme="https://blog.patrickcty.cc/categories/keras/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="语义分割" scheme="https://blog.patrickcty.cc/categories/keras/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    
    
      <category term="语义分割" scheme="https://blog.patrickcty.cc/tags/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    
  </entry>
  
  <entry>
    <title>深度学习一些概念整理</title>
    <link href="https://blog.patrickcty.cc/2019/05/03/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5%E6%95%B4%E7%90%86/"/>
    <id>https://blog.patrickcty.cc/2019/05/03/深度学习一些概念整理/</id>
    <published>2019-05-03T03:26:37.000Z</published>
    <updated>2019-12-30T13:48:30.511Z</updated>
    
    <content type="html"><![CDATA[<h2 id="全连接层转换为卷积层"><a href="#全连接层转换为卷积层" class="headerlink" title="全连接层转换为卷积层"></a>全连接层转换为卷积层</h2><h3 id="如何转换"><a href="#如何转换" class="headerlink" title="如何转换"></a>如何转换</h3><p>卷积层与全连接层可以相互转换，例如，对于输入为 7 <em> 7 </em> 512 的有 4096 个神经元的全连接层，可以表示为如下的卷积层：</p>
<ul>
<li>Kernel size: 7</li>
<li>Padding: 0</li>
<li>Stride: 1</li>
<li>Filters: 4096</li>
</ul>
<p>这样卷积层输出就是 1 <em> 1 </em> 4096，与全连接层的输出相同。</p>
<h3 id="转换的原理"><a href="#转换的原理" class="headerlink" title="转换的原理"></a>转换的原理</h3><p>还是以上面的为例，全连接层的每个输出（1/4096）需要输入的每一个元素都参与，即：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Dense_&#123;out_i&#125; = \Sigma_&#123;j=1&#125;^&#123;25088&#125;&#123;(w_&#123;ij&#125; * in_j)&#125; \\ i = 1, 2, \dots, 4096</div></pre></td></tr></table></figure>
<p>而对应的卷积层的输出也是需要每个元素的参与，即：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Conv_&#123;out_i&#125; = \Sigma_&#123;j=1&#125;^&#123;512&#125;&#123;\Sigma_&#123;k=1&#125;^&#123;49&#125;&#123;(w_&#123;ijk&#125; * in_&#123;jk&#125;)&#125;&#125; \\ i = 1, 2, \dots, 4096</div></pre></td></tr></table></figure>
<p>可以看出来，本质没有变，只是形式变了。</p>
<h3 id="转换的作用"><a href="#转换的作用" class="headerlink" title="转换的作用"></a>转换的作用</h3><ul>
<li>便于计算不同分辨率的输入</li>
</ul>
<p>比如 AlexNet 输入为 227 <em> 227，如果输入为 384 </em> 384 则到了全连接层会报错，而如果进行了如上转换，则会正常输出，不过输出结果为 6 <em> 6 </em> 1000 而非 1 <em> 1 </em> 1000。</p>
<p>实际上，常用于分割任务上的全卷积网络（FCN）就使用了这种方法去掉了全连接层以支持不同分辨率的输入。</p>
<h2 id="1-1-卷积核作用"><a href="#1-1-卷积核作用" class="headerlink" title="1 * 1 卷积核作用"></a>1 * 1 卷积核作用</h2><ul>
<li>实现数据维度改变</li>
</ul>
<p>可以把维度从 m <em> n </em> 10 改变到 m <em> n </em> 5 或者 m <em> n </em> 50，只需要改变 filter 的数量</p>
<ul>
<li>实现跨通道的交互信息的整合</li>
</ul>
<p>由于次个卷积会把多个通道的信息汇总，因此这个 1 * 1 卷积的过程也会把跨通道的交互信息整合起来</p>
<ul>
<li>增加非线性</li>
</ul>
<p>通过卷积之后的非线性激活函数来实现</p>
<p>具体讲解参考<a href="https://zhuanlan.zhihu.com/p/40050371" target="_blank" rel="external">这篇文章</a>。</p>
<h2 id="Global-Average-Pooling-GAP-作用"><a href="#Global-Average-Pooling-GAP-作用" class="headerlink" title="Global Average Pooling (GAP) 作用"></a>Global Average Pooling (GAP) 作用</h2><p>GAP 是用来将每个通道的信息统一到同一个像素上，比如输入为 7 <em> 7 </em> 512 的张量，经过 GAP 之后输出就是 1 <em> 1 </em> 512。</p>
<ul>
<li>代替全连接层</li>
</ul>
<p>CNN 最后一层卷积的输出就是一个高度提取的 feature map（本质上是特征），而全连接层就是将最后一层卷积得到的特征整合起来映射到样本空间（分类，识别等）（由于有非线性激活函数，因此不是线性映射）。</p>
<p>具体理解参照<a href="https://www.zhihu.com/question/41037974/answer/320267531" target="_blank" rel="external">这个回答</a>。</p>
<p>关于 GAP 的效果对比可以参考<a href="https://www.cnblogs.com/hutao722/p/10008581.html" target="_blank" rel="external">这篇博客</a>。</p>
<p>我自己在小型的神经网络上训练的结果（GAP 代替了 128 FC）是使用 GAP 提高了 2% 左右的准确度。</p>
<h2 id="batch"><a href="#batch" class="headerlink" title="batch"></a>batch</h2><p>深度学习更新参数通常不是由一个数据来决定的，不然更新的方向可能会差别较大（一下这边一下那边）。</p>
<p>一批里面有多个数据更容易朝着正确的方向进行，利用各个数据之间的一些共性。</p>
<p>另外，使用批处理也避免了一次使用所有数据进行训练，减小了显存的压力，也更有可能找到极小值。</p>
<h2 id="epoch"><a href="#epoch" class="headerlink" title="epoch"></a>epoch</h2><p>一个完整的数据集经过网络一次并返回一次的结果。一个 epoch 并不一定能让网络达到最佳的方向，因而要训练多个 epoch，但是训练过多会过拟合。</p>
<h2 id="Batch-Normalization-作用"><a href="#Batch-Normalization-作用" class="headerlink" title="Batch Normalization 作用"></a>Batch Normalization 作用</h2><p>将一个 batch 中的各个元素归一化（各个通道分别进行 BN），通常放到激活函数之前。</p>
<p>好处：</p>
<ul>
<li>减小梯度弥散（梯度消失/爆炸）</li>
</ul>
<p>改变激活函数的输入，让数据分布更均匀，从而杀掉的神经元更少。</p>
<ul>
<li>训练更快，可以用更高的学习率</li>
</ul>
<p>数据分布更均匀，神经网络不用去适应各种分布</p>
<ul>
<li>一定程度增加泛化能力，避免过拟合</li>
</ul>
<p>数据通过 BN 处理引入的随机噪声能够起到对模型参数进行正则化的作用，有利于增强模型泛化能力</p>
<p>缺陷：</p>
<ul>
<li>不适用 batch 非常小</li>
<li>不适用 RNN</li>
</ul>
<p>关于 BN 的理解，尤其是背后的原理理解参考<a href="https://www.jiqizhixin.com/articles/2018-08-29-7" target="_blank" rel="external">这篇文章</a></p>
<h2 id="验证-测试集的作用"><a href="#验证-测试集的作用" class="headerlink" title="验证/测试集的作用"></a>验证/测试集的作用</h2><h3 id="验证集"><a href="#验证集" class="headerlink" title="验证集"></a>验证集</h3><ul>
<li>与测试集同分布，用来观察训练的走向（是否过拟合等）</li>
<li>选择超参数</li>
</ul>
<h3 id="测试集"><a href="#测试集" class="headerlink" title="测试集"></a>测试集</h3><p>评估模型的训练状况，检验泛化能力</p>
<h2 id="Softmax-是什么"><a href="#Softmax-是什么" class="headerlink" title="Softmax 是什么"></a>Softmax 是什么</h2><p>Softmax 函数用来产生 k 个概率，而 Softmax 损失函数，准确来说是用 Softmax 的结果来计算交叉熵分类损失函数。</p>
<p>Softmax 函数可以参考<a href="https://blog.csdn.net/ture_dream/article/details/54948518" target="_blank" rel="external">这篇博文</a>，交叉熵可以参考<a href="https://zhuanlan.zhihu.com/p/35709485" target="_blank" rel="external">这篇博文</a>。</p>
<h2 id="logits-是什么"><a href="#logits-是什么" class="headerlink" title="logits 是什么"></a>logits 是什么</h2><p>出现于 <code>tf.nn.softmax_cross_entropy_with_logits</code>，简单来说就是 softmax 的输入。更多内容可以参考<a href="https://www.zhihu.com/question/60751553" target="_blank" rel="external">这个问题</a>。</p>
<h2 id="weight-的冷知识"><a href="#weight-的冷知识" class="headerlink" title="weight 的冷知识"></a>weight 的冷知识</h2><p>weight decay = 对 weight 施加 norm = 对输入数据增加方差小的噪音</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;全连接层转换为卷积层&quot;&gt;&lt;a href=&quot;#全连接层转换为卷积层&quot; class=&quot;headerlink&quot; title=&quot;全连接层转换为卷积层&quot;&gt;&lt;/a&gt;全连接层转换为卷积层&lt;/h2&gt;&lt;h3 id=&quot;如何转换&quot;&gt;&lt;a href=&quot;#如何转换&quot; class=&quot;head
    
    </summary>
    
      <category term="深度学习" scheme="https://blog.patrickcty.cc/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Batch Normalization" scheme="https://blog.patrickcty.cc/tags/Batch-Normalization/"/>
    
      <category term="Global Average Pooling" scheme="https://blog.patrickcty.cc/tags/Global-Average-Pooling/"/>
    
      <category term="Deep Learning" scheme="https://blog.patrickcty.cc/tags/Deep-Learning/"/>
    
      <category term="CNN" scheme="https://blog.patrickcty.cc/tags/CNN/"/>
    
  </entry>
  
  <entry>
    <title>cifar100实验</title>
    <link href="https://blog.patrickcty.cc/2019/05/03/cifar100%E5%AE%9E%E9%AA%8C/"/>
    <id>https://blog.patrickcty.cc/2019/05/03/cifar100实验/</id>
    <published>2019-05-03T02:44:20.000Z</published>
    <updated>2019-05-03T02:45:03.723Z</updated>
    
    <content type="html"><![CDATA[<h2 id="实验一：初步探究-BN-作用"><a href="#实验一：初步探究-BN-作用" class="headerlink" title="实验一：初步探究 BN 作用"></a>实验一：初步探究 BN 作用</h2><h3 id="基本配置"><a href="#基本配置" class="headerlink" title="基本配置"></a>基本配置</h3><ul>
<li>A：使用 VGG16 + BN + GAP</li>
<li>B：使用 VGG16 + GAP</li>
<li>数据集 cifar100</li>
<li>Adam，30 epoch</li>
</ul>
<h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><ul>
<li>A：train acc：90%+，test acc：50%，发生严重的过拟合</li>
<li>B：train acc：1%，发生严重的欠拟合</li>
</ul>
<h3 id="结果分析"><a href="#结果分析" class="headerlink" title="结果分析"></a>结果分析</h3><p>BN 在防止梯度弥散这方面起了重要的作用，让深层的神经网络在面对很小的数据的时候也能够拟合。</p>
<h2 id="实验二：探究-GAP-作用"><a href="#实验二：探究-GAP-作用" class="headerlink" title="实验二：探究 GAP 作用"></a>实验二：探究 GAP 作用</h2><h3 id="基本配置-1"><a href="#基本配置-1" class="headerlink" title="基本配置"></a>基本配置</h3><ul>
<li>A：使用 VGG16 + 256 fc * 2 + BN</li>
<li>B：使用 VGG16 + 256 fc * 2</li>
<li>数据集 cifar100</li>
<li>Adam，30 epoch</li>
</ul>
<h3 id="实验结果-1"><a href="#实验结果-1" class="headerlink" title="实验结果"></a>实验结果</h3><p>A，B train acc 均为 1%，发生严重的欠拟合</p>
<h3 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h3><p>怀疑是因为：</p>
<ul>
<li>数据维度过小，后面的卷积层很难提取特征（1 <em> 1， 2 </em> 2 这样的大小）</li>
<li>全连接层神经元太少（只有 256 * 2）</li>
<li>GAP 把过于分散的特征“结合”了起来，因此实验一在 BN 的帮助下还是可以拟合的</li>
</ul>
<h2 id="实验三：实验二欠拟合探究之一"><a href="#实验三：实验二欠拟合探究之一" class="headerlink" title="实验三：实验二欠拟合探究之一"></a>实验三：实验二欠拟合探究之一</h2><h3 id="基本配置-2"><a href="#基本配置-2" class="headerlink" title="基本配置"></a>基本配置</h3><ul>
<li>A：使用 VGG16 + 4096 fc * 2 + BN</li>
<li>B：使用 VGG16 + 256 fc <em> 2 + 图像缩放到 80 </em> 80 </li>
<li>数据集 cifar100</li>
<li>Adam，30 epoch</li>
</ul>
<h3 id="实验结果-2"><a href="#实验结果-2" class="headerlink" title="实验结果"></a>实验结果</h3><ul>
<li>A：train acc：69%，test acc：43%，略有过拟合</li>
<li>B：train acc：1%，欠拟合严重</li>
</ul>
<h3 id="结果分析-1"><a href="#结果分析-1" class="headerlink" title="结果分析"></a>结果分析</h3><p>增加了 fc 神经元个数之后就开始拟合了，效果好了一些，因此上一个推测二是对的；增加了图像的大大小之后还是不能拟合，因而单纯缩放是无法解决问题的（症结还是在网络骨架的结构上）。</p>
<h2 id="实验四：实验二欠拟合探究之二"><a href="#实验四：实验二欠拟合探究之二" class="headerlink" title="实验四：实验二欠拟合探究之二"></a>实验四：实验二欠拟合探究之二</h2><h3 id="基本配置-3"><a href="#基本配置-3" class="headerlink" title="基本配置"></a>基本配置</h3><ul>
<li>A：使用 VGG16 + BN + 4096 fc * 2（去掉 vgg block 5）</li>
<li>B：使用 VGG16 + 4096 fc <em> 2 + 图像缩放到 80 </em> 80 </li>
<li>数据集 cifar100</li>
<li>Adam，30 epoch</li>
</ul>
<h3 id="实验结果-3"><a href="#实验结果-3" class="headerlink" title="实验结果"></a>实验结果</h3><ul>
<li>A：train acc：75%，test acc：48%，有过拟合</li>
<li>B：train acc：1%，欠拟合严重</li>
</ul>
<h3 id="结果分析-2"><a href="#结果分析-2" class="headerlink" title="结果分析"></a>结果分析</h3><p>进一步表明图像缩不是症结所在果，图像本身太小了，持续的池化让 shape 过小，再使用卷积反而起反作用，因而效果差了。</p>
<h2 id="实验五：深入研究-BN-作用"><a href="#实验五：深入研究-BN-作用" class="headerlink" title="实验五：深入研究 BN 作用"></a>实验五：深入研究 BN 作用</h2><h3 id="基本配置-4"><a href="#基本配置-4" class="headerlink" title="基本配置"></a>基本配置</h3><ul>
<li>A：使用 VGG16 + GAP + BN（去掉 vgg block 5）</li>
<li>B：使用 VGG16 + GAP（去掉 vgg block 5）</li>
<li>C：使用 VGG16 + GAP + BN（去掉 vgg block 4、5）</li>
<li>D：使用 VGG16 + GAP（去掉 vgg block 4、5）</li>
<li>数据集 cifar100</li>
<li>Adam，30 epoch</li>
</ul>
<h3 id="实验结果-4"><a href="#实验结果-4" class="headerlink" title="实验结果"></a>实验结果</h3><ul>
<li>A：train acc：98%，test acc：53%，发生严重过拟合</li>
<li>B：train acc：&lt;1%，欠拟合严重</li>
<li>C：train acc：98%，test acc：59%，发生严重过拟合</li>
<li>D：train acc：87%，test acc：34%，过拟合严重且结果也一般</li>
</ul>
<h3 id="结果分析-3"><a href="#结果分析-3" class="headerlink" title="结果分析"></a>结果分析</h3><p>BN 确实厉害，可以有效防止过拟合，梯度弥散。</p>
<ul>
<li>同样是过拟合没加 BN 过拟合程度比加了要严重不少。</li>
<li>同样是多了一个 block，没有 BN 就直接梯度消失没办法拟合，有了 BN 尽管会过拟合但是可以非常顺利训练下来。</li>
</ul>
<p>而且加了 BN 之后训练的训读会快一些（A：47s-&gt;B：65s，C：24s-&gt;D：39s）</p>
<h2 id="实验六：过拟合探究"><a href="#实验六：过拟合探究" class="headerlink" title="实验六：过拟合探究"></a>实验六：过拟合探究</h2><h3 id="基本配置-5"><a href="#基本配置-5" class="headerlink" title="基本配置"></a>基本配置</h3><ul>
<li>A：使用 VGG16（去掉 vgg block 4、5） + GAP + BN + l2_normalization（所有卷积层都加 l2）+ 60 epoch</li>
<li>B：使用 VGG16（去掉 vgg block 4、5） + GAP + BN + l2_normalization（l2 只加到最后一个卷积上）+ 30 epoch</li>
<li>C：使用 VGG16（去掉 vgg block 4、5） + GAP + BN + l2_normalization（l2 只加到最后三个卷积上）+ 30 epoch</li>
<li>数据集 cifar100</li>
<li>Adam</li>
</ul>
<h3 id="实验结果-5"><a href="#实验结果-5" class="headerlink" title="实验结果"></a>实验结果</h3><ul>
<li>A：train acc：51.8%，test acc：38%，虽然过拟合没那么严重，但是效果比较差</li>
<li>B：train acc：93%，test acc：46%，惩罚作用太弱，过拟合严重</li>
<li>C：<ul>
<li>30 epoch：train acc：71%，test acc：43%，惩罚作用较强，过拟合依旧严重</li>
<li>60 epoch：train acc：84%，test acc：39%，惩罚作用较强，过拟合依旧严重</li>
</ul>
</li>
</ul>
<h3 id="结果分析-4"><a href="#结果分析-4" class="headerlink" title="结果分析"></a>结果分析</h3><p>l2_normalization 如果在全局应用会使惩罚作用太强，性能严重降低；只在最后一层加惩罚效果又太弱；在最后三层加则不仅性能差而且过拟合依旧严重。</p>
<p>这几次实验都是训练到最后，没有加入验证集，从而没有在过拟合之前停止下来查看效果。</p>
<p>不过实验证明了加 l2 正则并不是一个非常有效的方法。或者是 l2 正则不应该这样用。</p>
<h2 id="实验七：图片预处理"><a href="#实验七：图片预处理" class="headerlink" title="实验七：图片预处理"></a>实验七：图片预处理</h2><h3 id="基本配置-6"><a href="#基本配置-6" class="headerlink" title="基本配置"></a>基本配置</h3><ul>
<li>使用 VGG16 + GAP + BN + 预处理（去掉 vgg block 4、5）</li>
<li>数据集 cifar100</li>
<li>Adam，40 epoch</li>
</ul>
<h3 id="实验结果-6"><a href="#实验结果-6" class="headerlink" title="实验结果"></a>实验结果</h3><p>train acc：98%，test acc：65%，过拟合略有缓解</p>
<h3 id="结果分析-5"><a href="#结果分析-5" class="headerlink" title="结果分析"></a>结果分析</h3><p>给图片做预处理果然有用，缓解过拟合效果不错。不过需要注意，训练图片和测试图片格式必须一样！！！（比如如果要除以 255 就都要除），不然就是百分之百测试效果很差了 233。</p>
<h2 id="实验总结"><a href="#实验总结" class="headerlink" title="实验总结"></a>实验总结</h2><ul>
<li>对于小的输入不要使用太复杂的神经网络，不然梯度消失反而会起到反作用</li>
<li>设计网络时将最后一层卷积输出控制在 4 <em> 4 </em> 512 比较好</li>
<li>使用 BN 可以有效加快训练速度，缓解梯度弥散</li>
<li>使用 GAP 代替全连接层，减小训练量，降低过拟合</li>
<li>使用图片预处理减轻过拟合</li>
<li>l2 normalization 慎用</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;实验一：初步探究-BN-作用&quot;&gt;&lt;a href=&quot;#实验一：初步探究-BN-作用&quot; class=&quot;headerlink&quot; title=&quot;实验一：初步探究 BN 作用&quot;&gt;&lt;/a&gt;实验一：初步探究 BN 作用&lt;/h2&gt;&lt;h3 id=&quot;基本配置&quot;&gt;&lt;a href=&quot;#基
    
    </summary>
    
      <category term="深度学习" scheme="https://blog.patrickcty.cc/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="https://blog.patrickcty.cc/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Batch Normalization" scheme="https://blog.patrickcty.cc/tags/Batch-Normalization/"/>
    
      <category term="Global Average Pooling" scheme="https://blog.patrickcty.cc/tags/Global-Average-Pooling/"/>
    
  </entry>
  
  <entry>
    <title>图像检索一些指标</title>
    <link href="https://blog.patrickcty.cc/2019/04/26/%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2%E4%B8%80%E4%BA%9B%E6%8C%87%E6%A0%87/"/>
    <id>https://blog.patrickcty.cc/2019/04/26/图像检索一些指标/</id>
    <published>2019-04-26T02:27:44.000Z</published>
    <updated>2019-05-03T03:30:23.090Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Precision-查准率"><a href="#Precision-查准率" class="headerlink" title="Precision 查准率"></a>Precision 查准率</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Precision = \frac&#123;TP&#125;&#123;TP + TN&#125;</div></pre></td></tr></table></figure>
<p>即检索到的这些结果中正确结果的比例。</p>
<h2 id="Recall-查全率"><a href="#Recall-查全率" class="headerlink" title="Recall 查全率"></a>Recall 查全率</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Recall = \frac&#123;TP&#125;&#123;TP + FN&#125;</div></pre></td></tr></table></figure>
<p>即检索到的正确结果占所有正确结果的比例。</p>
<h2 id="F-measure"><a href="#F-measure" class="headerlink" title="F-measure"></a>F-measure</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Recall = 2 \cdot \frac&#123;Precision \cdot Recall&#125;&#123;Precision + Recall&#125;</div></pre></td></tr></table></figure>
<p>综合描述 Precision 和 Recall。</p>
<h2 id="PR-曲线"><a href="#PR-曲线" class="headerlink" title="PR 曲线"></a>PR 曲线</h2><p>描述 Precision 和 Recall 变化关系的曲线，一般来说 Precision 越高 Recall 就比较低，反之亦然。</p>
<p>用来进行二者之间的取舍，一般检索类的要保证 Recall 提高 Precision，反垃圾等则要保证 Precision 提高 Recall。</p>
<h2 id="AP-和-mAP"><a href="#AP-和-mAP" class="headerlink" title="AP 和 mAP"></a>AP 和 mAP</h2><p>分别为：图像检索精度（average precision，AP）与平均检索精度（mean average precision，mAP）。</p>
<p>这两个指标是为了解决 P，R，F-measure 的单点值局限性，考虑了检索效果的排名情况。</p>
<p>计算方法参考[1]。</p>
<h2 id="top-k"><a href="#top-k" class="headerlink" title="top@k"></a>top@k</h2><p>指检索返回的结果为 k 个，一般作为评价 P，R，mAP 等指标的阈值。</p>
<h2 id="信息检索评价指标"><a href="#信息检索评价指标" class="headerlink" title="信息检索评价指标"></a>信息检索评价指标</h2><p>一般是 Precision，Recall，mAP</p>
<h2 id="ROC-曲线和-AUC"><a href="#ROC-曲线和-AUC" class="headerlink" title="ROC 曲线和 AUC"></a>ROC 曲线和 AUC</h2><p>这个是用来评价二分类器所用指标，ROC 纵轴为 TPR（True Positive Rate），横轴为 FPR（False Positive Rate，公式分别为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">TPR = \frac&#123;TP&#125;&#123;TP + FN&#125;</div><div class="line"></div><div class="line">FPR = \frac&#123;fP&#125;&#123;FP + TN&#125;</div></pre></td></tr></table></figure>
<p>AUC（Area Under Curve）即 ROC 曲线与坐标轴围成的面积，一般不小于 0.5，越大表示分类效果越好。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] <a href="http://yongyuan.name/blog/evaluation-of-information-retrieval.html" target="_blank" rel="external">http://yongyuan.name/blog/evaluation-of-information-retrieval.html</a><br>[2] <a href="https://blog.csdn.net/marising/article/details/6543943" target="_blank" rel="external">https://blog.csdn.net/marising/article/details/6543943</a><br>[3] <a href="https://zhuanlan.zhihu.com/p/34079183" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/34079183</a><br>[4] <a href="https://blog.csdn.net/Lu597203933/article/details/41802155" target="_blank" rel="external">https://blog.csdn.net/Lu597203933/article/details/41802155</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Precision-查准率&quot;&gt;&lt;a href=&quot;#Precision-查准率&quot; class=&quot;headerlink&quot; title=&quot;Precision 查准率&quot;&gt;&lt;/a&gt;Precision 查准率&lt;/h2&gt;&lt;figure class=&quot;highlight plai
    
    </summary>
    
      <category term="深度学习" scheme="https://blog.patrickcty.cc/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Deep Learning" scheme="https://blog.patrickcty.cc/tags/Deep-Learning/"/>
    
      <category term="Information Retrieval" scheme="https://blog.patrickcty.cc/tags/Information-Retrieval/"/>
    
  </entry>
  
  <entry>
    <title>关于毕业设计的一些事</title>
    <link href="https://blog.patrickcty.cc/2019/04/16/%E5%85%B3%E4%BA%8E%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BA%8B/"/>
    <id>https://blog.patrickcty.cc/2019/04/16/关于毕业设计的一些事/</id>
    <published>2019-04-16T15:55:49.000Z</published>
    <updated>2019-05-03T03:29:37.042Z</updated>
    
    <content type="html"><![CDATA[<h2 id="漫画人脸二分类"><a href="#漫画人脸二分类" class="headerlink" title="漫画人脸二分类"></a>漫画人脸二分类</h2><p>一开始我一直想用 VGG 来实现漫画人脸的二分类，即判断是不是人脸。但是效果一直很差，acc 和随便猜的一模一样（50%）。</p>
<p>这时候我一直以为是数据有问题，不过在洗过好多次之后我发现并非如此，出问题的不是数据，而是数据和网络不匹配。</p>
<p>换句话来说就是漫画人脸中包含的要素太少，使用 VGG 这种深层网络会让特征到最后“消失殆尽”，所以最后效果就很差了。</p>
<p>为了验证这个猜想，我使用 VGG 训练 MNIST，结果不出意料的也是随便猜的概率（10%）。</p>
<p>++当然上面的也只是猜想，因为我对 CNN 理解还是太浅，这个基础问题还得在之后再恶补一下了。++</p>
<p>心里有这个概念之后我就尝试用浅一点的网络来解决问题了，尝试着用 AlexNet 和另一个浅一点的 CNN 来训练模型，虽然最后在二分类问题上能达到 80% 左右 的准确率，但是还有一个大问题又被我忽视掉了。</p>
<p>在尝试这两个网络中，我又在其中加入了 bn 层，不过加入之后浅层的 CNN acc 又变成了 50%……</p>
<h3 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h3><p>MNIST 这个 acc 这么低，原因不是我想的那样，而是我在处理输入的时候直接无脑 resize，破坏了原来图片的语义……使用正常的处理方法就能得到正确的结果了，并不是 VGG 的锅……</p>
<p>那么问题来了，我的漫画网络究竟是哪里出问题了呢……</p>
<h2 id="提取特征"><a href="#提取特征" class="headerlink" title="提取特征"></a>提取特征</h2><p>Acc 80%，这是一个不算特别好又不算坏的结果。但是试了很多种方法一时间没能找到更高的准确度，于是就准备拿这个模型来提取特征了。</p>
<p>不过在这个过程中，我有又发现了一个大问题：提取出来的特征太稀疏了，256 维的特征中，只有不到十个元素不为零……而 flatten 层也仅有 1/8 左右的不为零。虽然我内心没有逼数，但这的确是一个不正常的现象。</p>
<p>==后面我准备训练 MNIST 来观察一下各层的正常输出应该是怎么样的。==</p>
<h3 id="检索系统中遇到的坑"><a href="#检索系统中遇到的坑" class="headerlink" title="检索系统中遇到的坑"></a>检索系统中遇到的坑</h3><ul>
<li><code>ValueError: Tensor Tensor(&quot;Sigmoid_2:0&quot;, shape=(?, 17), dtype=float32) is not an element of this graph.</code></li>
</ul>
<p>出现这个问题的原因就是多线程、分布式环境下，恢复 Model 时的 Tensor Graph 和生成 Model 时不同。</p>
<p>具体来说就是模型是在全局变量里面恢复的，但是调用是在 Flask 的多线程调用的。</p>
<p>解决方法就是在恢复 Model 的时候保存相应的 Graph，然后再在 predict 的时候恢复这个 Graph 即可。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"># when load model</div><div class="line">graph = tf.get_default_graph()</div><div class="line"></div><div class="line"># when use model in another thread</div><div class="line">global graph</div><div class="line">with graph.as_default():</div><div class="line">    (... do inference here ...)</div></pre></td></tr></table></figure>
<p>参考资料：</p>
<ul>
<li><a href="https://github.com/keras-team/keras/issues/2397" target="_blank" rel="external">https://github.com/keras-team/keras/issues/2397</a></li>
<li><p><a href="https://justttry.github.io/justttry.github.io/not-an-element-of-Tensor-graph/" target="_blank" rel="external">https://justttry.github.io/justttry.github.io/not-an-element-of-Tensor-graph/</a></p>
</li>
<li><p><code>FailedPreconditionError: tensorflow not found container localhost does not exist</code></p>
</li>
</ul>
<p>这个问题比较玄学，好像各种问题都可能报这个错误。我出现这个问题的原因可能是 tf 的版本和 keras 的版本有些冲突，使用系统的 Python 不行，但是换成 Anaconda 的 Python 就没问题了。</p>
<p>不过需要注意的是，tf.keras 和 keras 并不是一个东西，如果两个混用的话是会出现各种错误的，如果用到了某一个就一条路走到黑。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;漫画人脸二分类&quot;&gt;&lt;a href=&quot;#漫画人脸二分类&quot; class=&quot;headerlink&quot; title=&quot;漫画人脸二分类&quot;&gt;&lt;/a&gt;漫画人脸二分类&lt;/h2&gt;&lt;p&gt;一开始我一直想用 VGG 来实现漫画人脸的二分类，即判断是不是人脸。但是效果一直很差，acc 和随便
    
    </summary>
    
      <category term="Python" scheme="https://blog.patrickcty.cc/categories/Python/"/>
    
      <category term="深度学习" scheme="https://blog.patrickcty.cc/categories/Python/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="Deep Learning" scheme="https://blog.patrickcty.cc/tags/Deep-Learning/"/>
    
      <category term="TensorFlow" scheme="https://blog.patrickcty.cc/tags/TensorFlow/"/>
    
      <category term="Keras" scheme="https://blog.patrickcty.cc/tags/Keras/"/>
    
  </entry>
  
  <entry>
    <title>安装 OpenCV C++ 库以及运行相应程序</title>
    <link href="https://blog.patrickcty.cc/2019/04/07/%E5%AE%89%E8%A3%85OpenCV/"/>
    <id>https://blog.patrickcty.cc/2019/04/07/安装OpenCV/</id>
    <published>2019-04-07T07:40:53.000Z</published>
    <updated>2019-05-03T03:31:38.203Z</updated>
    
    <content type="html"><![CDATA[<h2 id="扯两句废话"><a href="#扯两句废话" class="headerlink" title="扯两句废话"></a>扯两句废话</h2><p>之前用惯了 Python，以为使用 C++ 的模块也是直接一行命令安装然后再直接编译就可以了，没想到并没有这么简单，还是需要其他的一些步骤。</p>
<p>于是这两天在不会 C++ 上吃了大亏 orz。</p>
<h2 id="Ubuntu-安装-OpenCV"><a href="#Ubuntu-安装-OpenCV" class="headerlink" title="Ubuntu 安装 OpenCV"></a>Ubuntu 安装 OpenCV</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt-get install libopencv-dev</div></pre></td></tr></table></figure>
<p>没错，一行命令完事。</p>
<p>一开始我是老老实实下载、编译的（因为搜安装教程完全没看到用 apt 安装的，于是我以为只能编译来安装了 orz），结果配了半天环境变量还是找不到 OpenCV 的包，最后这行命令下去直接就一切 ok 了。</p>
<p>检查 OpenCV 是否安装成功：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pkg-config --cflags --libs opencv</div></pre></td></tr></table></figure>
<p>如果输出的那一大堆不是报错的那就说明安装成功了。</p>
<h2 id="Mac-安装-OpenCV"><a href="#Mac-安装-OpenCV" class="headerlink" title="Mac 安装 OpenCV"></a>Mac 安装 OpenCV</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">brew install opencv</div></pre></td></tr></table></figure>
<p>这样安装了还是要配置环境变量</p>
<h3 id="配置-pkg-config-环境变量"><a href="#配置-pkg-config-环境变量" class="headerlink" title="配置 pkg-config 环境变量"></a>配置 pkg-config 环境变量</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig/</div></pre></td></tr></table></figure>
<h3 id="把-OpenCV-pc-文件链接到-PKG-CONFIG-PATH"><a href="#把-OpenCV-pc-文件链接到-PKG-CONFIG-PATH" class="headerlink" title="把 OpenCV .pc 文件链接到 PKG_CONFIG_PATH"></a>把 OpenCV .pc 文件链接到 PKG_CONFIG_PATH</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ln -s /usr/local/opt/opencv3/lib/pkgconfig/opencv.pc $PKG_CONFIG_PATH</div></pre></td></tr></table></figure>
<p>这一步具体的路径就要看 opencv.pc 文件在哪里了，我的 Mac 上的是 opencv4.pc 文件</p>
<h3 id="然后"><a href="#然后" class="headerlink" title="然后"></a>然后</h3><p>环境变量配置好了之后应该就可以了，之后还是运行上面的命令来检查是否安装成功。详细的安装过程可以看<a href="https://gist.github.com/nkcr/6f5c6db4dccd3b32e8ba" target="_blank" rel="external">这个教程</a>。</p>
<h2 id="运行相应程序"><a href="#运行相应程序" class="headerlink" title="运行相应程序"></a>运行相应程序</h2><p>如果源程序中引用了相应的模块那么编译的时候就要加入一些其他的内容了，比如如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">g++ -std=c++11 main.cpp mangaLineSeparator.cpp -o main $(pkg-config --cflags --libs opencv4)</div></pre></td></tr></table></figure>
<p>然后就生成了可执行程序 <code>main</code> 了。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>C++ 的模块的使用和 Python 还是有一些不同的，在处理问题的时候不要根据惯性思维来思考，不然就会在一些你意想不到的地方纠结……比如明明是编译的命令写错了，我却一直以为是模块没有正常安装……</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;扯两句废话&quot;&gt;&lt;a href=&quot;#扯两句废话&quot; class=&quot;headerlink&quot; title=&quot;扯两句废话&quot;&gt;&lt;/a&gt;扯两句废话&lt;/h2&gt;&lt;p&gt;之前用惯了 Python，以为使用 C++ 的模块也是直接一行命令安装然后再直接编译就可以了，没想到并没有这么简单，
    
    </summary>
    
      <category term="C++" scheme="https://blog.patrickcty.cc/categories/C/"/>
    
    
      <category term="C++" scheme="https://blog.patrickcty.cc/tags/C/"/>
    
      <category term="OpenCV" scheme="https://blog.patrickcty.cc/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>3.28随想</title>
    <link href="https://blog.patrickcty.cc/2019/03/28/3-28%E9%9A%8F%E6%83%B3/"/>
    <id>https://blog.patrickcty.cc/2019/03/28/3-28随想/</id>
    <published>2019-03-28T06:10:34.000Z</published>
    <updated>2019-03-28T06:47:17.292Z</updated>
    
    <content type="html"><![CDATA[<p>好久没写随想了，不知不觉这本王小波散文集也快读完了。</p>
<p>今天读到的《盖茨的紧身衣》让我有了一些想法。现在经常有一些新事物号称要颠覆、取代已有的一些事物。也有一些新事物被人们鼓吹会完全取代旧事物。</p>
<p>虽然真正能颠覆和取代的确实存在，但大多数新事物只是让市面上多了一个 fancy 的选择，分流了一些摇摆的受众，原本的事物并没有收到那么大的冲击。就比如前几年很多人鼓吹电子书将取代书籍，电子货币将取代现金。但是现在呢？实体书依旧有市场，现金仍然被广泛的使用。不过还有下半句那就是实体书的市场已经大大萎缩了，现金的使用也大大减少了。但其实这种缩小并不是一件坏事，作家的书籍在互联网上得到了更大的曝光，更容易被其他人阅读到；货币的流通不但没有减少反而跟着网购一起腾飞。</p>
<p>不过说起要，要想不被淘汰，最重要的一点就是有实力。群众的眼睛是雪亮的，好的内容在竞争中往往不会落入下风。另外一点就是不要盲目跟风，虽然跟风的话运气好可以一夜暴富，但是通常情况下就会落得一个不三不四的结果。 </p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;好久没写随想了，不知不觉这本王小波散文集也快读完了。&lt;/p&gt;
&lt;p&gt;今天读到的《盖茨的紧身衣》让我有了一些想法。现在经常有一些新事物号称要颠覆、取代已有的一些事物。也有一些新事物被人们鼓吹会完全取代旧事物。&lt;/p&gt;
&lt;p&gt;虽然真正能颠覆和取代的确实存在，但大多数新事物只是让
    
    </summary>
    
      <category term="日记" scheme="https://blog.patrickcty.cc/categories/%E6%97%A5%E8%AE%B0/"/>
    
    
      <category term="王小波" scheme="https://blog.patrickcty.cc/tags/%E7%8E%8B%E5%B0%8F%E6%B3%A2/"/>
    
  </entry>
  
  <entry>
    <title>3.19随想</title>
    <link href="https://blog.patrickcty.cc/2019/03/19/3-19%E9%9A%8F%E6%83%B3/"/>
    <id>https://blog.patrickcty.cc/2019/03/19/3-19随想/</id>
    <published>2019-03-19T01:41:10.000Z</published>
    <updated>2019-03-19T02:01:53.558Z</updated>
    
    <content type="html"><![CDATA[<p>在看《我的精神家园》的时候我就一直在想我在大学之前的事。</p>
<p>王小波的精神家园来自于从小读过的书籍，而对于那些从小并没有养成主动读书习惯的人，精神家园则是大为不同了。在现在看来，我认为背诵语文书上的一些课文，尤其是诗歌与古文是非常有必要的，尽管在大学之前我都是那种看到“背诵”二字都会万分头疼的人（现在好像也非常讨厌背书）。</p>
<p>在批判过去教育的死板与迂腐之前，我不得不说，那种强行要你背的方法虽不是一个最佳的方法，但它的成效确实还不错。何出此言？不说是在小学和初中，就算是在高中很多人对生活的认识都是非常浅薄的，欣赏力也比较有限。即是说，他们无法发现其中的美与内涵。就以《游褒禅山记》为例，在学习这篇文章的时候我并没有感觉到任何吸引到我的地方，但在现在再回想里来，其中蕴含的道理，在生活之中还是非常受用的。我们到底是那些迎难而上的人还是看到险峰就回走的人？即使是最讨厌古文的我，在学习《滕王阁序》的时候，也彻底被王勃的喷涌而出的才华给折服了，这样一篇才华横溢的文章，课后没有要求背诵全文，我也基本把全文熟悉到可以背诵的地步。</p>
<p>虽然当时所学习的那些课文并没有建立起我的精神家园，但它们却在潜移默化之中改变了我的想法，同时这种帮助在我成熟的过程中越发清晰。</p>
<p>这些背诵全文，或者往广了说是语文的学习，都是为了构建我们的精神家园。只不过人们往往对强制的东西非常反感，所以在当时很多人都非常抵触，但还是有一些人从这样的过程中获得了乐趣，为他们的精神家园奠定了坚实的基础。现在的教育方式和我那时候相比已经有了长足的进步，老师都是以一种引导的方式来让学生自主进行自己精神家园的构建，这样的方法在效率和效果上都要比被动灌输要来的好不少。如今网络上键盘侠横行，一个重要的原因就是他们精神家园没有建立起来，自己独立思考的能力严重欠缺，非常缺乏教养。或许到了下一代之后这样的情形能有所好转吧，那时候大家都有了自己的精神家园。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在看《我的精神家园》的时候我就一直在想我在大学之前的事。&lt;/p&gt;
&lt;p&gt;王小波的精神家园来自于从小读过的书籍，而对于那些从小并没有养成主动读书习惯的人，精神家园则是大为不同了。在现在看来，我认为背诵语文书上的一些课文，尤其是诗歌与古文是非常有必要的，尽管在大学之前我都是那种
    
    </summary>
    
      <category term="日记" scheme="https://blog.patrickcty.cc/categories/%E6%97%A5%E8%AE%B0/"/>
    
    
      <category term="王小波" scheme="https://blog.patrickcty.cc/tags/%E7%8E%8B%E5%B0%8F%E6%B3%A2/"/>
    
  </entry>
  
  <entry>
    <title>写在考研尘埃落定之后</title>
    <link href="https://blog.patrickcty.cc/2019/03/18/%E5%86%99%E5%9C%A8%E8%80%83%E7%A0%94%E5%B0%98%E5%9F%83%E8%90%BD%E5%AE%9A%E4%B9%8B%E5%90%8E/"/>
    <id>https://blog.patrickcty.cc/2019/03/18/写在考研尘埃落定之后/</id>
    <published>2019-03-18T14:04:43.000Z</published>
    <updated>2019-03-18T14:29:20.785Z</updated>
    
    <content type="html"><![CDATA[<p>3.18 晚上七点二十，考研的总排名终于公布在软件学院的官网上了，我也在拟录取的名单之中。这也意味着我的考研生活终于真正意义上的尘埃落定了。</p>
<p>这个时候按理说应该是吹一波我考研是怎么认真复习，怎么磨练意志这种内容。然而事实并不是这样，虽然不想承认，但这次考研，特别是初试是有很大的运气成分存在的。即使是在最紧张的二轮复习的时候，我复习的效率还是非常低的；准备复试的效率低得就更加令人难以启齿了。关于考研，我想说的不是这些，而更多是一种感想。</p>
<p>在写《最短的捷径就是绕远路》这一篇博文的时候，我就想说我的考研相关内容，但当时还没有出结果，不好提前立 flag，现在终于可以来说一说了。就和乔尼认为的那样，我也饶了一大圈的远路，真的真的绕了好大一圈的远路，从武汉到广州，再从广州回到武汉。即使绕了这么大一圈的远路，但我好歹还是回到了起点，没有倒在半路，这也是一种幸运吧。但绕远路也不是没有代价的，无论是在知识储备还是编程能力亦或是专注力，我和同龄的优秀人才都有着不小的差距，我仅仅只是回到了以前——就像乔尼所说，从负数回归到零——但是他们已经往前冲了好大一截路了。这一段路是我在今后的生活中不能忽视的一段距离，也是我需要用实际行动来弥补的距离。</p>
<p>在这次考研的旅途中，我要感谢实验室的环境，一同考研小伙伴的相互鼓励，父母的全力支持，女朋友的鼓励，当然最大的帮助还是熊楚原全方位无死角的引导了。今天上热搜的清华初试专业第一复试被刷的当事人妹子就是因为缺乏正确的引导而导致这样的悲剧的发生。</p>
<p>说实话，当考研成绩真正出来的时候我的内心是无比的激动的，虽然现在内心依然有些躁动，不过我已经知道了这仅仅只是个开始，后面还有更多的事情要做，我不能一直沉溺在这次的成功之中，而是要像熊楚原说的那样，继续前行，做好我应该做的事情。今后的生活，希望我能多主动去“绕远路”，认真思考，不要逃避。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;3.18 晚上七点二十，考研的总排名终于公布在软件学院的官网上了，我也在拟录取的名单之中。这也意味着我的考研生活终于真正意义上的尘埃落定了。&lt;/p&gt;
&lt;p&gt;这个时候按理说应该是吹一波我考研是怎么认真复习，怎么磨练意志这种内容。然而事实并不是这样，虽然不想承认，但这次考研，特
    
    </summary>
    
      <category term="日记" scheme="https://blog.patrickcty.cc/categories/%E6%97%A5%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>最短的捷径就是绕远路</title>
    <link href="https://blog.patrickcty.cc/2019/03/13/%E6%9C%80%E7%9F%AD%E7%9A%84%E6%8D%B7%E5%BE%84%E5%B0%B1%E6%98%AF%E7%BB%95%E8%BF%9C%E8%B7%AF/"/>
    <id>https://blog.patrickcty.cc/2019/03/13/最短的捷径就是绕远路/</id>
    <published>2019-03-13T05:48:41.000Z</published>
    <updated>2019-05-03T03:32:27.331Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://static.jnugeek.cn/image/mangas/3992.jpeg" alt="image"></p>
<p>“我在这场 SBR 大赛中，总是尝试抄最短的捷径走，但是最短的捷径就是绕远路，绕远路才是我的最短捷径。在横跨这片大陆的期间，我一直都遵行着这个原则。也因为多亏有你陪伴，我才得以跨越这条漫漫长路。”  ——杰洛·齐贝林</p>
<p>杰洛的 Lesson 5 到底是什么意思，在看漫画的时候我就不明白，在之后这个问题又浮上我的心头，并又困扰了我许久。在参考了其他人的理解并结合自己的思考之后，我终于有了些端倪。</p>
<p>最令我困惑的就是杰洛的“在横跨这片大陆的期间，我一直都遵行着这个原则”这句话了。众所周知，杰洛在这次 SBR 大赛之中，从来都是抄捷径走。但实际上，这些所谓的捷径，或许就是“远路”。怎么理解呢？尽管这些路在距离上是最短的，但每一次都伴随着巨大的风险与挑战，稍有不慎就直接丧失比赛资格，输掉全盘的比赛了。所以这些道路尽管读作捷径，但是却写作需要勇气、果断与智慧的远路。也正是因为这样的“绕远路”，杰洛才能在比赛中拔得头筹。他没有波克洛克的强运，但他就是凭自己的努力，取得了领先的地位。</p>
<p><img src="https://static.jnugeek.cn/image/mangas/v2-f05fc60b0d4c75e3e4c01c143170a9c1_hd.jpg" alt="image"></p>
<p>纵观整部 SBR，我最喜欢的角色就是杰洛，一个追寻答案的人，一个良师益友。这部 SBR 我看的还是太匆忙，下次观看的时候我要专注于杰洛与乔尼的成长之上。</p>
<p>绕远路就是最短的捷径，可惜这个道理我没有早点领悟。</p>
<p>3.15</p>
<p>今天在思考中，我对这句话又有了新的理解。</p>
<p>一直以来，我都是一个喜欢抄近道的人，具体说来就是尽量的偷懒。不愿意去深入思考，不愿意去深入查找资料，于是就自己作出了很多让人后悔的决定。正是因为我大学生活之中抄捷径太多了，所以现在落到了一个尴尬的境地。和我比起来，熊楚原就是一个绕远路的人。于是现在的结果就是，熊楚原不仅比我有着更扎实同时更广的专业知识，而且在思想深度上也是我所不能企及的。</p>
<p>在编程方面，我坚信的一点就是“不要重复造轮子”，但是这句话是有适用对象的——是对那些对相关方面较为熟悉的人来说的。而对于接触一个领域的新手来说，造轮子的过程就是一个熟悉的过程，当你能自己独立地造出几个轮子，就说明你对这个领域已经有相当程度的了解了，这时候如果要开发一个项目或者工程的话就可以顺利地使用别人已经造好的轮子了。要不然可能会在你想不到的地方掉进坑，耗费更多的时间。很多时候一个简单的功能我宁可花很多时间来找相关的模块也不愿意自己动手实现一下——就算只有一行代码的事，想想真的有点本末倒置了。</p>
<p>一直以来在抄捷径的过程中，我饶了很多路，真的太讽刺了。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://static.jnugeek.cn/image/mangas/3992.jpeg&quot; alt=&quot;image&quot;&gt;&lt;/p&gt;
&lt;p&gt;“我在这场 SBR 大赛中，总是尝试抄最短的捷径走，但是最短的捷径就是绕远路，绕远路才是我的最短捷径。在横跨这片大
    
    </summary>
    
      <category term="漫画" scheme="https://blog.patrickcty.cc/categories/%E6%BC%AB%E7%94%BB/"/>
    
    
      <category term="JOJO 的奇妙冒险" scheme="https://blog.patrickcty.cc/tags/JOJO-%E7%9A%84%E5%A5%87%E5%A6%99%E5%86%92%E9%99%A9/"/>
    
      <category term="漫画" scheme="https://blog.patrickcty.cc/tags/%E6%BC%AB%E7%94%BB/"/>
    
      <category term="Steel Ball Run" scheme="https://blog.patrickcty.cc/tags/Steel-Ball-Run/"/>
    
  </entry>
  
  <entry>
    <title>3.12随想</title>
    <link href="https://blog.patrickcty.cc/2019/03/12/3-12%E9%9A%8F%E6%83%B3/"/>
    <id>https://blog.patrickcty.cc/2019/03/12/3-12随想/</id>
    <published>2019-03-12T01:13:46.000Z</published>
    <updated>2019-03-12T01:33:42.708Z</updated>
    
    <content type="html"><![CDATA[<p>前天看了《人性的逆转》，今天看了《体验生活》，这两者在一个方面有类似点，就是吃苦。</p>
<p>文章中指出，人们常常把吃苦当做是一种宝贵的精神财富，是一种获取收益的必要条件。如果把这当做一种自我安慰，来度过艰难的岁月，那我觉得无可厚非；但如果把这当成一种真理进行鼓吹，让人们在不需要受苦的时候去追求吃苦，那就是一种非常害人的思想了。</p>
<p>在一些影视剧里面，常常会出现“忆苦思甜”的场景：一家人坐在餐桌上，吃着菜杆子，讲述着以前的苦日子。从那个苦年代过来的人非常吃这一套，而且这样的氛围真真切切能让他们回忆起之前的经历，不过对于他们的子女，这就是一顿难吃的饭以及一些不知所云的经历。忆苦思甜不是这么来的，在优渥环境中长大的人是无法想象那种艰难的情景的，你也别想他们能从中学到珍惜现在。</p>
<p>要让他们珍惜当下，培养他们的同理心，最好的方法就是实践。有条件的话可以去偏远山区去探望那里的儿童，让子女亲自把物资交给他们，让他们亲自感受一下安稳的生活是并不是理所当然；即使去不了偏远山区也可以去孤儿院这些地方去看看。形式从来都没那么重要，重要的是一种真真切切的感情，你说这样就比吃菜杆子更加的苦吗？完全没有啊！但这样的效果却比吃菜杆子来的不知道有多好，甚至还可以在回程的路上，在他们还没有回到他们熟悉的舒服环境之前，再给他们讲讲过去的苦日子，这样一来就能让他们有更深的感触。</p>
<p>最后我想说的是，很多人的吃苦就是一种假把式，用来麻痹自己，让自己心安理得，真正是因为懒还是因为别的什么的原因个人自己心里都有数。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前天看了《人性的逆转》，今天看了《体验生活》，这两者在一个方面有类似点，就是吃苦。&lt;/p&gt;
&lt;p&gt;文章中指出，人们常常把吃苦当做是一种宝贵的精神财富，是一种获取收益的必要条件。如果把这当做一种自我安慰，来度过艰难的岁月，那我觉得无可厚非；但如果把这当成一种真理进行鼓吹，让人
    
    </summary>
    
      <category term="日记" scheme="https://blog.patrickcty.cc/categories/%E6%97%A5%E8%AE%B0/"/>
    
    
      <category term="王小波" scheme="https://blog.patrickcty.cc/tags/%E7%8E%8B%E5%B0%8F%E6%B3%A2/"/>
    
  </entry>
  
  <entry>
    <title>复试准备指二零零七到二零一二上机题</title>
    <link href="https://blog.patrickcty.cc/2019/03/09/%E5%A4%8D%E8%AF%95%E5%87%86%E5%A4%87%E6%8C%87%E4%BA%8C%E9%9B%B6%E9%9B%B6%E4%B8%83%E5%88%B0%E4%BA%8C%E9%9B%B6%E4%B8%80%E4%BA%8C%E4%B8%8A%E6%9C%BA%E9%A2%98/"/>
    <id>https://blog.patrickcty.cc/2019/03/09/复试准备指二零零七到二零一二上机题/</id>
    <published>2019-03-09T03:21:35.000Z</published>
    <updated>2019-03-09T03:21:51.633Z</updated>
    
    <content type="html"><![CDATA[<ol>
<li>一群人（排列的编号从 1 到 N，N 可以设定）围成一圈，按一定规则出列。剩余的人仍然围成一圈，出列规则是顺着 1 到 N 的方向对圈内的人从 1 到 C 记数（C 可以设定）。圈内 记数为 C 的人出列。剩余的人重新计数。按上述规则，让圈内所有的人出列。请编程输出 出列编号的序列。</li>
</ol>
<p>例：</p>
<p>若 N=3,C=1,则出列编号的序列为 1，2，3</p>
<p>若 N=3,C=2,则出列编号的序列为 2，1，3</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"># include &lt;iostream&gt;</div><div class="line"></div><div class="line">using namespace std;</div><div class="line"></div><div class="line">int main() &#123;</div><div class="line"></div><div class="line">    int n, c;</div><div class="line">    while (cin &gt;&gt; n &gt;&gt; c) &#123;</div><div class="line">        int out[1000] = &#123;0&#125;;</div><div class="line">        int cnt = n;  // 没有出列的人数</div><div class="line">        int num = 1;  // 报数</div><div class="line">        int no = 0;  // 排列编号</div><div class="line">        while (cnt) &#123;</div><div class="line">            if (out[no] == 1) &#123;</div><div class="line">                no = (no + 1) % n;</div><div class="line">                continue;</div><div class="line">            &#125;</div><div class="line">            if (num == c) &#123;</div><div class="line">                cout &lt;&lt; no + 1 &lt;&lt; &apos; &apos;;</div><div class="line">                out[no] = 1;</div><div class="line">                num = 1;</div><div class="line">                cnt--;</div><div class="line">            &#125;</div><div class="line">            else &#123;</div><div class="line">                num++;</div><div class="line">            &#125;</div><div class="line">            no = (no + 1) % n;</div><div class="line">        &#125;</div><div class="line">        cout &lt;&lt; endl;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    return 0;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ol>
<li>输入一个循环数组（数组的最后一个元素的下一元素为数组的第一个元素），依次打印出 数组中所有元素的下一个比这个元素更大的值（按数组下标大小搜寻，可以循环），如果不 存在更大的元素，打印-1。</li>
</ol>
<p>例：</p>
<p>输入：</p>
<p>6</p>
<p>1 2 1 6 3 4</p>
<p>输出：2 6 6 -1 4 6 </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"># include &lt;iostream&gt;</div><div class="line"></div><div class="line">using namespace std;</div><div class="line"></div><div class="line">int main() &#123;</div><div class="line"></div><div class="line">    int n;</div><div class="line">    int a[1000];</div><div class="line">    while (cin &gt;&gt; n) &#123;</div><div class="line">        int mmax = -1;</div><div class="line">        for (int i = 0; i &lt; n; ++i) &#123;</div><div class="line">            cin &gt;&gt; a[i];</div><div class="line">            if (a[i] &gt; mmax) &#123;</div><div class="line">                mmax = a[i];</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        for (int i = 0; i &lt; n; ++i) &#123;</div><div class="line">            if (a[i] == mmax) &#123;</div><div class="line">                cout &lt;&lt; -1 &lt;&lt; &apos; &apos;;</div><div class="line">                continue;</div><div class="line">            &#125;</div><div class="line">            int next = (i + 1) % n;</div><div class="line">            while (1) &#123;</div><div class="line">                if (a[i] &lt; a[next]) &#123;</div><div class="line">                    cout &lt;&lt; a[next] &lt;&lt; &apos; &apos;;</div><div class="line">                    break;</div><div class="line">                &#125;</div><div class="line">                next = (next + 1) % n;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        cout &lt;&lt; endl;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    return 0;</div><div class="line">&#125;</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;ol&gt;
&lt;li&gt;一群人（排列的编号从 1 到 N，N 可以设定）围成一圈，按一定规则出列。剩余的人仍然围成一圈，出列规则是顺着 1 到 N 的方向对圈内的人从 1 到 C 记数（C 可以设定）。圈内 记数为 C 的人出列。剩余的人重新计数。按上述规则，让圈内所有的人出列。请编程
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>复试准备之二零一三上机题</title>
    <link href="https://blog.patrickcty.cc/2019/03/07/%E5%A4%8D%E8%AF%95%E5%87%86%E5%A4%87%E4%B9%8B%E4%BA%8C%E9%9B%B6%E4%B8%80%E4%B8%89%E4%B8%8A%E6%9C%BA%E9%A2%98/"/>
    <id>https://blog.patrickcty.cc/2019/03/07/复试准备之二零一三上机题/</id>
    <published>2019-03-07T13:46:47.000Z</published>
    <updated>2019-03-07T13:47:08.959Z</updated>
    
    <content type="html"><![CDATA[<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><ol>
<li>输出 100-1000 的所有平方回文数。</li>
</ol>
<p>平分回文数字是满足下列条件的整数：</p>
<p>（1）从左读与从右读都是一样的。</p>
<p>（2）为某一个数的平方。</p>
<p>例：121 是平方回文数。</p>
<ol>
<li>编程解决“八皇后问题”：即在一个 8*8 的矩形格子中排放 8 个皇后，要满足的条件包 括：任意两个皇后不能在同一行，同一列，也不能在同一条对角线上。</li>
</ol>
<p>要求编程给出解的个数。</p>
<h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>第一题</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"># include &lt;iostream&gt;</div><div class="line"># include &lt;cmath&gt;  // 用来求平方根</div><div class="line"></div><div class="line">using namespace std;</div><div class="line"></div><div class="line">bool is_square(int num) &#123;</div><div class="line">    double x = sqrt(num);</div><div class="line">    int y = (int)x;</div><div class="line"></div><div class="line">    return x == y;</div><div class="line">&#125;</div><div class="line"></div><div class="line">bool is_huiwen(int num) &#123;</div><div class="line">    int x = num % 10;</div><div class="line">    int y = num / 100;</div><div class="line"></div><div class="line">    return x == y;</div><div class="line">&#125;</div><div class="line"></div><div class="line">int main() &#123;</div><div class="line"></div><div class="line">    for (int i = 100; i &lt; 1000; ++i) &#123;</div><div class="line">        if (is_square(i) &amp;&amp; is_huiwen(i)) &#123;</div><div class="line">            cout &lt;&lt; i &lt;&lt; &apos; &apos;;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    cout &lt;&lt; endl;</div><div class="line"></div><div class="line">    return 0;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>第二题</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div></pre></td><td class="code"><pre><div class="line"># include &lt;iostream&gt;</div><div class="line"># include &lt;string&gt;</div><div class="line"></div><div class="line">using namespace std;</div><div class="line"></div><div class="line">int arr[8][8] = &#123;0&#125;;</div><div class="line">int col_flags[8] = &#123;0&#125;;</div><div class="line">int cnt = 0;</div><div class="line"></div><div class="line">void queen(int row) &#123;</div><div class="line">    if (row == 8) &#123;</div><div class="line">        cnt++;</div><div class="line">        for (int i = 0; i &lt; 8; ++i) &#123;</div><div class="line">            for (int j = 0; j &lt; 8; ++j) &#123;</div><div class="line">                cout &lt;&lt; arr[i][j] &lt;&lt; &apos; &apos;;</div><div class="line">            &#125;</div><div class="line">            cout &lt;&lt; endl;</div><div class="line">        &#125;</div><div class="line">        cout &lt;&lt; endl;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    for (int i = 0; i &lt; 8; ++i) &#123;</div><div class="line">        // 纵列上没有皇后</div><div class="line">        if (col_flags[i] == 1) continue;</div><div class="line">        // 左斜对角线上没有皇后</div><div class="line">        int flag = 0;</div><div class="line">        for (int j = 1; j + i &lt; 8; ++j) &#123;</div><div class="line">            if (row - j &gt;= 0) &#123;</div><div class="line">                if (arr[row - j][i + j] != 0) &#123;</div><div class="line">                    flag = 1;</div><div class="line">                    continue;</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        if (flag == 1) &#123;</div><div class="line">            continue;</div><div class="line">        &#125;</div><div class="line">        flag = 0;</div><div class="line">        // 右斜对角线没有皇后</div><div class="line">        for (int j = 1; j &lt;= i; ++j) &#123;</div><div class="line">            if (row - j &gt;= 0) &#123;</div><div class="line">                if (arr[row - j][i - j] != 0) &#123;</div><div class="line">                    flag = 1;</div><div class="line">                    continue;</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        if (flag == 1) &#123;</div><div class="line">            continue;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        arr[row][i] = 1;</div><div class="line">        col_flags[i] = 1;</div><div class="line">        queen(row + 1);</div><div class="line">        arr[row][i] = 0;</div><div class="line">        col_flags[i] = 0;</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">int main() &#123;</div><div class="line">    queen(0);</div><div class="line">    cout &lt;&lt; cnt &lt;&lt; endl;</div><div class="line"></div><div class="line">    return 0;</div><div class="line">&#125;</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;问题描述&quot;&gt;&lt;a href=&quot;#问题描述&quot; class=&quot;headerlink&quot; title=&quot;问题描述&quot;&gt;&lt;/a&gt;问题描述&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;输出 100-1000 的所有平方回文数。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;平分回文数字是满足下列条件的整数：&lt;/p
    
    </summary>
    
    
  </entry>
  
</feed>
